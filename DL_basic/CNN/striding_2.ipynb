{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.302107767398287\n",
      "=== epoch:1, train acc:0.17, test acc:0.196 ===, time:  0.034906625747680664\n",
      "train loss:2.301800116930653\n",
      "train loss:2.3009777642792004\n",
      "train loss:2.3015219803521445\n",
      "train loss:2.2999062586776287\n",
      "train loss:2.2988767592892443\n",
      "train loss:2.2996968214794378\n",
      "train loss:2.2976189025736233\n",
      "train loss:2.2976957298315277\n",
      "train loss:2.2949449315732138\n",
      "train loss:2.2951774831439864\n",
      "train loss:2.2935965854897273\n",
      "train loss:2.2893287814581176\n",
      "train loss:2.2819172548030635\n",
      "train loss:2.2833987450991136\n",
      "train loss:2.2788710432236288\n",
      "train loss:2.2726643168252236\n",
      "train loss:2.269077045894517\n",
      "train loss:2.2580024326814137\n",
      "train loss:2.2446498321724335\n",
      "train loss:2.231775000873076\n",
      "train loss:2.231853365837705\n",
      "train loss:2.2189822344331165\n",
      "train loss:2.194319384402018\n",
      "train loss:2.167626814505583\n",
      "train loss:2.1664733254268604\n",
      "train loss:2.1436947929268793\n",
      "train loss:2.1455137518042413\n",
      "train loss:2.1000225574007962\n",
      "train loss:2.1263099586610053\n",
      "train loss:2.064694210586907\n",
      "train loss:2.023071440347703\n",
      "train loss:2.0245388861434166\n",
      "train loss:1.9858633867284912\n",
      "train loss:1.9571669874533706\n",
      "train loss:1.9777017395050978\n",
      "train loss:1.8917364921774824\n",
      "train loss:1.901721661947036\n",
      "train loss:1.8201046604823463\n",
      "train loss:1.8532128437104682\n",
      "train loss:1.7511395592693173\n",
      "train loss:1.7755764641698357\n",
      "train loss:1.745106779746445\n",
      "train loss:1.7564222746360556\n",
      "train loss:1.7199767375582595\n",
      "train loss:1.5409871771964803\n",
      "train loss:1.595938376389876\n",
      "train loss:1.634149476387611\n",
      "train loss:1.5527405881648793\n",
      "train loss:1.5102960210556469\n",
      "train loss:1.3780083948384916\n",
      "train loss:1.4382681494673983\n",
      "train loss:1.4814597322652552\n",
      "train loss:1.3286298073648615\n",
      "train loss:1.5047532626267754\n",
      "train loss:1.3166596895571225\n",
      "train loss:1.2361343500888335\n",
      "train loss:1.3507646559229016\n",
      "train loss:1.2791559538055675\n",
      "train loss:1.273871396939193\n",
      "train loss:1.3315346641689338\n",
      "train loss:1.2877502036082675\n",
      "train loss:1.130949254977324\n",
      "train loss:1.1073701068631219\n",
      "train loss:1.2325837224575138\n",
      "train loss:1.1632550270178308\n",
      "train loss:1.094242005142687\n",
      "train loss:1.2255506229459312\n",
      "train loss:1.1922262290379546\n",
      "train loss:1.1723790080244227\n",
      "train loss:1.2040477588715135\n",
      "train loss:1.241952638882825\n",
      "train loss:1.0324015155326542\n",
      "train loss:1.0822570088236247\n",
      "train loss:1.0850893616235375\n",
      "train loss:1.216871370044354\n",
      "train loss:1.1425336971977866\n",
      "train loss:1.0052763781593035\n",
      "train loss:1.0255691038652086\n",
      "train loss:0.9737156921639126\n",
      "train loss:0.8566730583972899\n",
      "train loss:1.0034484895987723\n",
      "train loss:0.9351240236627797\n",
      "train loss:0.7670247372058725\n",
      "train loss:0.966344630553774\n",
      "train loss:1.143241016630864\n",
      "train loss:1.1880998729874046\n",
      "train loss:1.0195400993400827\n",
      "train loss:0.9130366145625528\n",
      "train loss:0.9366505704402871\n",
      "train loss:1.0610133578407146\n",
      "train loss:0.9807894933990052\n",
      "train loss:0.9786408459566255\n",
      "train loss:1.180527772259384\n",
      "train loss:0.956535048584783\n",
      "train loss:0.8347783476148791\n",
      "train loss:0.8588441575172719\n",
      "train loss:0.9147353932402542\n",
      "train loss:0.958012176161856\n",
      "train loss:1.099364336763442\n",
      "train loss:0.9246309421802242\n",
      "train loss:0.9270844781837648\n",
      "train loss:0.8826115708676971\n",
      "train loss:0.9155361051287018\n",
      "train loss:1.0934308682721943\n",
      "train loss:0.9695240900457505\n",
      "train loss:0.8035039956770066\n",
      "train loss:0.9581655446100834\n",
      "train loss:0.912198759336627\n",
      "train loss:0.7480857703947192\n",
      "train loss:0.6775704475385941\n",
      "train loss:0.7739704453185539\n",
      "train loss:1.1257198851190744\n",
      "train loss:0.7517861301218309\n",
      "train loss:0.846066218591603\n",
      "train loss:0.8407866554345103\n",
      "train loss:0.7759525562794769\n",
      "train loss:0.783798452044827\n",
      "train loss:0.8009522163703419\n",
      "train loss:0.8711204705731599\n",
      "train loss:0.885520630634498\n",
      "train loss:0.8385417163019286\n",
      "train loss:1.0276645188739233\n",
      "train loss:0.8346816976066291\n",
      "train loss:0.9033553205775954\n",
      "train loss:0.8873172007797975\n",
      "train loss:0.7350444665191997\n",
      "train loss:0.9099066827714337\n",
      "train loss:0.8872668086635929\n",
      "train loss:0.5777876247084897\n",
      "train loss:0.9703395735576222\n",
      "train loss:0.8449013633452596\n",
      "train loss:0.7209827189915005\n",
      "train loss:0.8022476962313579\n",
      "train loss:0.7672124571932164\n",
      "train loss:0.9550943376261845\n",
      "train loss:0.9700652678682671\n",
      "train loss:0.8653919020072763\n",
      "train loss:0.7811412922578026\n",
      "train loss:0.7810705436239122\n",
      "train loss:0.9096530168780609\n",
      "train loss:1.0389583562739235\n",
      "train loss:0.9236159590734361\n",
      "train loss:0.7585766486348252\n",
      "train loss:0.8105183507349121\n",
      "train loss:1.0503998285611484\n",
      "train loss:0.954536748584192\n",
      "train loss:0.7573076455757785\n",
      "train loss:0.9007746870648065\n",
      "train loss:0.9158350958399243\n",
      "train loss:0.6764081137491508\n",
      "train loss:0.7450367360287362\n",
      "train loss:0.7053608813590163\n",
      "train loss:0.8446678604159424\n",
      "train loss:0.9299917635178852\n",
      "train loss:0.8142668014469429\n",
      "train loss:0.8107408871153616\n",
      "train loss:0.8555833464557963\n",
      "train loss:0.9144944708608072\n",
      "train loss:0.9306791519607206\n",
      "train loss:0.8811770470718576\n",
      "train loss:0.932140545887274\n",
      "train loss:0.8029152064392242\n",
      "train loss:0.8703669774553155\n",
      "train loss:0.8808246240124773\n",
      "train loss:0.8705662832100599\n",
      "train loss:0.8501345772191712\n",
      "train loss:0.804166245374309\n",
      "train loss:0.8860371602349915\n",
      "train loss:0.7131401784897692\n",
      "train loss:1.063594915253804\n",
      "train loss:0.6995901043746471\n",
      "train loss:0.8815473386191978\n",
      "train loss:0.6099420907395393\n",
      "train loss:0.6527607882732047\n",
      "train loss:0.807507609595879\n",
      "train loss:0.6928916263659781\n",
      "train loss:0.815319910059086\n",
      "train loss:0.7550843501059386\n",
      "train loss:0.7593544117984279\n",
      "train loss:0.8552330824625013\n",
      "train loss:0.8969006016769856\n",
      "train loss:0.7850030311816956\n",
      "train loss:0.8463466659566228\n",
      "train loss:0.8215414268865916\n",
      "train loss:0.7303814946908236\n",
      "train loss:0.8374522624084395\n",
      "train loss:0.8746849070473508\n",
      "train loss:0.6671610051795978\n",
      "train loss:0.7206336408479417\n",
      "train loss:0.7720065236043356\n",
      "train loss:0.6382291538320091\n",
      "train loss:0.6522270096286377\n",
      "train loss:0.7524830972984137\n",
      "train loss:0.7956046868631623\n",
      "train loss:0.7805007592687058\n",
      "train loss:0.8542553991808384\n",
      "train loss:0.6496708636819752\n",
      "train loss:0.8613751836754111\n",
      "train loss:0.7756765965220555\n",
      "train loss:0.9506112215281032\n",
      "train loss:0.7813428602257511\n",
      "train loss:0.8118142796665375\n",
      "train loss:0.84112132749328\n",
      "train loss:0.8913371695662013\n",
      "train loss:0.7246792543390813\n",
      "train loss:0.9966815103024683\n",
      "train loss:0.8026500154025428\n",
      "train loss:0.954183651768862\n",
      "train loss:0.7762062029117466\n",
      "train loss:0.6411282798057496\n",
      "train loss:0.569587469743055\n",
      "train loss:0.7681977732211501\n",
      "train loss:0.7195155239618878\n",
      "train loss:0.6894558101923988\n",
      "train loss:0.7961952267885092\n",
      "train loss:0.7258876290580872\n",
      "train loss:0.7294794693750642\n",
      "train loss:0.8630728103682509\n",
      "train loss:0.7337907080559729\n",
      "train loss:0.9245219517898142\n",
      "train loss:0.7526319078496256\n",
      "train loss:0.5773098529695101\n",
      "train loss:0.5938693909607907\n",
      "train loss:0.7931040973835084\n",
      "train loss:0.6743041423683855\n",
      "train loss:0.739490217992912\n",
      "train loss:0.6831169357054615\n",
      "train loss:0.6988979922187935\n",
      "train loss:0.9123434278499658\n",
      "train loss:0.6807843861845729\n",
      "train loss:0.8019651538569603\n",
      "train loss:0.6713711203391936\n",
      "train loss:0.8017319554707608\n",
      "train loss:0.6018362693758783\n",
      "train loss:0.7472886703628115\n",
      "train loss:0.6953866395754499\n",
      "train loss:0.7424466522738549\n",
      "train loss:0.694108817288454\n",
      "train loss:0.7697655496442313\n",
      "train loss:0.6194699094349994\n",
      "train loss:0.7006437261961453\n",
      "train loss:0.800729853087576\n",
      "train loss:0.6466707495927024\n",
      "train loss:0.5964373908859932\n",
      "train loss:0.7439237778030825\n",
      "train loss:0.684812210756085\n",
      "train loss:0.7690616313934799\n",
      "train loss:0.9700009611596363\n",
      "train loss:0.6780974768379185\n",
      "train loss:0.6516208315599704\n",
      "train loss:0.5881142005800151\n",
      "train loss:0.9999098125596629\n",
      "train loss:0.7346812947779928\n",
      "train loss:0.8181660010586843\n",
      "train loss:0.7069906803197908\n",
      "train loss:0.5299636010951714\n",
      "train loss:0.4788430084268557\n",
      "train loss:0.772833552812277\n",
      "train loss:0.6743752168295436\n",
      "train loss:0.6523066412876011\n",
      "train loss:0.7104393418592135\n",
      "train loss:0.7523664475954412\n",
      "train loss:0.6490657457414738\n",
      "train loss:0.7061542954284179\n",
      "train loss:0.6870080822172946\n",
      "train loss:0.7692899901322356\n",
      "train loss:0.745142793299006\n",
      "train loss:0.6908759808910162\n",
      "train loss:0.5846531822501979\n",
      "train loss:0.5067656636801203\n",
      "train loss:0.6294864353348857\n",
      "train loss:0.6175456713916437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.4556574032959292\n",
      "train loss:0.562995964701367\n",
      "train loss:0.652581891543725\n",
      "train loss:0.6089782655573701\n",
      "train loss:0.7121266116148475\n",
      "train loss:0.5372267493803029\n",
      "train loss:0.8039973459562276\n",
      "train loss:0.5707216732655731\n",
      "train loss:0.6991107292346617\n",
      "train loss:0.6051042022047866\n",
      "train loss:0.6329196802822694\n",
      "train loss:0.6082690481930583\n",
      "train loss:0.7919929085642577\n",
      "train loss:0.6889523495238463\n",
      "train loss:0.573885665214377\n",
      "train loss:0.6776760984864483\n",
      "train loss:0.6655993592935598\n",
      "train loss:0.7775158714931757\n",
      "train loss:0.6810241364907178\n",
      "train loss:0.6526296545869994\n",
      "train loss:0.719407114018844\n",
      "train loss:0.7202908525987155\n",
      "train loss:0.5681901501489475\n",
      "train loss:0.5778517760517756\n",
      "train loss:0.5230207804185365\n",
      "train loss:0.626433015667647\n",
      "train loss:0.6548467988930637\n",
      "train loss:0.8201088514495034\n",
      "train loss:0.6914160670977174\n",
      "train loss:0.5836943637050102\n",
      "train loss:0.5744706013699087\n",
      "train loss:0.6075185538348942\n",
      "train loss:0.5378517000205509\n",
      "train loss:0.5444460652224509\n",
      "train loss:0.6685288616634685\n",
      "train loss:0.5658422375116641\n",
      "train loss:0.5202101599534017\n",
      "train loss:0.6424496269348913\n",
      "train loss:0.7071359013803267\n",
      "train loss:0.5891504409827504\n",
      "train loss:0.5366178965701867\n",
      "train loss:0.627892504461487\n",
      "train loss:0.6443685442787231\n",
      "train loss:0.563014515806297\n",
      "train loss:0.47364536505542737\n",
      "train loss:0.7090886341799694\n",
      "train loss:0.6858185931181844\n",
      "train loss:0.7000283088812808\n",
      "train loss:0.6484375407507477\n",
      "train loss:0.5192780563085971\n",
      "train loss:0.4664190594935972\n",
      "train loss:0.5925579232319853\n",
      "train loss:0.5029955144684335\n",
      "train loss:0.4528517281286489\n",
      "train loss:0.644860625887929\n",
      "train loss:0.5171883093453207\n",
      "train loss:0.6073435168686343\n",
      "train loss:0.6090609842469397\n",
      "train loss:0.6510453705133599\n",
      "train loss:0.643624394630583\n",
      "train loss:0.7377025984950367\n",
      "train loss:0.5654569721294341\n",
      "train loss:0.6264441266404885\n",
      "train loss:0.5742028217087803\n",
      "train loss:0.5452553863297335\n",
      "train loss:0.46308300243157613\n",
      "train loss:0.41738282930110104\n",
      "train loss:0.5852636186317266\n",
      "train loss:0.6461216203681077\n",
      "train loss:0.5611039205917802\n",
      "train loss:0.6598011319101373\n",
      "train loss:0.45975049363386283\n",
      "train loss:0.5785152040187573\n",
      "train loss:0.7563899620094093\n",
      "train loss:0.5309433467243341\n",
      "train loss:0.5268311911169978\n",
      "train loss:0.6629868190812299\n",
      "train loss:0.5355641497542731\n",
      "train loss:0.5813936018896314\n",
      "train loss:0.5041580676978893\n",
      "train loss:0.6873446021965206\n",
      "train loss:0.5566341673600007\n",
      "train loss:0.6031773010570399\n",
      "train loss:0.5715958602422314\n",
      "train loss:0.6426095211419756\n",
      "train loss:0.4844568214072131\n",
      "train loss:0.6013790901446314\n",
      "train loss:0.44349779459352556\n",
      "train loss:0.5576944524206118\n",
      "train loss:0.5156224070793988\n",
      "train loss:0.509476013069571\n",
      "train loss:0.5053547016225184\n",
      "train loss:0.5988003021912738\n",
      "train loss:0.726853662434241\n",
      "train loss:0.3868945513780242\n",
      "train loss:0.7778680526765317\n",
      "train loss:0.5049567903940898\n",
      "train loss:0.5966164228283397\n",
      "train loss:0.5500293213493458\n",
      "train loss:0.7863167265456238\n",
      "train loss:0.4408470785200327\n",
      "train loss:0.529528402632917\n",
      "train loss:0.4920275756557336\n",
      "train loss:0.7149617666249793\n",
      "train loss:0.47437902528774445\n",
      "train loss:0.5764748503131257\n",
      "train loss:0.5258010988644181\n",
      "train loss:0.5191008159023555\n",
      "train loss:0.5171580842372329\n",
      "train loss:0.5143874421655528\n",
      "train loss:0.5271030383788883\n",
      "train loss:0.6904893039742476\n",
      "train loss:0.4918574552631258\n",
      "train loss:0.7249776098221328\n",
      "train loss:0.4184696544416153\n",
      "train loss:0.4597565306538366\n",
      "train loss:0.46102480055948836\n",
      "train loss:0.6258040824474707\n",
      "train loss:0.539282692150777\n",
      "train loss:0.7963354631242461\n",
      "train loss:0.5438850633100489\n",
      "train loss:0.5034562166901103\n",
      "train loss:0.5671876919662883\n",
      "train loss:0.6567643007828946\n",
      "train loss:0.6334578323048738\n",
      "train loss:0.5675526936948707\n",
      "train loss:0.4552715963342097\n",
      "train loss:0.4522621383794142\n",
      "train loss:0.3943569345560378\n",
      "train loss:0.5064098170342196\n",
      "train loss:0.625154434538656\n",
      "train loss:0.5859272841609158\n",
      "train loss:0.5895773708629718\n",
      "train loss:0.49494268378339124\n",
      "train loss:0.40117660696286483\n",
      "train loss:0.4546074128500288\n",
      "train loss:0.3898426713534066\n",
      "train loss:0.5403037021180104\n",
      "train loss:0.6857234337395481\n",
      "train loss:0.5859876665289833\n",
      "train loss:0.38098526773050884\n",
      "train loss:0.7047579478683645\n",
      "train loss:0.4118764588552335\n",
      "train loss:0.5061057048862408\n",
      "train loss:0.6521877838989251\n",
      "train loss:0.41692260301098566\n",
      "train loss:0.6304681454780563\n",
      "train loss:0.5966082652988418\n",
      "train loss:0.5445672708523281\n",
      "train loss:0.6929738546580516\n",
      "train loss:0.46636114271549567\n",
      "train loss:0.4698213880090151\n",
      "train loss:0.49521442758822\n",
      "train loss:0.4909204002701572\n",
      "train loss:0.4654552825226766\n",
      "train loss:0.4818174335792705\n",
      "train loss:0.5803542239749915\n",
      "train loss:0.5010615165679265\n",
      "train loss:0.5664108468704059\n",
      "train loss:0.4922678978819058\n",
      "train loss:0.6149535598592089\n",
      "train loss:0.5803516749100863\n",
      "train loss:0.5222991258894392\n",
      "train loss:0.6277870087817585\n",
      "train loss:0.5618848153136244\n",
      "train loss:0.7832660790079947\n",
      "train loss:0.42513931569646246\n",
      "train loss:0.4866295588379279\n",
      "train loss:0.434171841723807\n",
      "train loss:0.40334831659855963\n",
      "train loss:0.6994842553189448\n",
      "train loss:0.7654601815071644\n",
      "train loss:0.44281014784287337\n",
      "train loss:0.5082538442593535\n",
      "train loss:0.6192801095680484\n",
      "train loss:0.43669302844677665\n",
      "train loss:0.6601950612090919\n",
      "train loss:0.42965765620448443\n",
      "train loss:0.44591031361001826\n",
      "train loss:0.4610925814542029\n",
      "train loss:0.3637953626415192\n",
      "train loss:0.44111672436320526\n",
      "train loss:0.6048828003354677\n",
      "train loss:0.5925770861449066\n",
      "train loss:0.5609753714395891\n",
      "train loss:0.3983336654610716\n",
      "train loss:0.44513836666445805\n",
      "train loss:0.48233019326834475\n",
      "train loss:0.6049830472027782\n",
      "train loss:0.39946136709396485\n",
      "train loss:0.5446112774521722\n",
      "train loss:0.5203948745511208\n",
      "train loss:0.48302761906231595\n",
      "train loss:0.5999055521506527\n",
      "train loss:0.5264301542076105\n",
      "train loss:0.6198959992255668\n",
      "train loss:0.467091862537698\n",
      "train loss:0.4710179982438749\n",
      "train loss:0.3486645308927405\n",
      "train loss:0.478174190967231\n",
      "train loss:0.3952058489612677\n",
      "train loss:0.43189287084122296\n",
      "train loss:0.535016108856623\n",
      "train loss:0.47033169412046283\n",
      "train loss:0.6860978624348248\n",
      "train loss:0.47187133561900974\n",
      "train loss:0.5680531211541305\n",
      "train loss:0.5365768901295327\n",
      "train loss:0.5421114499338179\n",
      "train loss:0.5097294307848245\n",
      "train loss:0.5358328588708234\n",
      "train loss:0.59309352572544\n",
      "train loss:0.5502394146582926\n",
      "train loss:0.39757005899157727\n",
      "train loss:0.3876894299681456\n",
      "train loss:0.5667157889587209\n",
      "train loss:0.5020064889475728\n",
      "train loss:0.4704821994539139\n",
      "train loss:0.5668093670558434\n",
      "train loss:0.26421524019495746\n",
      "train loss:0.44192296507543716\n",
      "train loss:0.41009315427415743\n",
      "train loss:0.42411478635623145\n",
      "train loss:0.5382875219360854\n",
      "train loss:0.5359681822097253\n",
      "train loss:0.47485992544364153\n",
      "train loss:0.609126102281992\n",
      "train loss:0.6462049546401525\n",
      "train loss:0.49639881446799244\n",
      "train loss:0.44993754888517706\n",
      "train loss:0.3794982990309517\n",
      "train loss:0.5615196735077957\n",
      "train loss:0.3603071395900551\n",
      "train loss:0.4502838281363768\n",
      "train loss:0.5586198522368508\n",
      "train loss:0.5592393921362201\n",
      "train loss:0.5600006719919697\n",
      "train loss:0.47049362069634904\n",
      "train loss:0.43764817047262367\n",
      "train loss:0.32553623008004995\n",
      "train loss:0.45084645531844186\n",
      "train loss:0.3452073932980341\n",
      "train loss:0.6562296929244035\n",
      "train loss:0.3553993922031151\n",
      "train loss:0.3524339670826964\n",
      "train loss:0.3585556077874213\n",
      "train loss:0.4786826191391508\n",
      "train loss:0.46605667830890185\n",
      "train loss:0.6203240547614943\n",
      "train loss:0.457730409029501\n",
      "train loss:0.3309252955640072\n",
      "train loss:0.4974433669249854\n",
      "train loss:0.41277291713393865\n",
      "train loss:0.39958837128829683\n",
      "train loss:0.47178337272473897\n",
      "train loss:0.5488816403040387\n",
      "train loss:0.3084508455940702\n",
      "train loss:0.4084306508436422\n",
      "train loss:0.39381196534779667\n",
      "train loss:0.47078298771356764\n",
      "train loss:0.41094926437854257\n",
      "train loss:0.4071606636379172\n",
      "train loss:0.47104881357781553\n",
      "train loss:0.43159915088425294\n",
      "train loss:0.5382632611812541\n",
      "train loss:0.41198707000427226\n",
      "train loss:0.3959280481045097\n",
      "train loss:0.5401071375104576\n",
      "train loss:0.37975711585917016\n",
      "train loss:0.3990366360230952\n",
      "train loss:0.6167500374910684\n",
      "train loss:0.4431220056198866\n",
      "train loss:0.4813042534663876\n",
      "train loss:0.37673244907145803\n",
      "train loss:0.4110779337185771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.5016109725779329\n",
      "train loss:0.5674057893280321\n",
      "train loss:0.46507609141653783\n",
      "train loss:0.4968189673717984\n",
      "train loss:0.5363627902763732\n",
      "train loss:0.6214812882457416\n",
      "train loss:0.3952128726330893\n",
      "train loss:0.3812515799851334\n",
      "train loss:0.48910393359709536\n",
      "train loss:0.35288636989799677\n",
      "train loss:0.35864623834990733\n",
      "train loss:0.41375118666061994\n",
      "train loss:0.4518600185199695\n",
      "train loss:0.619231528283112\n",
      "train loss:0.4538849404896274\n",
      "train loss:0.42289562766435007\n",
      "train loss:0.4182358112556599\n",
      "train loss:0.4584948876782683\n",
      "train loss:0.4385055783741605\n",
      "train loss:0.3102910746386535\n",
      "train loss:0.4745379133482848\n",
      "train loss:0.5518684358909796\n",
      "train loss:0.4747593192279255\n",
      "train loss:0.420371190754448\n",
      "train loss:0.44238446770953305\n",
      "train loss:0.390357440207995\n",
      "train loss:0.3902881388053172\n",
      "train loss:0.5149194875771985\n",
      "train loss:0.4996809667332829\n",
      "train loss:0.3727807921188925\n",
      "train loss:0.364182183528604\n",
      "train loss:0.46845202638460653\n",
      "train loss:0.5271648471898448\n",
      "train loss:0.3611034412002185\n",
      "train loss:0.2560548780860663\n",
      "train loss:0.6472309841465035\n",
      "train loss:0.42265961192859786\n",
      "train loss:0.44594299238922047\n",
      "train loss:0.4333839099439307\n",
      "train loss:0.5053200316045344\n",
      "train loss:0.3052224816169989\n",
      "train loss:0.3190922699358037\n",
      "train loss:0.40887164669602444\n",
      "train loss:0.5098233741530802\n",
      "train loss:0.46497087959970146\n",
      "train loss:0.3474441017005778\n",
      "train loss:0.3122405543326413\n",
      "train loss:0.41267360235624456\n",
      "train loss:0.37544003179788743\n",
      "train loss:0.42483471807521594\n",
      "train loss:0.37202787142374993\n",
      "train loss:0.436578025224567\n",
      "train loss:0.3774913267823792\n",
      "=== epoch:2, train acc:0.876, test acc:0.863 ===, time:  17.772939443588257\n",
      "train loss:0.5006921268526964\n",
      "train loss:0.37177470576195437\n",
      "train loss:0.3405463844631146\n",
      "train loss:0.41789092736397215\n",
      "train loss:0.3661638904802838\n",
      "train loss:0.29666816182660355\n",
      "train loss:0.43943615719596\n",
      "train loss:0.2926510829346206\n",
      "train loss:0.3612883673720795\n",
      "train loss:0.30615554310621684\n",
      "train loss:0.4871265995747875\n",
      "train loss:0.3978823122795672\n",
      "train loss:0.43030360836882814\n",
      "train loss:0.5311052188496257\n",
      "train loss:0.44843221620951207\n",
      "train loss:0.33451895089625333\n",
      "train loss:0.4575127582334872\n",
      "train loss:0.3242828360393045\n",
      "train loss:0.23541114405780025\n",
      "train loss:0.4253698978328257\n",
      "train loss:0.5197584903076428\n",
      "train loss:0.4032123661403126\n",
      "train loss:0.29748637411370454\n",
      "train loss:0.3962312898376598\n",
      "train loss:0.3764359891665614\n",
      "train loss:0.2631624259324221\n",
      "train loss:0.4276254856346747\n",
      "train loss:0.36179498657970727\n",
      "train loss:0.3591458990204907\n",
      "train loss:0.33308462390408244\n",
      "train loss:0.55617723564912\n",
      "train loss:0.31139966279085607\n",
      "train loss:0.4069320517933329\n",
      "train loss:0.4067822152400158\n",
      "train loss:0.3541191261056397\n",
      "train loss:0.43886721432827036\n",
      "train loss:0.41210168876691194\n",
      "train loss:0.3470515916689249\n",
      "train loss:0.392435803792232\n",
      "train loss:0.44987639341197144\n",
      "train loss:0.42652411974787163\n",
      "train loss:0.4282767573190769\n",
      "train loss:0.313876596661456\n",
      "train loss:0.2960256158628093\n",
      "train loss:0.4806457291376598\n",
      "train loss:0.3544486504511712\n",
      "train loss:0.4160191926672626\n",
      "train loss:0.4490231391865151\n",
      "train loss:0.3755949461861094\n",
      "train loss:0.41808540368987196\n",
      "train loss:0.3080419280909443\n",
      "train loss:0.42490297553104084\n",
      "train loss:0.27428741100492876\n",
      "train loss:0.5250673624008235\n",
      "train loss:0.44235037754760076\n",
      "train loss:0.34169468709513673\n",
      "train loss:0.5839602386138641\n",
      "train loss:0.36650855440144847\n",
      "train loss:0.5122085997383156\n",
      "train loss:0.347263239248113\n",
      "train loss:0.5657690602670854\n",
      "train loss:0.4333945179923661\n",
      "train loss:0.3131013941865432\n",
      "train loss:0.41526802476400254\n",
      "train loss:0.3051399701619634\n",
      "train loss:0.22802794076459063\n",
      "train loss:0.48715799902456425\n",
      "train loss:0.29365840806378024\n",
      "train loss:0.2987315190159264\n",
      "train loss:0.2815327910793024\n",
      "train loss:0.38672763280421873\n",
      "train loss:0.3376915107622447\n",
      "train loss:0.4780514205225012\n",
      "train loss:0.3649490355181761\n",
      "train loss:0.3230920701832097\n",
      "train loss:0.3947033108551479\n",
      "train loss:0.3659735910230906\n",
      "train loss:0.26801036995732774\n",
      "train loss:0.4077934059490376\n",
      "train loss:0.33664381566175705\n",
      "train loss:0.34700382585626316\n",
      "train loss:0.30417810500496845\n",
      "train loss:0.409413890838783\n",
      "train loss:0.30443325520508724\n",
      "train loss:0.46512653989387576\n",
      "train loss:0.30332664624027816\n",
      "train loss:0.2999445791204918\n",
      "train loss:0.26273238070243676\n",
      "train loss:0.3350775444975914\n",
      "train loss:0.39208199604440064\n",
      "train loss:0.33112720600512907\n",
      "train loss:0.6632318599455246\n",
      "train loss:0.2867189942027636\n",
      "train loss:0.3410106967882676\n",
      "train loss:0.3825739426022573\n",
      "train loss:0.32373457202802647\n",
      "train loss:0.30980125784525275\n",
      "train loss:0.3525105674229467\n",
      "train loss:0.35793957332678816\n",
      "train loss:0.30018672758205794\n",
      "train loss:0.35333392166372385\n",
      "train loss:0.37796765090239753\n",
      "train loss:0.26232626435603124\n",
      "train loss:0.4996084807897357\n",
      "train loss:0.3759927776866689\n",
      "train loss:0.32906760475026575\n",
      "train loss:0.25520484116643444\n",
      "train loss:0.21343860335424159\n",
      "train loss:0.3280859202044957\n",
      "train loss:0.589868129550167\n",
      "train loss:0.26195316472760327\n",
      "train loss:0.32535541443794336\n",
      "train loss:0.44771733123570345\n",
      "train loss:0.33768171706211214\n",
      "train loss:0.4161301312743988\n",
      "train loss:0.39839150167656096\n",
      "train loss:0.4354438214391852\n",
      "train loss:0.3104778338073666\n",
      "train loss:0.5136043267270904\n",
      "train loss:0.283542282248287\n",
      "train loss:0.42844509829030075\n",
      "train loss:0.48031569617945985\n",
      "train loss:0.2731701526227408\n",
      "train loss:0.3451328950354099\n",
      "train loss:0.34103997930870167\n",
      "train loss:0.3548482854376918\n",
      "train loss:0.4046283374682964\n",
      "train loss:0.5348887416881987\n",
      "train loss:0.2834092428203401\n",
      "train loss:0.4093430104732173\n",
      "train loss:0.37735440137534826\n",
      "train loss:0.33600111298863483\n",
      "train loss:0.297526310656948\n",
      "train loss:0.33291677754986204\n",
      "train loss:0.400634235046169\n",
      "train loss:0.43902415486556134\n",
      "train loss:0.3831616983363491\n",
      "train loss:0.5105754466930065\n",
      "train loss:0.378841590078397\n",
      "train loss:0.4189428073799392\n",
      "train loss:0.2769591532676658\n",
      "train loss:0.4137928720760071\n",
      "train loss:0.36184129756740036\n",
      "train loss:0.3807887139707314\n",
      "train loss:0.2379321955939114\n",
      "train loss:0.38070451689979956\n",
      "train loss:0.2415748463965428\n",
      "train loss:0.30778608343039443\n",
      "train loss:0.36135676075679335\n",
      "train loss:0.466694583270794\n",
      "train loss:0.37536055175136146\n",
      "train loss:0.3716748608873209\n",
      "train loss:0.4164171217313211\n",
      "train loss:0.4592205997858542\n",
      "train loss:0.34413421609331896\n",
      "train loss:0.2650465022003974\n",
      "train loss:0.33480823711587726\n",
      "train loss:0.2659131259220175\n",
      "train loss:0.22286740405821098\n",
      "train loss:0.7282768854224996\n",
      "train loss:0.3238081042657191\n",
      "train loss:0.2939033380002327\n",
      "train loss:0.53351049667823\n",
      "train loss:0.31462394756096834\n",
      "train loss:0.31485113760493433\n",
      "train loss:0.424709617882469\n",
      "train loss:0.45344987924038627\n",
      "train loss:0.21408013339012485\n",
      "train loss:0.3258587998268416\n",
      "train loss:0.31470174989155675\n",
      "train loss:0.3418421026815718\n",
      "train loss:0.3836433886654107\n",
      "train loss:0.2662127941561672\n",
      "train loss:0.2875677850804943\n",
      "train loss:0.27197246040728706\n",
      "train loss:0.2517446952337434\n",
      "train loss:0.24482976538834117\n",
      "train loss:0.2811915868671488\n",
      "train loss:0.3837659004142228\n",
      "train loss:0.3718761050556933\n",
      "train loss:0.24688375845074023\n",
      "train loss:0.39313405449075306\n",
      "train loss:0.3247061614031999\n",
      "train loss:0.3047785984342172\n",
      "train loss:0.2913826400485139\n",
      "train loss:0.3115929154545016\n",
      "train loss:0.228408715710674\n",
      "train loss:0.3770934769337294\n",
      "train loss:0.2318124165003203\n",
      "train loss:0.35577809962739954\n",
      "train loss:0.3260549666813176\n",
      "train loss:0.38021924208240676\n",
      "train loss:0.4371412031805601\n",
      "train loss:0.37330773027788405\n",
      "train loss:0.17297842626421914\n",
      "train loss:0.16046511407488295\n",
      "train loss:0.34191363439511846\n",
      "train loss:0.35912121814526204\n",
      "train loss:0.5485408549251064\n",
      "train loss:0.2329530987773742\n",
      "train loss:0.3052353078507261\n",
      "train loss:0.47916482749691425\n",
      "train loss:0.32148644325487097\n",
      "train loss:0.39364206994386564\n",
      "train loss:0.5098339124686353\n",
      "train loss:0.22212352437831878\n",
      "train loss:0.3439875968257287\n",
      "train loss:0.266350599884105\n",
      "train loss:0.3717394866670233\n",
      "train loss:0.37523989956878284\n",
      "train loss:0.28773267733166064\n",
      "train loss:0.3076886975890127\n",
      "train loss:0.3022911204009662\n",
      "train loss:0.34774341480638954\n",
      "train loss:0.3577099529753799\n",
      "train loss:0.3674013056693919\n",
      "train loss:0.3350144342740218\n",
      "train loss:0.24890000037535653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.39888886581941113\n",
      "train loss:0.28875851738419167\n",
      "train loss:0.31131094780285035\n",
      "train loss:0.2999634392950517\n",
      "train loss:0.2563091974325095\n",
      "train loss:0.37223385290589733\n",
      "train loss:0.3239833602698681\n",
      "train loss:0.3371949496558122\n",
      "train loss:0.3114229840399856\n",
      "train loss:0.32049799636172294\n",
      "train loss:0.24547420234507059\n",
      "train loss:0.32290142514246173\n",
      "train loss:0.3228549824833996\n",
      "train loss:0.4070517611469513\n",
      "train loss:0.26436276462790226\n",
      "train loss:0.3037214262485415\n",
      "train loss:0.3163289133285703\n",
      "train loss:0.4834881648793972\n",
      "train loss:0.3423367723165244\n",
      "train loss:0.3269444249064761\n",
      "train loss:0.34380710174154494\n",
      "train loss:0.25989684967721294\n",
      "train loss:0.3547826205583052\n",
      "train loss:0.23577013288245494\n",
      "train loss:0.43738210070875444\n",
      "train loss:0.2672652986496143\n",
      "train loss:0.43845671910400374\n",
      "train loss:0.2938396982048013\n",
      "train loss:0.3714636976818656\n",
      "train loss:0.32453876062224185\n",
      "train loss:0.24465461745516057\n",
      "train loss:0.3115104911661386\n",
      "train loss:0.42195757115513216\n",
      "train loss:0.23762628432598806\n",
      "train loss:0.3112844982563851\n",
      "train loss:0.23105149328425273\n",
      "train loss:0.23241712533002967\n",
      "train loss:0.2620891703671835\n",
      "train loss:0.3232096524570828\n",
      "train loss:0.27444683405546927\n",
      "train loss:0.32981856726429\n",
      "train loss:0.44018337593869306\n",
      "train loss:0.38384010200776975\n",
      "train loss:0.22360040450496288\n",
      "train loss:0.23358812466851894\n",
      "train loss:0.2597857456842297\n",
      "train loss:0.45818834046252993\n",
      "train loss:0.3862172110408622\n",
      "train loss:0.30354381199998365\n",
      "train loss:0.4185631866255678\n",
      "train loss:0.38214040057581533\n",
      "train loss:0.23278250272889373\n",
      "train loss:0.275215637688611\n",
      "train loss:0.25851014180595094\n",
      "train loss:0.2704649592779989\n",
      "train loss:0.3382442762879939\n",
      "train loss:0.41235701315235984\n",
      "train loss:0.2997558919037832\n",
      "train loss:0.328593367061454\n",
      "train loss:0.2733627101743375\n",
      "train loss:0.25694154870159414\n",
      "train loss:0.37897187098907087\n",
      "train loss:0.46746936011513734\n",
      "train loss:0.28780585378698526\n",
      "train loss:0.34687781427320535\n",
      "train loss:0.34135174252083367\n",
      "train loss:0.32513951807320646\n",
      "train loss:0.3093899438068087\n",
      "train loss:0.2365075576875649\n",
      "train loss:0.2093903914426166\n",
      "train loss:0.3465763530078321\n",
      "train loss:0.36916592111067936\n",
      "train loss:0.32995219792635244\n",
      "train loss:0.40380606706600347\n",
      "train loss:0.3336154869004889\n",
      "train loss:0.3593876325320269\n",
      "train loss:0.3230721643926539\n",
      "train loss:0.1983997271624562\n",
      "train loss:0.39282258831566963\n",
      "train loss:0.21296280147462834\n",
      "train loss:0.4204285197204369\n",
      "train loss:0.3581581851965154\n",
      "train loss:0.3183023482625894\n",
      "train loss:0.326441849911311\n",
      "train loss:0.23369474124207534\n",
      "train loss:0.32879867347916614\n",
      "train loss:0.451151542224863\n",
      "train loss:0.27474678932696145\n",
      "train loss:0.201103259562883\n",
      "train loss:0.30605301628717674\n",
      "train loss:0.2805543500876197\n",
      "train loss:0.3081940848894498\n",
      "train loss:0.30047494331616553\n",
      "train loss:0.35418054909548574\n",
      "train loss:0.2015478700741246\n",
      "train loss:0.37402791839891414\n",
      "train loss:0.22600915350410503\n",
      "train loss:0.2967303215668069\n",
      "train loss:0.2861759257248775\n",
      "train loss:0.2497066229612209\n",
      "train loss:0.37351522046033553\n",
      "train loss:0.2637482027400285\n",
      "train loss:0.19254779537477426\n",
      "train loss:0.18974444206851268\n",
      "train loss:0.2895666319782969\n",
      "train loss:0.2351447057960266\n",
      "train loss:0.1827652539882412\n",
      "train loss:0.2538287927229005\n",
      "train loss:0.26392228022863606\n",
      "train loss:0.3452138907898102\n",
      "train loss:0.25598205072845903\n",
      "train loss:0.21694789120622793\n",
      "train loss:0.31677702540641267\n",
      "train loss:0.31563468467360495\n",
      "train loss:0.2660247832730815\n",
      "train loss:0.3539456041776877\n",
      "train loss:0.2630569740584922\n",
      "train loss:0.4229332870618172\n",
      "train loss:0.19481699092050708\n",
      "train loss:0.20610790743961027\n",
      "train loss:0.25212487159734775\n",
      "train loss:0.2836406031726612\n",
      "train loss:0.21689344959704526\n",
      "train loss:0.27258657603303693\n",
      "train loss:0.2882726874942947\n",
      "train loss:0.22815032387471657\n",
      "train loss:0.30851827893449013\n",
      "train loss:0.25858633431796446\n",
      "train loss:0.3125497940647887\n",
      "train loss:0.4023559289103657\n",
      "train loss:0.30927483599952027\n",
      "train loss:0.3515811565276571\n",
      "train loss:0.36279489594524506\n",
      "train loss:0.27596885183419584\n",
      "train loss:0.22987017490616965\n",
      "train loss:0.26205651581582873\n",
      "train loss:0.24945177634840843\n",
      "train loss:0.30194803487800076\n",
      "train loss:0.3267095155092694\n",
      "train loss:0.3011541550267286\n",
      "train loss:0.2797190632713522\n",
      "train loss:0.33197215973881683\n",
      "train loss:0.3283674078497004\n",
      "train loss:0.247668773744193\n",
      "train loss:0.4493088888356271\n",
      "train loss:0.22764121587418815\n",
      "train loss:0.4420917668873416\n",
      "train loss:0.304258179083557\n",
      "train loss:0.45816729420698615\n",
      "train loss:0.3465334074967554\n",
      "train loss:0.28255898018478587\n",
      "train loss:0.3187583345751873\n",
      "train loss:0.3775813932344757\n",
      "train loss:0.24914696880717435\n",
      "train loss:0.2767911906094848\n",
      "train loss:0.42064187229292116\n",
      "train loss:0.35008395661633684\n",
      "train loss:0.2624774057595536\n",
      "train loss:0.26382827215717053\n",
      "train loss:0.3781717705229529\n",
      "train loss:0.23862954255074262\n",
      "train loss:0.31671242170953684\n",
      "train loss:0.1870045414631738\n",
      "train loss:0.34564507248540155\n",
      "train loss:0.27130143500870524\n",
      "train loss:0.17970486013006826\n",
      "train loss:0.2399876077421019\n",
      "train loss:0.3153114708660779\n",
      "train loss:0.3335709886429909\n",
      "train loss:0.3086188132180223\n",
      "train loss:0.2841650344739938\n",
      "train loss:0.2673297054898826\n",
      "train loss:0.2459992292486543\n",
      "train loss:0.2957506263603866\n",
      "train loss:0.3199970978193995\n",
      "train loss:0.2815031699389723\n",
      "train loss:0.25929381292182285\n",
      "train loss:0.14469942488901244\n",
      "train loss:0.3954994420234479\n",
      "train loss:0.29461737453210624\n",
      "train loss:0.3007796721373031\n",
      "train loss:0.31760060387150807\n",
      "train loss:0.29717726859190796\n",
      "train loss:0.32560577525841533\n",
      "train loss:0.40455671038348356\n",
      "train loss:0.27526802730115757\n",
      "train loss:0.29465711884265505\n",
      "train loss:0.22272166284099237\n",
      "train loss:0.15120734992811782\n",
      "train loss:0.16883195507790702\n",
      "train loss:0.29878775568275595\n",
      "train loss:0.3031264045162178\n",
      "train loss:0.4112525016344851\n",
      "train loss:0.29620848183763265\n",
      "train loss:0.20994864227079865\n",
      "train loss:0.36276556742548344\n",
      "train loss:0.18067600483310126\n",
      "train loss:0.41430420949088753\n",
      "train loss:0.2804865062459589\n",
      "train loss:0.35251003920343726\n",
      "train loss:0.2546891235468949\n",
      "train loss:0.26254226462534663\n",
      "train loss:0.2905152208205811\n",
      "train loss:0.17714439933239934\n",
      "train loss:0.2988896367294169\n",
      "train loss:0.22417859351230135\n",
      "train loss:0.24800088081538238\n",
      "train loss:0.1467560437221236\n",
      "train loss:0.1539815853358386\n",
      "train loss:0.24283679323227872\n",
      "train loss:0.2477725437570388\n",
      "train loss:0.1999352989829584\n",
      "train loss:0.33971817284344674\n",
      "train loss:0.2630645461456245\n",
      "train loss:0.2212037773145701\n",
      "train loss:0.3403723441302657\n",
      "train loss:0.2562914274766419\n",
      "train loss:0.43313627690828654\n",
      "train loss:0.3847939571465496\n",
      "train loss:0.23585692704191918\n",
      "train loss:0.2668052623259445\n",
      "train loss:0.3795058559521437\n",
      "train loss:0.38291410954829935\n",
      "train loss:0.27037161544709554\n",
      "train loss:0.3075612797554801\n",
      "train loss:0.4358087497724092\n",
      "train loss:0.26929106284783993\n",
      "train loss:0.42595290501893784\n",
      "train loss:0.4329209280146135\n",
      "train loss:0.21496698138006912\n",
      "train loss:0.23345470114010247\n",
      "train loss:0.31355025383379315\n",
      "train loss:0.31029956827265376\n",
      "train loss:0.3099438903394164\n",
      "train loss:0.3371719442536859\n",
      "train loss:0.2730253544359419\n",
      "train loss:0.3546382992025625\n",
      "train loss:0.4841261606541365\n",
      "train loss:0.2864268614785206\n",
      "train loss:0.24369800031937547\n",
      "train loss:0.33172192784297566\n",
      "train loss:0.21675109628709155\n",
      "train loss:0.4005712258730783\n",
      "train loss:0.27813248890700093\n",
      "train loss:0.3499646413923202\n",
      "train loss:0.3186646696292386\n",
      "train loss:0.3833721714940817\n",
      "train loss:0.28561037362467107\n",
      "train loss:0.29636933613537364\n",
      "train loss:0.29743702490930957\n",
      "train loss:0.3560932838018662\n",
      "train loss:0.33628770991068696\n",
      "train loss:0.2811646358200551\n",
      "train loss:0.2923108956774476\n",
      "train loss:0.21788743303673075\n",
      "train loss:0.2483908608187292\n",
      "train loss:0.20565812204890868\n",
      "train loss:0.3915212179995218\n",
      "train loss:0.19562070607907034\n",
      "train loss:0.24119661777434295\n",
      "train loss:0.3234852658625773\n",
      "train loss:0.36196850981664597\n",
      "train loss:0.30203396802082155\n",
      "train loss:0.25240153721106817\n",
      "train loss:0.24309995470363263\n",
      "train loss:0.19994625721106385\n",
      "train loss:0.22115482458306335\n",
      "train loss:0.25136703046387937\n",
      "train loss:0.4350888772123795\n",
      "train loss:0.2329236086783727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.30326435826747905\n",
      "train loss:0.30985191411069385\n",
      "train loss:0.2946186444688355\n",
      "train loss:0.24536407642298994\n",
      "train loss:0.29818839842037403\n",
      "train loss:0.2761773612534839\n",
      "train loss:0.28391966105585686\n",
      "train loss:0.25219025131355477\n",
      "train loss:0.21115986106486273\n",
      "train loss:0.2471926287482315\n",
      "train loss:0.25385434657633044\n",
      "train loss:0.354147242213124\n",
      "train loss:0.3848570993692414\n",
      "train loss:0.3139208096849061\n",
      "train loss:0.27212038880896516\n",
      "train loss:0.3221132513430858\n",
      "train loss:0.197916039602836\n",
      "train loss:0.22360234979574872\n",
      "train loss:0.17060271338168345\n",
      "train loss:0.3592425939396128\n",
      "train loss:0.3755516049449213\n",
      "train loss:0.24379048972775094\n",
      "train loss:0.3007539782314093\n",
      "train loss:0.2012230230507344\n",
      "train loss:0.22780687287572396\n",
      "train loss:0.2691476915083297\n",
      "train loss:0.44074474153610693\n",
      "train loss:0.2869484428627673\n",
      "train loss:0.1814091751679887\n",
      "train loss:0.22210662045133248\n",
      "train loss:0.3544883925283432\n",
      "train loss:0.2863997792133203\n",
      "train loss:0.2566492861831305\n",
      "train loss:0.30516680650724853\n",
      "train loss:0.5313050291782574\n",
      "train loss:0.24868086567591025\n",
      "train loss:0.12888778323838346\n",
      "train loss:0.2774799303573719\n",
      "train loss:0.26438453032238646\n",
      "train loss:0.31741998433042545\n",
      "train loss:0.21275721400356523\n",
      "train loss:0.3179463147144622\n",
      "train loss:0.2599169095728676\n",
      "train loss:0.20488373920248487\n",
      "train loss:0.28791636386149805\n",
      "train loss:0.36331107953136943\n",
      "train loss:0.18013230519117504\n",
      "train loss:0.285650982212079\n",
      "train loss:0.2624306264429341\n",
      "train loss:0.37486883270999644\n",
      "train loss:0.24300768887235166\n",
      "train loss:0.3347266577688513\n",
      "train loss:0.29236676811213974\n",
      "train loss:0.29821351160401\n",
      "train loss:0.24094118780183657\n",
      "train loss:0.2560572534307002\n",
      "train loss:0.32347646890646403\n",
      "train loss:0.1966256470232548\n",
      "train loss:0.23860603573791525\n",
      "train loss:0.19607231151252028\n",
      "train loss:0.1991524794892534\n",
      "train loss:0.1622299344328526\n",
      "train loss:0.2158616186884858\n",
      "train loss:0.20664713447658056\n",
      "train loss:0.24715765346503044\n",
      "train loss:0.18971080544089142\n",
      "train loss:0.270077027771026\n",
      "train loss:0.11944730075233792\n",
      "train loss:0.4489734352515129\n",
      "train loss:0.2275199438838984\n",
      "train loss:0.17551651898932583\n",
      "train loss:0.26295448492314955\n",
      "train loss:0.27478072770192774\n",
      "train loss:0.18513436890251966\n",
      "train loss:0.3726623574276233\n",
      "train loss:0.16113371373938595\n",
      "train loss:0.17215125844333518\n",
      "train loss:0.21950198845201324\n",
      "train loss:0.23841497796403693\n",
      "train loss:0.23977164115555116\n",
      "train loss:0.27980824658946646\n",
      "train loss:0.45068002641075644\n",
      "train loss:0.2661008028911632\n",
      "train loss:0.22997079715064495\n",
      "train loss:0.24038257458890985\n",
      "train loss:0.2051472940522892\n",
      "train loss:0.20947284211504916\n",
      "train loss:0.2639564085033984\n",
      "train loss:0.28911350310145795\n",
      "train loss:0.23088694128998866\n",
      "train loss:0.3135858295241328\n",
      "train loss:0.22661403081574785\n",
      "train loss:0.3960895111507452\n",
      "train loss:0.2987577352408125\n",
      "train loss:0.3263434324948832\n",
      "train loss:0.22423176504551076\n",
      "train loss:0.26989833956969367\n",
      "train loss:0.32981247972310435\n",
      "train loss:0.15957226014340165\n",
      "train loss:0.36178158763647233\n",
      "train loss:0.22722867564643562\n",
      "train loss:0.20935719671789552\n",
      "train loss:0.18467605337894719\n",
      "train loss:0.25430068454926913\n",
      "train loss:0.21281225720011643\n",
      "train loss:0.20897456806118292\n",
      "train loss:0.24939097108764702\n",
      "train loss:0.1571891910141172\n",
      "train loss:0.26320684120024823\n",
      "train loss:0.17380593823076437\n",
      "train loss:0.20155590509504406\n",
      "train loss:0.2836887089803473\n",
      "=== epoch:3, train acc:0.923, test acc:0.908 ===, time:  37.538578748703\n",
      "train loss:0.24899073676290656\n",
      "train loss:0.23055816002217192\n",
      "train loss:0.32612483379732454\n",
      "train loss:0.3682570288046255\n",
      "train loss:0.2589414464133595\n",
      "train loss:0.20775587642392032\n",
      "train loss:0.27216183593424825\n",
      "train loss:0.24194206065657192\n",
      "train loss:0.21861244603901528\n",
      "train loss:0.24010194432089293\n",
      "train loss:0.2424399947258063\n",
      "train loss:0.48710697065561454\n",
      "train loss:0.2392374253881878\n",
      "train loss:0.23138955564038943\n",
      "train loss:0.20753171517321134\n",
      "train loss:0.2739891016441042\n",
      "train loss:0.14221223292285343\n",
      "train loss:0.18166588620098362\n",
      "train loss:0.24571628150992597\n",
      "train loss:0.23407615333034507\n",
      "train loss:0.303734604147212\n",
      "train loss:0.12332538655058707\n",
      "train loss:0.13474273062888142\n",
      "train loss:0.20840517327978783\n",
      "train loss:0.33545126341009124\n",
      "train loss:0.32061957210358727\n",
      "train loss:0.20841124608670888\n",
      "train loss:0.21642162045096158\n",
      "train loss:0.24557968004223674\n",
      "train loss:0.24766698880153468\n",
      "train loss:0.26110743607620507\n",
      "train loss:0.17830919075973642\n",
      "train loss:0.27629484475985566\n",
      "train loss:0.19468847694706815\n",
      "train loss:0.28292993282171386\n",
      "train loss:0.23559667606323906\n",
      "train loss:0.22079450932830458\n",
      "train loss:0.3222123632153579\n",
      "train loss:0.18391081236133183\n",
      "train loss:0.17820870386729443\n",
      "train loss:0.5213028982674921\n",
      "train loss:0.2865104572083659\n",
      "train loss:0.25198731597476803\n",
      "train loss:0.26101025849365217\n",
      "train loss:0.2738389143447376\n",
      "train loss:0.14681390027420335\n",
      "train loss:0.2628444256008679\n",
      "train loss:0.27119185491818176\n",
      "train loss:0.17099195049643234\n",
      "train loss:0.21172110141911957\n",
      "train loss:0.39615247871938164\n",
      "train loss:0.19194677992029377\n",
      "train loss:0.22820574739602628\n",
      "train loss:0.31513058011622486\n",
      "train loss:0.2194123498261366\n",
      "train loss:0.23915821885576347\n",
      "train loss:0.2682988390844407\n",
      "train loss:0.2515572145146499\n",
      "train loss:0.22554854921770182\n",
      "train loss:0.2876954421755366\n",
      "train loss:0.27536679115198814\n",
      "train loss:0.20578593492139646\n",
      "train loss:0.3206389188583552\n",
      "train loss:0.2286589817016496\n",
      "train loss:0.280171816434387\n",
      "train loss:0.27415825908732583\n",
      "train loss:0.33217011404546026\n",
      "train loss:0.2648436259873129\n",
      "train loss:0.2938420025364152\n",
      "train loss:0.27471553880474864\n",
      "train loss:0.22509853638657887\n",
      "train loss:0.30489869425015603\n",
      "train loss:0.3258160945716485\n",
      "train loss:0.21640014021244855\n",
      "train loss:0.29975291261061765\n",
      "train loss:0.4526611302654125\n",
      "train loss:0.3122221457404468\n",
      "train loss:0.21270495510383747\n",
      "train loss:0.2071100964059983\n",
      "train loss:0.20209357531813107\n",
      "train loss:0.2777715293278704\n",
      "train loss:0.12700779531156908\n",
      "train loss:0.29170164461041775\n",
      "train loss:0.36722158300775043\n",
      "train loss:0.23760737557544137\n",
      "train loss:0.3108962783312535\n",
      "train loss:0.1953767460198588\n",
      "train loss:0.3044204538719326\n",
      "train loss:0.1869455819820752\n",
      "train loss:0.12874864083770143\n",
      "train loss:0.31934445190445276\n",
      "train loss:0.2313227932390064\n",
      "train loss:0.2817494272859725\n",
      "train loss:0.18783972642446614\n",
      "train loss:0.17241640441939818\n",
      "train loss:0.3712917483616498\n",
      "train loss:0.31375233370981725\n",
      "train loss:0.2780741806198509\n",
      "train loss:0.19497922161129075\n",
      "train loss:0.2633614853605696\n",
      "train loss:0.16941727349345728\n",
      "train loss:0.3631596047271241\n",
      "train loss:0.3196844063122647\n",
      "train loss:0.3243495036606428\n",
      "train loss:0.2459589567803314\n",
      "train loss:0.22575749156080793\n",
      "train loss:0.3366266670976455\n",
      "train loss:0.31742264287139255\n",
      "train loss:0.2064998940216113\n",
      "train loss:0.19109724155923768\n",
      "train loss:0.2360464978238984\n",
      "train loss:0.2531751062427481\n",
      "train loss:0.1710588963561242\n",
      "train loss:0.31407489200664684\n",
      "train loss:0.22736539612210716\n",
      "train loss:0.16545204134053343\n",
      "train loss:0.22850456236785666\n",
      "train loss:0.17177250629221028\n",
      "train loss:0.26663338696761163\n",
      "train loss:0.212433770376258\n",
      "train loss:0.2596281219015795\n",
      "train loss:0.09602797185214738\n",
      "train loss:0.1770187994777842\n",
      "train loss:0.33909659637033246\n",
      "train loss:0.17871586857188848\n",
      "train loss:0.2248602242572294\n",
      "train loss:0.39001490201504063\n",
      "train loss:0.24259183309023574\n",
      "train loss:0.19957848119568605\n",
      "train loss:0.2691183498902947\n",
      "train loss:0.1297140288885943\n",
      "train loss:0.2247525378606247\n",
      "train loss:0.35570103883466175\n",
      "train loss:0.3208761948056085\n",
      "train loss:0.2305844069301796\n",
      "train loss:0.32929835616321484\n",
      "train loss:0.34370787160367017\n",
      "train loss:0.12071861404772358\n",
      "train loss:0.21751753253333722\n",
      "train loss:0.18817067029789264\n",
      "train loss:0.2486672431270195\n",
      "train loss:0.2356341623506883\n",
      "train loss:0.25089264166067604\n",
      "train loss:0.22021945009422342\n",
      "train loss:0.2469801530519513\n",
      "train loss:0.18458910056139885\n",
      "train loss:0.29637049154750156\n",
      "train loss:0.2377704565144407\n",
      "train loss:0.20244575378009433\n",
      "train loss:0.18498722505974907\n",
      "train loss:0.2326751213275772\n",
      "train loss:0.35949665172301065\n",
      "train loss:0.3556435505350756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.23506321971759106\n",
      "train loss:0.24567438541156814\n",
      "train loss:0.25837629534187245\n",
      "train loss:0.30916762148512883\n",
      "train loss:0.19773513527568135\n",
      "train loss:0.33849990514087863\n",
      "train loss:0.24096190868863043\n",
      "train loss:0.29049109822729247\n",
      "train loss:0.3864251164621\n",
      "train loss:0.19645777796975947\n",
      "train loss:0.1476415645664446\n",
      "train loss:0.16128408436597208\n",
      "train loss:0.12666332074230127\n",
      "train loss:0.2637550392720111\n",
      "train loss:0.2544659083581459\n",
      "train loss:0.2722570456301997\n",
      "train loss:0.21205018394624722\n",
      "train loss:0.24918200397205897\n",
      "train loss:0.2301155196552861\n",
      "train loss:0.17239971968065754\n",
      "train loss:0.33098112352797854\n",
      "train loss:0.19481953786121964\n",
      "train loss:0.21356349052625867\n",
      "train loss:0.3510318821931148\n",
      "train loss:0.20624800346837824\n",
      "train loss:0.13911618828004899\n",
      "train loss:0.2633704082393852\n",
      "train loss:0.13096604910043474\n",
      "train loss:0.21395618170040834\n",
      "train loss:0.27813965547490904\n",
      "train loss:0.1882191028037109\n",
      "train loss:0.274027190435872\n",
      "train loss:0.2181337350438251\n",
      "train loss:0.2623651988754382\n",
      "train loss:0.2660156010212967\n",
      "train loss:0.15562332583396507\n",
      "train loss:0.17096117144478143\n",
      "train loss:0.20439504024803518\n",
      "train loss:0.2836881697171\n",
      "train loss:0.2505651569819121\n",
      "train loss:0.13566814430099586\n",
      "train loss:0.19226108724647822\n",
      "train loss:0.2511925486448505\n",
      "train loss:0.23350457444946093\n",
      "train loss:0.11812575998138389\n",
      "train loss:0.3105535448693024\n",
      "train loss:0.2595285473958082\n",
      "train loss:0.20989380306270383\n",
      "train loss:0.21052612368892817\n",
      "train loss:0.2162046288819104\n",
      "train loss:0.18620077598742887\n",
      "train loss:0.1633481063945596\n",
      "train loss:0.2191569913611406\n",
      "train loss:0.25583923758653343\n",
      "train loss:0.2547444795273963\n",
      "train loss:0.2149060368690347\n",
      "train loss:0.4139756273609547\n",
      "train loss:0.1758577485217642\n",
      "train loss:0.311197766001759\n",
      "train loss:0.1533635616945503\n",
      "train loss:0.1571803978151661\n",
      "train loss:0.2550470990047993\n",
      "train loss:0.2011508319088102\n",
      "train loss:0.34420044566806884\n",
      "train loss:0.2030559986545613\n",
      "train loss:0.23996675860055533\n",
      "train loss:0.2061846133609411\n",
      "train loss:0.2530513599578962\n",
      "train loss:0.2780770082065023\n",
      "train loss:0.17532085455222032\n",
      "train loss:0.27749341007336203\n",
      "train loss:0.2949651262183927\n",
      "train loss:0.33623330128739537\n",
      "train loss:0.2272453796597484\n",
      "train loss:0.10988836153921183\n",
      "train loss:0.2109127502901262\n",
      "train loss:0.23076355383392888\n",
      "train loss:0.1447888406250708\n",
      "train loss:0.22295218332261985\n",
      "train loss:0.34947401528035876\n",
      "train loss:0.3997495632175182\n",
      "train loss:0.29462432125978155\n",
      "train loss:0.3558373409187539\n",
      "train loss:0.23379593201601284\n",
      "train loss:0.27016374717800384\n",
      "train loss:0.20326777533882573\n",
      "train loss:0.1451047358849104\n",
      "train loss:0.14379220583251892\n",
      "train loss:0.3837245827735555\n",
      "train loss:0.3048579303018274\n",
      "train loss:0.20741275532994255\n",
      "train loss:0.39395802521523016\n",
      "train loss:0.28038530856697774\n",
      "train loss:0.14774820465949084\n",
      "train loss:0.24435463829949977\n",
      "train loss:0.23437364611200506\n",
      "train loss:0.15409802400893327\n",
      "train loss:0.2001973416101881\n",
      "train loss:0.40232203001572686\n",
      "train loss:0.2939377900426606\n",
      "train loss:0.19926319636902712\n",
      "train loss:0.1693675323975072\n",
      "train loss:0.17146837301992585\n",
      "train loss:0.1901803352180539\n",
      "train loss:0.25249052841227526\n",
      "train loss:0.27611620545102666\n",
      "train loss:0.2740364504216423\n",
      "train loss:0.25077255785738806\n",
      "train loss:0.2941874334282828\n",
      "train loss:0.20067319356150531\n",
      "train loss:0.2320206739319519\n",
      "train loss:0.14433330876596406\n",
      "train loss:0.24956650507485756\n",
      "train loss:0.27230827705351035\n",
      "train loss:0.13830635186046053\n",
      "train loss:0.28637294658148454\n",
      "train loss:0.2963899021198918\n",
      "train loss:0.35735395615919807\n",
      "train loss:0.25443822707098496\n",
      "train loss:0.4293059041287085\n",
      "train loss:0.2575084839731642\n",
      "train loss:0.25485035891717056\n",
      "train loss:0.21582406098301338\n",
      "train loss:0.24151360965639226\n",
      "train loss:0.1658573913198835\n",
      "train loss:0.14714450768881518\n",
      "train loss:0.24049792535452696\n",
      "train loss:0.3096403641355719\n",
      "train loss:0.15751996448616934\n",
      "train loss:0.2157507299155321\n",
      "train loss:0.16734323479148763\n",
      "train loss:0.16737072103471884\n",
      "train loss:0.2962935210041294\n",
      "train loss:0.21098523584607357\n",
      "train loss:0.21703706710593867\n",
      "train loss:0.20088705455710468\n",
      "train loss:0.12084150850761897\n",
      "train loss:0.1327877922102933\n",
      "train loss:0.18033092511512414\n",
      "train loss:0.09872125049335984\n",
      "train loss:0.18481984674522722\n",
      "train loss:0.2539497938328992\n",
      "train loss:0.36217906788483567\n",
      "train loss:0.27648584440319923\n",
      "train loss:0.3877613761082631\n",
      "train loss:0.16616415885636093\n",
      "train loss:0.29043056425117547\n",
      "train loss:0.2462067445947541\n",
      "train loss:0.1403483251741818\n",
      "train loss:0.1659301855971945\n",
      "train loss:0.2546738164338211\n",
      "train loss:0.18269353353645432\n",
      "train loss:0.22711691820464977\n",
      "train loss:0.20358816933538\n",
      "train loss:0.21504558970271528\n",
      "train loss:0.20858931091816704\n",
      "train loss:0.39431062260907035\n",
      "train loss:0.3113101710273761\n",
      "train loss:0.2089659234147794\n",
      "train loss:0.16777646452663306\n",
      "train loss:0.2693900004197865\n",
      "train loss:0.26372947401177105\n",
      "train loss:0.1725284612405691\n",
      "train loss:0.4113965466139836\n",
      "train loss:0.2874530517866845\n",
      "train loss:0.19145467295533\n",
      "train loss:0.10968938618448197\n",
      "train loss:0.24049829966656613\n",
      "train loss:0.1484653784560059\n",
      "train loss:0.2827939724010037\n",
      "train loss:0.11790764057967457\n",
      "train loss:0.1621550352334228\n",
      "train loss:0.16652332335937056\n",
      "train loss:0.13029053351545083\n",
      "train loss:0.203720005425753\n",
      "train loss:0.29198380542158564\n",
      "train loss:0.15638291829859294\n",
      "train loss:0.1516412291901015\n",
      "train loss:0.28943238738312155\n",
      "train loss:0.19999769965956524\n",
      "train loss:0.32262917608888203\n",
      "train loss:0.27695049633690505\n",
      "train loss:0.16617036732400717\n",
      "train loss:0.15078606922468998\n",
      "train loss:0.2399306781151293\n",
      "train loss:0.19770784986103038\n",
      "train loss:0.284673964957318\n",
      "train loss:0.268163440974687\n",
      "train loss:0.21526142534790987\n",
      "train loss:0.2035152928805015\n",
      "train loss:0.17749410250817343\n",
      "train loss:0.21402820337459189\n",
      "train loss:0.2993329978904163\n",
      "train loss:0.26065354583029887\n",
      "train loss:0.20714971031760476\n",
      "train loss:0.2549352601135629\n",
      "train loss:0.26213532581498994\n",
      "train loss:0.19985009465092382\n",
      "train loss:0.21881486814346968\n",
      "train loss:0.22292923773227133\n",
      "train loss:0.27829798388561056\n",
      "train loss:0.2870641729015546\n",
      "train loss:0.21787151686729597\n",
      "train loss:0.23721428762868288\n",
      "train loss:0.30010057053331374\n",
      "train loss:0.15517825702138516\n",
      "train loss:0.274779135275114\n",
      "train loss:0.28035031918902414\n",
      "train loss:0.2881662069860704\n",
      "train loss:0.13530581257207203\n",
      "train loss:0.19436577619919437\n",
      "train loss:0.20967890465453176\n",
      "train loss:0.14932856164473868\n",
      "train loss:0.2058496522175108\n",
      "train loss:0.22865860463418175\n",
      "train loss:0.26497183712707273\n",
      "train loss:0.21431722698738312\n",
      "train loss:0.23146198532604767\n",
      "train loss:0.18141670864151088\n",
      "train loss:0.28528625591053464\n",
      "train loss:0.23617065242992002\n",
      "train loss:0.17157118787434253\n",
      "train loss:0.2435934684031366\n",
      "train loss:0.33646098456095835\n",
      "train loss:0.2211073784930799\n",
      "train loss:0.11506041663781748\n",
      "train loss:0.12404365930270206\n",
      "train loss:0.2740658752884106\n",
      "train loss:0.22077985152377275\n",
      "train loss:0.09987639253826872\n",
      "train loss:0.19620850832165143\n",
      "train loss:0.20042376286935273\n",
      "train loss:0.24798452909066332\n",
      "train loss:0.12093303901460778\n",
      "train loss:0.2893178233440272\n",
      "train loss:0.1726737486534775\n",
      "train loss:0.20650802307643978\n",
      "train loss:0.15784928779840102\n",
      "train loss:0.2749864466098833\n",
      "train loss:0.23707982126038712\n",
      "train loss:0.20337821739652423\n",
      "train loss:0.21241667755655796\n",
      "train loss:0.18421914163975045\n",
      "train loss:0.2246505116660721\n",
      "train loss:0.10666804389641936\n",
      "train loss:0.2203330373554333\n",
      "train loss:0.4086176660634964\n",
      "train loss:0.2431846971877641\n",
      "train loss:0.23909637438473427\n",
      "train loss:0.18949749369102423\n",
      "train loss:0.16748600853248446\n",
      "train loss:0.24708973348685898\n",
      "train loss:0.17184473051964522\n",
      "train loss:0.2081219053155364\n",
      "train loss:0.18657878759496532\n",
      "train loss:0.2016887074920154\n",
      "train loss:0.2926855369596091\n",
      "train loss:0.09897121100306261\n",
      "train loss:0.22577655693841656\n",
      "train loss:0.22676848940641087\n",
      "train loss:0.26032289616032384\n",
      "train loss:0.2045759344926129\n",
      "train loss:0.19109914987461607\n",
      "train loss:0.2438557344331659\n",
      "train loss:0.17271182516613093\n",
      "train loss:0.16629553977805106\n",
      "train loss:0.20229954130416603\n",
      "train loss:0.3802764547027613\n",
      "train loss:0.19841664271305054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.25685399808177295\n",
      "train loss:0.1314636605949328\n",
      "train loss:0.30222100121144846\n",
      "train loss:0.19709574516261952\n",
      "train loss:0.25200505961606273\n",
      "train loss:0.13500387489358134\n",
      "train loss:0.34620830188510965\n",
      "train loss:0.42581613926674455\n",
      "train loss:0.18885336564644922\n",
      "train loss:0.10340434774233413\n",
      "train loss:0.23752417441508583\n",
      "train loss:0.23214549488468872\n",
      "train loss:0.1524293996444895\n",
      "train loss:0.17164672976631223\n",
      "train loss:0.21070167212433547\n",
      "train loss:0.3051027994155839\n",
      "train loss:0.1156682279027951\n",
      "train loss:0.255770777445027\n",
      "train loss:0.18509690163127068\n",
      "train loss:0.292409343365058\n",
      "train loss:0.16211125248756567\n",
      "train loss:0.33712174043717447\n",
      "train loss:0.14615426569783227\n",
      "train loss:0.13625532715295516\n",
      "train loss:0.13591302357685933\n",
      "train loss:0.1317059741337564\n",
      "train loss:0.24905654074641037\n",
      "train loss:0.14296019310529995\n",
      "train loss:0.15459900245991867\n",
      "train loss:0.2939945654175972\n",
      "train loss:0.2565933114586578\n",
      "train loss:0.24218924791007923\n",
      "train loss:0.17713859989633066\n",
      "train loss:0.19284154757989103\n",
      "train loss:0.2695089321281021\n",
      "train loss:0.13442080369471252\n",
      "train loss:0.22494796378383236\n",
      "train loss:0.17587616910777182\n",
      "train loss:0.2042666958689881\n",
      "train loss:0.2373207588229121\n",
      "train loss:0.20766162189020743\n",
      "train loss:0.17266089313712585\n",
      "train loss:0.2403173735286214\n",
      "train loss:0.2491715202258551\n",
      "train loss:0.1295888017917722\n",
      "train loss:0.1337458514886959\n",
      "train loss:0.31243954259459544\n",
      "train loss:0.20842254888205544\n",
      "train loss:0.17355388338436928\n",
      "train loss:0.23384147998654167\n",
      "train loss:0.1753362695460912\n",
      "train loss:0.23033146972446258\n",
      "train loss:0.2742396478990654\n",
      "train loss:0.14640626944790122\n",
      "train loss:0.18127447382091963\n",
      "train loss:0.34259614394783305\n",
      "train loss:0.26736457654991347\n",
      "train loss:0.1985588204312252\n",
      "train loss:0.2808519023537832\n",
      "train loss:0.13597035733854085\n",
      "train loss:0.34119724875978164\n",
      "train loss:0.14113927186198166\n",
      "train loss:0.29543558750058285\n",
      "train loss:0.34408242429639707\n",
      "train loss:0.13273384870232094\n",
      "train loss:0.16633276814631995\n",
      "train loss:0.18991341397746564\n",
      "train loss:0.22035821280120263\n",
      "train loss:0.1562141359611161\n",
      "train loss:0.2097442352275095\n",
      "train loss:0.16792640834705877\n",
      "train loss:0.19284417482925328\n",
      "train loss:0.21663523553234687\n",
      "train loss:0.15921895290965346\n",
      "train loss:0.23600188937257754\n",
      "train loss:0.19616741231263202\n",
      "train loss:0.21829521392190154\n",
      "train loss:0.2868250879757623\n",
      "train loss:0.22412130840003341\n",
      "train loss:0.35511435050933604\n",
      "train loss:0.2947526748674315\n",
      "train loss:0.13309417365354428\n",
      "train loss:0.20487053745509112\n",
      "train loss:0.14906911954558275\n",
      "train loss:0.2101679595117824\n",
      "train loss:0.2817963911029111\n",
      "train loss:0.21180996776158595\n",
      "train loss:0.17081808413729582\n",
      "train loss:0.09010864929923149\n",
      "train loss:0.22223796756663092\n",
      "train loss:0.15862235337670058\n",
      "train loss:0.16814626732034132\n",
      "train loss:0.1569110553414874\n",
      "train loss:0.25002600747344045\n",
      "train loss:0.17547316430030524\n",
      "train loss:0.2754827972358236\n",
      "train loss:0.14776761916168776\n",
      "train loss:0.13348525291471175\n",
      "train loss:0.09988644624187452\n",
      "train loss:0.2081443752413704\n",
      "train loss:0.26520297666687775\n",
      "train loss:0.27240989853212777\n",
      "train loss:0.196291041133404\n",
      "train loss:0.1567371381719391\n",
      "train loss:0.19897617929973296\n",
      "train loss:0.2331324690147497\n",
      "train loss:0.28043561318330995\n",
      "train loss:0.170097413211282\n",
      "train loss:0.23658231878205363\n",
      "train loss:0.3035132395154494\n",
      "train loss:0.23148667864399985\n",
      "train loss:0.24722193281156163\n",
      "train loss:0.15695453210857968\n",
      "train loss:0.13853631485847717\n",
      "train loss:0.3380941360039852\n",
      "train loss:0.14421708400699496\n",
      "train loss:0.12680915776128232\n",
      "train loss:0.2798666654196923\n",
      "train loss:0.39930828811557034\n",
      "train loss:0.16963771792698895\n",
      "train loss:0.16601059814987984\n",
      "train loss:0.17688833311109026\n",
      "train loss:0.3858616257343766\n",
      "train loss:0.19081486867054587\n",
      "train loss:0.29873022692777856\n",
      "train loss:0.2090843025425758\n",
      "train loss:0.19772058199892928\n",
      "train loss:0.23209273574486922\n",
      "train loss:0.1377506922855185\n",
      "train loss:0.13495905614515594\n",
      "train loss:0.19817662345944118\n",
      "train loss:0.1862298802953548\n",
      "train loss:0.16061689822992573\n",
      "train loss:0.21654211545726695\n",
      "train loss:0.17399516677829802\n",
      "train loss:0.1587399963242816\n",
      "train loss:0.3346462752533542\n",
      "train loss:0.18479437534346332\n",
      "train loss:0.2440466546259854\n",
      "train loss:0.23202235469358293\n",
      "train loss:0.19346584264670758\n",
      "train loss:0.21130331376204206\n",
      "train loss:0.3973147038250515\n",
      "train loss:0.20906391885072273\n",
      "train loss:0.16514181311808296\n",
      "train loss:0.19849655829711702\n",
      "train loss:0.2957347436940526\n",
      "train loss:0.12745655444567602\n",
      "train loss:0.17745802696989826\n",
      "train loss:0.3742377978875753\n",
      "train loss:0.26078126326803996\n",
      "train loss:0.1726556748115946\n",
      "train loss:0.26654645713502517\n",
      "train loss:0.2575326163362627\n",
      "train loss:0.3514109211797249\n",
      "train loss:0.20700939198419044\n",
      "train loss:0.16905706432124187\n",
      "train loss:0.1574003694737837\n",
      "train loss:0.17133462249168915\n",
      "train loss:0.11306626246566881\n",
      "train loss:0.2729901236228761\n",
      "train loss:0.1062580225851706\n",
      "train loss:0.21708117777275382\n",
      "train loss:0.1519965908277565\n",
      "train loss:0.2044875870395913\n",
      "train loss:0.1922589869113148\n",
      "train loss:0.24126726585418276\n",
      "train loss:0.19256306467108472\n",
      "train loss:0.17177993977536246\n",
      "train loss:0.21939589299013093\n",
      "train loss:0.18974658664468433\n",
      "train loss:0.2683694382165004\n",
      "train loss:0.28823496677616695\n",
      "train loss:0.12839464165245915\n",
      "train loss:0.3058555489201827\n",
      "train loss:0.1662888472577313\n",
      "train loss:0.10096234992613441\n",
      "train loss:0.16867149900100536\n",
      "=== epoch:4, train acc:0.934, test acc:0.918 ===, time:  56.381081342697144\n",
      "train loss:0.2648093260235111\n",
      "train loss:0.2530153026500325\n",
      "train loss:0.18058254369279156\n",
      "train loss:0.2105058186446856\n",
      "train loss:0.23951348979501727\n",
      "train loss:0.16434937015561982\n",
      "train loss:0.172871309335342\n",
      "train loss:0.23061705929335413\n",
      "train loss:0.09740005817306473\n",
      "train loss:0.2061672418932153\n",
      "train loss:0.13993981099911992\n",
      "train loss:0.23207847036539836\n",
      "train loss:0.135206622539006\n",
      "train loss:0.15119947489587016\n",
      "train loss:0.23467748132105018\n",
      "train loss:0.1966283532439892\n",
      "train loss:0.14176986780970555\n",
      "train loss:0.25042258422760105\n",
      "train loss:0.11137954046066258\n",
      "train loss:0.13428575532131126\n",
      "train loss:0.23802126658465445\n",
      "train loss:0.21223586897980623\n",
      "train loss:0.16645689260970775\n",
      "train loss:0.20455270407630508\n",
      "train loss:0.16834519731549213\n",
      "train loss:0.18896996390615126\n",
      "train loss:0.22623668692000293\n",
      "train loss:0.12188168135949456\n",
      "train loss:0.13032782898121645\n",
      "train loss:0.3043487973556194\n",
      "train loss:0.19220541431771324\n",
      "train loss:0.2703636120168052\n",
      "train loss:0.11463212623700554\n",
      "train loss:0.10534720957048388\n",
      "train loss:0.16204562214319046\n",
      "train loss:0.21079872571662558\n",
      "train loss:0.11919737159704762\n",
      "train loss:0.221817187960116\n",
      "train loss:0.30484257983150426\n",
      "train loss:0.15895475761238406\n",
      "train loss:0.19446911133951622\n",
      "train loss:0.19273293836368527\n",
      "train loss:0.170026800575981\n",
      "train loss:0.12909378050790948\n",
      "train loss:0.1652028777107114\n",
      "train loss:0.11531302845852806\n",
      "train loss:0.11852956489710204\n",
      "train loss:0.1291554858768632\n",
      "train loss:0.2914479156203498\n",
      "train loss:0.14171355047041154\n",
      "train loss:0.1903213594981109\n",
      "train loss:0.2578009258730777\n",
      "train loss:0.2075911214502606\n",
      "train loss:0.2572919189836952\n",
      "train loss:0.22856468389796214\n",
      "train loss:0.1597632077255006\n",
      "train loss:0.2597153502711716\n",
      "train loss:0.14714958705877598\n",
      "train loss:0.16726034861398045\n",
      "train loss:0.23206939451717115\n",
      "train loss:0.1968848551437724\n",
      "train loss:0.2568598805165859\n",
      "train loss:0.4077176548085961\n",
      "train loss:0.1264816655544063\n",
      "train loss:0.19623774173801004\n",
      "train loss:0.12721740355237882\n",
      "train loss:0.20254233133876987\n",
      "train loss:0.17327311494883277\n",
      "train loss:0.15896280619010514\n",
      "train loss:0.1251603308404796\n",
      "train loss:0.19361774142873903\n",
      "train loss:0.1871087308593911\n",
      "train loss:0.20907627925194633\n",
      "train loss:0.322468863878902\n",
      "train loss:0.1724863036883471\n",
      "train loss:0.20759182144903188\n",
      "train loss:0.18102167582851209\n",
      "train loss:0.19306794945819195\n",
      "train loss:0.17751945347287093\n",
      "train loss:0.15059649978622053\n",
      "train loss:0.2870065958209907\n",
      "train loss:0.14570189942843365\n",
      "train loss:0.2230783356448188\n",
      "train loss:0.08518826816611537\n",
      "train loss:0.18606010082848837\n",
      "train loss:0.1474954102228392\n",
      "train loss:0.294459120116972\n",
      "train loss:0.13532626933941386\n",
      "train loss:0.0997923452714991\n",
      "train loss:0.1560435941355984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.19867757064144986\n",
      "train loss:0.2553839485000908\n",
      "train loss:0.17024506305665937\n",
      "train loss:0.16691845534062655\n",
      "train loss:0.23783687004140663\n",
      "train loss:0.08739518544920871\n",
      "train loss:0.16761303021883525\n",
      "train loss:0.23418409243106436\n",
      "train loss:0.1806105377401613\n",
      "train loss:0.27870277215883044\n",
      "train loss:0.3431803449220756\n",
      "train loss:0.213295774826026\n",
      "train loss:0.15448883297727592\n",
      "train loss:0.1296830448344905\n",
      "train loss:0.1940046413937363\n",
      "train loss:0.1705738123975041\n",
      "train loss:0.14310797756633623\n",
      "train loss:0.23540672222908007\n",
      "train loss:0.18515327334903575\n",
      "train loss:0.23365950254230064\n",
      "train loss:0.20570223483685196\n",
      "train loss:0.20749528811180135\n",
      "train loss:0.10556305832470882\n",
      "train loss:0.13612714691307856\n",
      "train loss:0.33293774596479525\n",
      "train loss:0.1953964092635109\n",
      "train loss:0.14380141712646247\n",
      "train loss:0.08865470240923223\n",
      "train loss:0.18171227022248332\n",
      "train loss:0.17620353106389913\n",
      "train loss:0.17946724675361436\n",
      "train loss:0.34344947928687136\n",
      "train loss:0.13039946399659572\n",
      "train loss:0.24192296044341863\n",
      "train loss:0.27887360231226865\n",
      "train loss:0.2741040677325682\n",
      "train loss:0.1656525551068765\n",
      "train loss:0.26038189076290774\n",
      "train loss:0.1812963887088611\n",
      "train loss:0.15604070760671088\n",
      "train loss:0.31100444056224985\n",
      "train loss:0.12541847321553928\n",
      "train loss:0.14252111129325923\n",
      "train loss:0.2742644207955418\n",
      "train loss:0.2549310321915294\n",
      "train loss:0.1772015857682049\n",
      "train loss:0.16712215323189458\n",
      "train loss:0.3123777821708716\n",
      "train loss:0.08097682293042506\n",
      "train loss:0.1862590923988529\n",
      "train loss:0.2364886152719408\n",
      "train loss:0.18643999455075583\n",
      "train loss:0.17916832397801735\n",
      "train loss:0.2391360423762377\n",
      "train loss:0.1572600080250655\n",
      "train loss:0.14548083367320502\n",
      "train loss:0.3338894560096026\n",
      "train loss:0.3338814633155647\n",
      "train loss:0.10643431323188429\n",
      "train loss:0.07324568342240685\n",
      "train loss:0.23841986499515094\n",
      "train loss:0.11595319184820614\n",
      "train loss:0.09702552102229392\n",
      "train loss:0.19837670496493257\n",
      "train loss:0.14796325108167033\n",
      "train loss:0.18890129651923174\n",
      "train loss:0.20348037648908288\n",
      "train loss:0.2470822229945977\n",
      "train loss:0.13916045486685164\n",
      "train loss:0.23547246684742817\n",
      "train loss:0.19313416691013935\n",
      "train loss:0.2330691739870626\n",
      "train loss:0.32752271334076816\n",
      "train loss:0.17629123330526864\n",
      "train loss:0.10641175128290474\n",
      "train loss:0.17667652410191179\n",
      "train loss:0.14111808298554462\n",
      "train loss:0.1952883026743014\n",
      "train loss:0.13797824134377595\n",
      "train loss:0.15316003979412707\n",
      "train loss:0.2715721799063815\n",
      "train loss:0.09406911144459765\n",
      "train loss:0.12378585577283475\n",
      "train loss:0.13232022652926553\n",
      "train loss:0.15549542751826004\n",
      "train loss:0.18086052495588117\n",
      "train loss:0.1701358043779685\n",
      "train loss:0.2611668344645041\n",
      "train loss:0.07645483974590733\n",
      "train loss:0.25573209812640235\n",
      "train loss:0.20667679224320978\n",
      "train loss:0.08316685098514917\n",
      "train loss:0.21745256540777294\n",
      "train loss:0.28271608418069893\n",
      "train loss:0.09945687534527886\n",
      "train loss:0.19397677852990217\n",
      "train loss:0.12499728608395955\n",
      "train loss:0.31305623459920545\n",
      "train loss:0.17601586558971807\n",
      "train loss:0.1497273332526799\n",
      "train loss:0.23827281352309243\n",
      "train loss:0.22917995662188023\n",
      "train loss:0.17724057507717003\n",
      "train loss:0.15131427215463977\n",
      "train loss:0.2710654557103455\n",
      "train loss:0.27248700388058855\n",
      "train loss:0.20484282106485074\n",
      "train loss:0.22552635345332697\n",
      "train loss:0.15646687010059518\n",
      "train loss:0.17929983334319616\n",
      "train loss:0.16698556812886955\n",
      "train loss:0.1955595844092125\n",
      "train loss:0.2820551183934409\n",
      "train loss:0.10560611241342956\n",
      "train loss:0.2378471400564298\n",
      "train loss:0.1413452520708466\n",
      "train loss:0.15592381777781805\n",
      "train loss:0.258166613458543\n",
      "train loss:0.21352312688401412\n",
      "train loss:0.2609594305426524\n",
      "train loss:0.11959029934310385\n",
      "train loss:0.1630136750624357\n",
      "train loss:0.1061397160740376\n",
      "train loss:0.1188009326980053\n",
      "train loss:0.2127393939734647\n",
      "train loss:0.2392936914619608\n",
      "train loss:0.12095063592328835\n",
      "train loss:0.18367684419397196\n",
      "train loss:0.15069415154460178\n",
      "train loss:0.196583991373031\n",
      "train loss:0.2067711695666759\n",
      "train loss:0.14494513425840894\n",
      "train loss:0.18940140281371465\n",
      "train loss:0.15871971011746752\n",
      "train loss:0.12512810622932216\n",
      "train loss:0.19261671084877272\n",
      "train loss:0.1269265310442723\n",
      "train loss:0.1721988421486106\n",
      "train loss:0.24042505978367984\n",
      "train loss:0.23437509966968204\n",
      "train loss:0.21006353761428617\n",
      "train loss:0.19944451950511038\n",
      "train loss:0.14971309470167438\n",
      "train loss:0.21845042770997075\n",
      "train loss:0.23694240423939056\n",
      "train loss:0.44905565940498315\n",
      "train loss:0.27806488526704\n",
      "train loss:0.1068723972707844\n",
      "train loss:0.08460665751405907\n",
      "train loss:0.26344021321821964\n",
      "train loss:0.07758032896667827\n",
      "train loss:0.17225995744216455\n",
      "train loss:0.1696315056021293\n",
      "train loss:0.23309163573144634\n",
      "train loss:0.13496595117141422\n",
      "train loss:0.12112203157242231\n",
      "train loss:0.15849121313945688\n",
      "train loss:0.18885536447160284\n",
      "train loss:0.26622119696001734\n",
      "train loss:0.13218555999441287\n",
      "train loss:0.262504167842431\n",
      "train loss:0.09506334737683\n",
      "train loss:0.18096243240843385\n",
      "train loss:0.1976641723307504\n",
      "train loss:0.3191151228547978\n",
      "train loss:0.13044674063085301\n",
      "train loss:0.16917554764187254\n",
      "train loss:0.22635474176392414\n",
      "train loss:0.1811237754462238\n",
      "train loss:0.06705332149375826\n",
      "train loss:0.21146435120813295\n",
      "train loss:0.22760268193328098\n",
      "train loss:0.12100956829282185\n",
      "train loss:0.2292321632681004\n",
      "train loss:0.2065347540603241\n",
      "train loss:0.18185222182140692\n",
      "train loss:0.23815520428772052\n",
      "train loss:0.20254887636158903\n",
      "train loss:0.13907916885721752\n",
      "train loss:0.19531557683992326\n",
      "train loss:0.12500936685198621\n",
      "train loss:0.11296544127164836\n",
      "train loss:0.23615587338341856\n",
      "train loss:0.18812146299124283\n",
      "train loss:0.2088900739612033\n",
      "train loss:0.20913192516436493\n",
      "train loss:0.20505073254368658\n",
      "train loss:0.23750899466937017\n",
      "train loss:0.10962002523355631\n",
      "train loss:0.21094569566821508\n",
      "train loss:0.2230307468435843\n",
      "train loss:0.13382817372018757\n",
      "train loss:0.1171869442819125\n",
      "train loss:0.144469375072199\n",
      "train loss:0.3102884096555521\n",
      "train loss:0.1759734635544826\n",
      "train loss:0.1389517274557629\n",
      "train loss:0.11241410315079384\n",
      "train loss:0.27511800828413846\n",
      "train loss:0.11398135014042435\n",
      "train loss:0.1951729590904165\n",
      "train loss:0.1390440111439872\n",
      "train loss:0.334442261597681\n",
      "train loss:0.20692223829057613\n",
      "train loss:0.20964865299234314\n",
      "train loss:0.122599402168738\n",
      "train loss:0.17358989864785973\n",
      "train loss:0.19781733449245434\n",
      "train loss:0.25279507649656285\n",
      "train loss:0.12622404810097831\n",
      "train loss:0.14015711212542611\n",
      "train loss:0.11397233465465936\n",
      "train loss:0.2638075992264487\n",
      "train loss:0.15761418615205788\n",
      "train loss:0.17601396625972623\n",
      "train loss:0.2403659113149149\n",
      "train loss:0.22699356820565852\n",
      "train loss:0.20624576749672918\n",
      "train loss:0.16638541996024592\n",
      "train loss:0.2136866560141566\n",
      "train loss:0.15982722257308826\n",
      "train loss:0.2320993782589803\n",
      "train loss:0.1859874619704587\n",
      "train loss:0.2079979287360629\n",
      "train loss:0.17639369864491145\n",
      "train loss:0.1250156385491213\n",
      "train loss:0.2760135156992172\n",
      "train loss:0.20945450969321416\n",
      "train loss:0.15460668127014154\n",
      "train loss:0.11315919043884072\n",
      "train loss:0.1558603367516421\n",
      "train loss:0.15416894661885133\n",
      "train loss:0.17396422507379616\n",
      "train loss:0.07970682077521621\n",
      "train loss:0.11763781153902743\n",
      "train loss:0.1874389642305656\n",
      "train loss:0.21363891490375317\n",
      "train loss:0.22390798360133515\n",
      "train loss:0.2077970571872647\n",
      "train loss:0.2021174475614151\n",
      "train loss:0.2237876692346863\n",
      "train loss:0.3711808567292898\n",
      "train loss:0.12635853136696376\n",
      "train loss:0.26247029518903553\n",
      "train loss:0.1311394769148383\n",
      "train loss:0.34807555437173304\n",
      "train loss:0.08515833568935002\n",
      "train loss:0.1808006694408351\n",
      "train loss:0.1898026490737001\n",
      "train loss:0.3332723050539451\n",
      "train loss:0.2011976516600098\n",
      "train loss:0.2210288107513489\n",
      "train loss:0.274019930137842\n",
      "train loss:0.054310726769746485\n",
      "train loss:0.14560559194447872\n",
      "train loss:0.13838834725715166\n",
      "train loss:0.17589653842809344\n",
      "train loss:0.12007773756348353\n",
      "train loss:0.22270113236557304\n",
      "train loss:0.1134262678798537\n",
      "train loss:0.1827581162284266\n",
      "train loss:0.1456516925097019\n",
      "train loss:0.162738977741833\n",
      "train loss:0.2693630530454253\n",
      "train loss:0.1806871277882899\n",
      "train loss:0.11012298106009766\n",
      "train loss:0.11941675708176744\n",
      "train loss:0.13694992813568865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07869448593723394\n",
      "train loss:0.2376000035069347\n",
      "train loss:0.16687300805263428\n",
      "train loss:0.15713931008257384\n",
      "train loss:0.17860978536918048\n",
      "train loss:0.16342708750692217\n",
      "train loss:0.12629708077096732\n",
      "train loss:0.21286524476372826\n",
      "train loss:0.21959262505054433\n",
      "train loss:0.20756337910149653\n",
      "train loss:0.15084600039493554\n",
      "train loss:0.15317342188678013\n",
      "train loss:0.11501224969507177\n",
      "train loss:0.2099506246113296\n",
      "train loss:0.15431033766203658\n",
      "train loss:0.24082272067315763\n",
      "train loss:0.25084395075901594\n",
      "train loss:0.1726534452828312\n",
      "train loss:0.16581893296508737\n",
      "train loss:0.24898950828847002\n",
      "train loss:0.19591852547540728\n",
      "train loss:0.13245715127418536\n",
      "train loss:0.23053524914176346\n",
      "train loss:0.18040783432155189\n",
      "train loss:0.14661222268407742\n",
      "train loss:0.16691250432938368\n",
      "train loss:0.11419890331277945\n",
      "train loss:0.19718979483558757\n",
      "train loss:0.17050848543218694\n",
      "train loss:0.1698714926273787\n",
      "train loss:0.2421640728994594\n",
      "train loss:0.07025267236066676\n",
      "train loss:0.10496603875674004\n",
      "train loss:0.10439743251320976\n",
      "train loss:0.19456816887594428\n",
      "train loss:0.22460449302277927\n",
      "train loss:0.0966177494034058\n",
      "train loss:0.13674113740064586\n",
      "train loss:0.1472957443194566\n",
      "train loss:0.1717353774808179\n",
      "train loss:0.09383519978562357\n",
      "train loss:0.09034271928103678\n",
      "train loss:0.118169859449692\n",
      "train loss:0.18812323428366193\n",
      "train loss:0.16123512556133102\n",
      "train loss:0.10094156825208983\n",
      "train loss:0.2089371198508309\n",
      "train loss:0.07887338698072943\n",
      "train loss:0.17067421101321045\n",
      "train loss:0.10634516304108421\n",
      "train loss:0.15935913259841747\n",
      "train loss:0.13436396393480532\n",
      "train loss:0.14677316164165163\n",
      "train loss:0.15191912802369434\n",
      "train loss:0.0932261447634663\n",
      "train loss:0.2416379527592861\n",
      "train loss:0.18322837328080901\n",
      "train loss:0.16543841694702976\n",
      "train loss:0.18775678025115336\n",
      "train loss:0.19906843499371657\n",
      "train loss:0.20266683310314174\n",
      "train loss:0.08386504921472762\n",
      "train loss:0.08527736430194204\n",
      "train loss:0.2168689879668616\n",
      "train loss:0.21471444140003582\n",
      "train loss:0.3796489060263626\n",
      "train loss:0.22592225818491524\n",
      "train loss:0.15826641582847895\n",
      "train loss:0.184082700890922\n",
      "train loss:0.14708880098745303\n",
      "train loss:0.1283738103405609\n",
      "train loss:0.16089937053146383\n",
      "train loss:0.13555826635077478\n",
      "train loss:0.11014928292190525\n",
      "train loss:0.11795193907278527\n",
      "train loss:0.24324986610909072\n",
      "train loss:0.18570126018444066\n",
      "train loss:0.38183155867915575\n",
      "train loss:0.19478727723578454\n",
      "train loss:0.33501798860457876\n",
      "train loss:0.12073728154874278\n",
      "train loss:0.26454581491244883\n",
      "train loss:0.07938654361141419\n",
      "train loss:0.15411522787192294\n",
      "train loss:0.0937171312221071\n",
      "train loss:0.14866041488854206\n",
      "train loss:0.08874819929586435\n",
      "train loss:0.2150693544031509\n",
      "train loss:0.11851231654186481\n",
      "train loss:0.1435332607768408\n",
      "train loss:0.17024265503637584\n",
      "train loss:0.2434222198314697\n",
      "train loss:0.16469469751593938\n",
      "train loss:0.1868629763312023\n",
      "train loss:0.2740947364213261\n",
      "train loss:0.0680520130437345\n",
      "train loss:0.08880945295569695\n",
      "train loss:0.18874064016574624\n",
      "train loss:0.23711445236843853\n",
      "train loss:0.12541887640319582\n",
      "train loss:0.25248961288887783\n",
      "train loss:0.2577013465098593\n",
      "train loss:0.17007218512390207\n",
      "train loss:0.20111128757854968\n",
      "train loss:0.21425668491151373\n",
      "train loss:0.05102100349963137\n",
      "train loss:0.11582061769175586\n",
      "train loss:0.18219954850578612\n",
      "train loss:0.1803584092249289\n",
      "train loss:0.09860035039976164\n",
      "train loss:0.12170657261948117\n",
      "train loss:0.12129155002044759\n",
      "train loss:0.23079738886655637\n",
      "train loss:0.11112421014676149\n",
      "train loss:0.18537294786331213\n",
      "train loss:0.226797089132561\n",
      "train loss:0.14863031891261325\n",
      "train loss:0.2849882325182443\n",
      "train loss:0.18921096900060977\n",
      "train loss:0.17699826726138712\n",
      "train loss:0.05993846292393796\n",
      "train loss:0.15240433918552243\n",
      "train loss:0.17641571676832302\n",
      "train loss:0.20237333330141616\n",
      "train loss:0.10588570440367595\n",
      "train loss:0.09158078510910345\n",
      "train loss:0.128082338866066\n",
      "train loss:0.11651887692165216\n",
      "train loss:0.15190543655851152\n",
      "train loss:0.21071494589468118\n",
      "train loss:0.15379561343281034\n",
      "train loss:0.2887087350553646\n",
      "train loss:0.1819791761306794\n",
      "train loss:0.07596253205275481\n",
      "train loss:0.30932693907194114\n",
      "train loss:0.1391837431689263\n",
      "train loss:0.2019012655307372\n",
      "train loss:0.22451750091823147\n",
      "train loss:0.12817032397214784\n",
      "train loss:0.1667442032315679\n",
      "train loss:0.2978349519531994\n",
      "train loss:0.23642643324584747\n",
      "train loss:0.1604242592356785\n",
      "train loss:0.0903185592879521\n",
      "train loss:0.18319294368131253\n",
      "train loss:0.20074361685329875\n",
      "train loss:0.17713092426644053\n",
      "train loss:0.16128031360580825\n",
      "train loss:0.18255466164622935\n",
      "train loss:0.057207726574642966\n",
      "train loss:0.18142597296347998\n",
      "train loss:0.244241476780778\n",
      "train loss:0.17469042778311927\n",
      "train loss:0.2006974855275155\n",
      "train loss:0.26273580820665376\n",
      "train loss:0.18028612826744667\n",
      "train loss:0.30880768326895824\n",
      "train loss:0.23513915980282402\n",
      "train loss:0.14664853019942803\n",
      "train loss:0.1361528877470621\n",
      "train loss:0.21804386331697703\n",
      "train loss:0.12616434007742305\n",
      "train loss:0.22755747473309282\n",
      "train loss:0.16574597325661508\n",
      "train loss:0.11508230832494158\n",
      "train loss:0.1893849999821709\n",
      "train loss:0.16939267310901632\n",
      "train loss:0.14922372750862792\n",
      "train loss:0.08709082098742629\n",
      "train loss:0.10671643536763455\n",
      "train loss:0.12452907620580145\n",
      "train loss:0.27147206180903455\n",
      "train loss:0.20443978162208945\n",
      "train loss:0.13575412836384826\n",
      "train loss:0.22858106035658202\n",
      "train loss:0.1646454664830149\n",
      "train loss:0.0946227394450192\n",
      "train loss:0.14887548683553148\n",
      "train loss:0.20872557581111156\n",
      "train loss:0.15363967598883685\n",
      "train loss:0.20450019013645687\n",
      "train loss:0.1799947737452605\n",
      "train loss:0.11718372533829507\n",
      "train loss:0.23452734644831502\n",
      "train loss:0.1531894029130428\n",
      "train loss:0.23174164867675556\n",
      "train loss:0.1429126832358714\n",
      "train loss:0.17405176994769322\n",
      "train loss:0.19129821402591954\n",
      "train loss:0.1744975924507603\n",
      "train loss:0.12453198963251942\n",
      "train loss:0.10554412462031774\n",
      "train loss:0.16072535671636143\n",
      "train loss:0.22752873708601815\n",
      "train loss:0.12093249589152823\n",
      "train loss:0.12447271534971469\n",
      "train loss:0.15461177719443428\n",
      "train loss:0.1149998647623073\n",
      "train loss:0.1931507799547755\n",
      "train loss:0.22364161453980091\n",
      "train loss:0.11053839028280697\n",
      "train loss:0.24314127458051438\n",
      "train loss:0.10125496509555947\n",
      "train loss:0.19159207728449218\n",
      "train loss:0.24415188618717953\n",
      "train loss:0.18211331092370803\n",
      "train loss:0.13860674728433048\n",
      "train loss:0.2128914248817303\n",
      "train loss:0.1464621494971072\n",
      "train loss:0.20994285894768513\n",
      "train loss:0.15740234683028193\n",
      "train loss:0.13091735437562446\n",
      "train loss:0.1924349028033963\n",
      "train loss:0.16162847615819156\n",
      "train loss:0.2585058405432992\n",
      "train loss:0.1925940350047211\n",
      "train loss:0.10530798656367513\n",
      "train loss:0.19369295483572366\n",
      "train loss:0.1960243799976723\n",
      "train loss:0.09750623412110312\n",
      "train loss:0.12412996431087935\n",
      "train loss:0.19438782270783037\n",
      "train loss:0.1426840117641663\n",
      "train loss:0.13108179813005535\n",
      "train loss:0.1411227784588651\n",
      "train loss:0.21571527103656749\n",
      "train loss:0.0905996341079082\n",
      "train loss:0.06564328332695746\n",
      "train loss:0.06335576465368586\n",
      "train loss:0.1398133254982546\n",
      "train loss:0.19664202758161464\n",
      "train loss:0.2127765282666395\n",
      "train loss:0.1489125509135752\n",
      "train loss:0.1916719926485146\n",
      "train loss:0.2278119675152075\n",
      "train loss:0.11214705332120398\n",
      "train loss:0.18535792768831003\n",
      "train loss:0.0817059862145463\n",
      "train loss:0.11524227346186873\n",
      "train loss:0.15110202672213574\n",
      "train loss:0.11255763566893774\n",
      "train loss:0.15890829521273425\n",
      "=== epoch:5, train acc:0.951, test acc:0.938 ===, time:  75.72410249710083\n",
      "train loss:0.20277093995776962\n",
      "train loss:0.0945044232808877\n",
      "train loss:0.0858221123791188\n",
      "train loss:0.1163346434299717\n",
      "train loss:0.28835493919191846\n",
      "train loss:0.19232796495541046\n",
      "train loss:0.17030169506348827\n",
      "train loss:0.08156067839857123\n",
      "train loss:0.10484833203415939\n",
      "train loss:0.21084361954387265\n",
      "train loss:0.15940187922703397\n",
      "train loss:0.10100752996955054\n",
      "train loss:0.18365873615348302\n",
      "train loss:0.14081329041297563\n",
      "train loss:0.13789967908342893\n",
      "train loss:0.14555443443775057\n",
      "train loss:0.0738491917671765\n",
      "train loss:0.09021997901082834\n",
      "train loss:0.17684185342726452\n",
      "train loss:0.23386199894676782\n",
      "train loss:0.1695285261394549\n",
      "train loss:0.048015786392686215\n",
      "train loss:0.15472974789785784\n",
      "train loss:0.1405771624975762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.14971422992516997\n",
      "train loss:0.18850410465863982\n",
      "train loss:0.22016274320030998\n",
      "train loss:0.09878581262089664\n",
      "train loss:0.1632561289583984\n",
      "train loss:0.27496793591270813\n",
      "train loss:0.12501040534091254\n",
      "train loss:0.17992865953225498\n",
      "train loss:0.19899035349650313\n",
      "train loss:0.12511666606209132\n",
      "train loss:0.25619961976872835\n",
      "train loss:0.24858521997183253\n",
      "train loss:0.06689316490124199\n",
      "train loss:0.08686271458036206\n",
      "train loss:0.235528027406209\n",
      "train loss:0.12080488772765209\n",
      "train loss:0.1037722932766657\n",
      "train loss:0.176197701334671\n",
      "train loss:0.12202798461439723\n",
      "train loss:0.13379229004562354\n",
      "train loss:0.1985514944329948\n",
      "train loss:0.1235314397034889\n",
      "train loss:0.1036780627272758\n",
      "train loss:0.2449748597133382\n",
      "train loss:0.1132553364678875\n",
      "train loss:0.18308373922352142\n",
      "train loss:0.1999811329048151\n",
      "train loss:0.18733820402716841\n",
      "train loss:0.12775905478664878\n",
      "train loss:0.10519237131020366\n",
      "train loss:0.13091981026652447\n",
      "train loss:0.25729331667217775\n",
      "train loss:0.17246211623178734\n",
      "train loss:0.13503618786696897\n",
      "train loss:0.19653991767210272\n",
      "train loss:0.14595378797088446\n",
      "train loss:0.20454148523928073\n",
      "train loss:0.21425932365291245\n",
      "train loss:0.12465528995347862\n",
      "train loss:0.12352043947480601\n",
      "train loss:0.06837141610712959\n",
      "train loss:0.21540864099091736\n",
      "train loss:0.07383118323609658\n",
      "train loss:0.12372150010425528\n",
      "train loss:0.17310599788438633\n",
      "train loss:0.20203691436364127\n",
      "train loss:0.15391920213483762\n",
      "train loss:0.15852026643343872\n",
      "train loss:0.2434833923323891\n",
      "train loss:0.2774771449262932\n",
      "train loss:0.1268988386631521\n",
      "train loss:0.20177689040081248\n",
      "train loss:0.10933743384594206\n",
      "train loss:0.13830286779080744\n",
      "train loss:0.180851180129896\n",
      "train loss:0.11679757379476216\n",
      "train loss:0.21248494820833638\n",
      "train loss:0.17349816751775968\n",
      "train loss:0.12257820549508482\n",
      "train loss:0.2299596830509668\n",
      "train loss:0.22404287673022122\n",
      "train loss:0.18865046414298037\n",
      "train loss:0.1818483224046078\n",
      "train loss:0.16409060393043817\n",
      "train loss:0.13431961224730865\n",
      "train loss:0.1330498327182363\n",
      "train loss:0.3963094500801445\n",
      "train loss:0.2438793862568741\n",
      "train loss:0.17198860168723384\n",
      "train loss:0.08620360693836568\n",
      "train loss:0.1725371113867571\n",
      "train loss:0.1344887888901075\n",
      "train loss:0.15940680794936576\n",
      "train loss:0.18642729748075623\n",
      "train loss:0.15184100197456196\n",
      "train loss:0.16340268402476846\n",
      "train loss:0.10327568226485088\n",
      "train loss:0.08413576785544069\n",
      "train loss:0.21624738787947798\n",
      "train loss:0.2937419029274686\n",
      "train loss:0.06772894912094866\n",
      "train loss:0.15763127323872733\n",
      "train loss:0.15375987258674226\n",
      "train loss:0.26295004323861204\n",
      "train loss:0.15897233865340488\n",
      "train loss:0.17941370778926405\n",
      "train loss:0.1242546969461716\n",
      "train loss:0.0917401374285554\n",
      "train loss:0.15742806146592994\n",
      "train loss:0.1689906170945404\n",
      "train loss:0.11863532762402286\n",
      "train loss:0.15999317602900154\n",
      "train loss:0.16253076071662964\n",
      "train loss:0.26125908185372276\n",
      "train loss:0.07733896704792083\n",
      "train loss:0.21293543507894186\n",
      "train loss:0.10056133796872123\n",
      "train loss:0.16647957905636956\n",
      "train loss:0.20807611819029342\n",
      "train loss:0.15351293218325313\n",
      "train loss:0.1797283079147033\n",
      "train loss:0.11068706909680018\n",
      "train loss:0.2690278082521806\n",
      "train loss:0.17602755853691984\n",
      "train loss:0.19463035508489196\n",
      "train loss:0.16049094135378222\n",
      "train loss:0.16041352567842534\n",
      "train loss:0.05079438400613056\n",
      "train loss:0.18864090079197257\n",
      "train loss:0.22945922318028056\n",
      "train loss:0.12196369606873118\n",
      "train loss:0.1775891275412498\n",
      "train loss:0.09042377603193356\n",
      "train loss:0.14432769642380971\n",
      "train loss:0.28484982792276176\n",
      "train loss:0.1481640706494322\n",
      "train loss:0.17637302617913042\n",
      "train loss:0.1601904554686614\n",
      "train loss:0.07712699755725258\n",
      "train loss:0.06434617831223728\n",
      "train loss:0.09727833919360311\n",
      "train loss:0.175004655587845\n",
      "train loss:0.2215219536391068\n",
      "train loss:0.1898828202949395\n",
      "train loss:0.15847357053702582\n",
      "train loss:0.2110713737509027\n",
      "train loss:0.1912675709100746\n",
      "train loss:0.14179495429010475\n",
      "train loss:0.11130674261094954\n",
      "train loss:0.12769318180389164\n",
      "train loss:0.11511770744508393\n",
      "train loss:0.3174476902471751\n",
      "train loss:0.13352547274738075\n",
      "train loss:0.13553828290955403\n",
      "train loss:0.14875391380647845\n",
      "train loss:0.1306145442323098\n",
      "train loss:0.09838661974727579\n",
      "train loss:0.2004875131823752\n",
      "train loss:0.1681846191011674\n",
      "train loss:0.1401353000659922\n",
      "train loss:0.19385517410965933\n",
      "train loss:0.14819522814906197\n",
      "train loss:0.09031405197938185\n",
      "train loss:0.1225945175109805\n",
      "train loss:0.10494083053013932\n",
      "train loss:0.1942978858863815\n",
      "train loss:0.27175573615286247\n",
      "train loss:0.18982655440149357\n",
      "train loss:0.16213583809838691\n",
      "train loss:0.17136004802639712\n",
      "train loss:0.0999849262338513\n",
      "train loss:0.2753346181868307\n",
      "train loss:0.14289654096055324\n",
      "train loss:0.11349845015515263\n",
      "train loss:0.08653668136468104\n",
      "train loss:0.26773004774251297\n",
      "train loss:0.06401482081222319\n",
      "train loss:0.21917579498726855\n",
      "train loss:0.24775145407989918\n",
      "train loss:0.1924686327373805\n",
      "train loss:0.1005114577159298\n",
      "train loss:0.18793483278240816\n",
      "train loss:0.0951347602432046\n",
      "train loss:0.1466559577846063\n",
      "train loss:0.14777234355248134\n",
      "train loss:0.10827695541298767\n",
      "train loss:0.14759772840040514\n",
      "train loss:0.12992918109903184\n",
      "train loss:0.18385387636357858\n",
      "train loss:0.1865182741952639\n",
      "train loss:0.24466446298194264\n",
      "train loss:0.1570782511676801\n",
      "train loss:0.11339169554702234\n",
      "train loss:0.10105069593488397\n",
      "train loss:0.13165791274041758\n",
      "train loss:0.2521550142960266\n",
      "train loss:0.10473197017394485\n",
      "train loss:0.17197515621634465\n",
      "train loss:0.14548600629472083\n",
      "train loss:0.11979488958736166\n",
      "train loss:0.20890387204769856\n",
      "train loss:0.1386925769705008\n",
      "train loss:0.11244433227606578\n",
      "train loss:0.1283287872400406\n",
      "train loss:0.1283611427508632\n",
      "train loss:0.24792790419610922\n",
      "train loss:0.09762186501201014\n",
      "train loss:0.04379654464180078\n",
      "train loss:0.11096734101150721\n",
      "train loss:0.13380224801058294\n",
      "train loss:0.18226956251421383\n",
      "train loss:0.08064020169470593\n",
      "train loss:0.15963288509963913\n",
      "train loss:0.15906913235298703\n",
      "train loss:0.19140880635617236\n",
      "train loss:0.13128510704530347\n",
      "train loss:0.15927039114056757\n",
      "train loss:0.13221659976457592\n",
      "train loss:0.10064548713792078\n",
      "train loss:0.13173167649101333\n",
      "train loss:0.20588435649370834\n",
      "train loss:0.17838783342894138\n",
      "train loss:0.16965904265473178\n",
      "train loss:0.10918149300767813\n",
      "train loss:0.1542619106633514\n",
      "train loss:0.10697231211513956\n",
      "train loss:0.12815523735338738\n",
      "train loss:0.2306248426244727\n",
      "train loss:0.09921515618442742\n",
      "train loss:0.1490653601016278\n",
      "train loss:0.22537682185913213\n",
      "train loss:0.13388645029500532\n",
      "train loss:0.13663098995944659\n",
      "train loss:0.16971083485793925\n",
      "train loss:0.12017070138006042\n",
      "train loss:0.12251872544905758\n",
      "train loss:0.22699125256541186\n",
      "train loss:0.15857982274179347\n",
      "train loss:0.13151011707157487\n",
      "train loss:0.15405843216102705\n",
      "train loss:0.18607404200726851\n",
      "train loss:0.11819430011613244\n",
      "train loss:0.22968277370936352\n",
      "train loss:0.10881098233087155\n",
      "train loss:0.10229962571059982\n",
      "train loss:0.13674073014496646\n",
      "train loss:0.1669122301122327\n",
      "train loss:0.11674120458370935\n",
      "train loss:0.12836823595530084\n",
      "train loss:0.10582726258300955\n",
      "train loss:0.16371494862141112\n",
      "train loss:0.13537530169404105\n",
      "train loss:0.1795206818673977\n",
      "train loss:0.24960280532896995\n",
      "train loss:0.23634403508567378\n",
      "train loss:0.1128334669975062\n",
      "train loss:0.12739206317123947\n",
      "train loss:0.14913671962698977\n",
      "train loss:0.2601653639943009\n",
      "train loss:0.11194824757923583\n",
      "train loss:0.16894629441728995\n",
      "train loss:0.2624708500734439\n",
      "train loss:0.09507881684041383\n",
      "train loss:0.2097153409458984\n",
      "train loss:0.1265105410153495\n",
      "train loss:0.11954424780566555\n",
      "train loss:0.14331428468965168\n",
      "train loss:0.17909120395443023\n",
      "train loss:0.1285890094144281\n",
      "train loss:0.0996747690726509\n",
      "train loss:0.19138210660230776\n",
      "train loss:0.13140824693162484\n",
      "train loss:0.280262541587166\n",
      "train loss:0.08601628161718766\n",
      "train loss:0.1383282253451707\n",
      "train loss:0.09982659180378883\n",
      "train loss:0.13685371597479956\n",
      "train loss:0.17473177942391327\n",
      "train loss:0.08671410447981721\n",
      "train loss:0.21708219545546106\n",
      "train loss:0.2739248665942021\n",
      "train loss:0.15073327236514894\n",
      "train loss:0.10589613090319036\n",
      "train loss:0.2681657662060458\n",
      "train loss:0.2202238472778706\n",
      "train loss:0.10588536271716556\n",
      "train loss:0.249513534673403\n",
      "train loss:0.21996347770769697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.14797748831428284\n",
      "train loss:0.21005826442962008\n",
      "train loss:0.14240622882501805\n",
      "train loss:0.10226248852751103\n",
      "train loss:0.13790684996935632\n",
      "train loss:0.1545948181063462\n",
      "train loss:0.16610125688031924\n",
      "train loss:0.20838040209845926\n",
      "train loss:0.14372027551859543\n",
      "train loss:0.1233698021109743\n",
      "train loss:0.20485084591665498\n",
      "train loss:0.06891085404263905\n",
      "train loss:0.10478819379118118\n",
      "train loss:0.13159225718074366\n",
      "train loss:0.16145594613757602\n",
      "train loss:0.1031045704986231\n",
      "train loss:0.16586189709426488\n",
      "train loss:0.2013890895111135\n",
      "train loss:0.1913766323077743\n",
      "train loss:0.1114950735870371\n",
      "train loss:0.1665189024543489\n",
      "train loss:0.12364269188593509\n",
      "train loss:0.20273789710491397\n",
      "train loss:0.11324196401745809\n",
      "train loss:0.15092120684121366\n",
      "train loss:0.14214265989771252\n",
      "train loss:0.1647330557641443\n",
      "train loss:0.14752054867674647\n",
      "train loss:0.1676288167168778\n",
      "train loss:0.18483058669192917\n",
      "train loss:0.1545562416078544\n",
      "train loss:0.05856028885652049\n",
      "train loss:0.18699763023025973\n",
      "train loss:0.2169936688466287\n",
      "train loss:0.1209697120189146\n",
      "train loss:0.13785867829639778\n",
      "train loss:0.21403308027812531\n",
      "train loss:0.2091908811644791\n",
      "train loss:0.3047836304874441\n",
      "train loss:0.19076153143213348\n",
      "train loss:0.08300593498855546\n",
      "train loss:0.15831065300356412\n",
      "train loss:0.1462268921438162\n",
      "train loss:0.19537071115447302\n",
      "train loss:0.21621023359730887\n",
      "train loss:0.08832214377237961\n",
      "train loss:0.16227288217290678\n",
      "train loss:0.09765395797283447\n",
      "train loss:0.23744161606003014\n",
      "train loss:0.1665543334793105\n",
      "train loss:0.12793997874522947\n",
      "train loss:0.08419191203427187\n",
      "train loss:0.12706484886871056\n",
      "train loss:0.1382316462343071\n",
      "train loss:0.09032964360016148\n",
      "train loss:0.1512125934195716\n",
      "train loss:0.20901462126690906\n",
      "train loss:0.09415914188209856\n",
      "train loss:0.23325796402133173\n",
      "train loss:0.10350776667539366\n",
      "train loss:0.16136184334012796\n",
      "train loss:0.08717764293228669\n",
      "train loss:0.23399183337899604\n",
      "train loss:0.17261335986671802\n",
      "train loss:0.14320705242966675\n",
      "train loss:0.1790836240525762\n",
      "train loss:0.14090910221534286\n",
      "train loss:0.21382872681585696\n",
      "train loss:0.2746550430942536\n",
      "train loss:0.23778503800377554\n",
      "train loss:0.09185288202327538\n",
      "train loss:0.2365198427748258\n",
      "train loss:0.10808195656055922\n",
      "train loss:0.13835380585739024\n",
      "train loss:0.10081297981038345\n",
      "train loss:0.17558697125439415\n",
      "train loss:0.09661805465845517\n",
      "train loss:0.10054628028391392\n",
      "train loss:0.06256161931662821\n",
      "train loss:0.288741897986089\n",
      "train loss:0.1136199096038415\n",
      "train loss:0.08380763027051547\n",
      "train loss:0.08500362088097348\n",
      "train loss:0.129772652617794\n",
      "train loss:0.09554882148217565\n",
      "train loss:0.08739267765630815\n",
      "train loss:0.09354341484178462\n",
      "train loss:0.16535833892828133\n",
      "train loss:0.12655624313698607\n",
      "train loss:0.08425334238135886\n",
      "train loss:0.1056845735324802\n",
      "train loss:0.07371055995682264\n",
      "train loss:0.15611309842568746\n",
      "train loss:0.10239437393624798\n",
      "train loss:0.1638396036642706\n",
      "train loss:0.13023686443301113\n",
      "train loss:0.10678321390991653\n",
      "train loss:0.16400299319170242\n",
      "train loss:0.17316201612826115\n",
      "train loss:0.0942195022390668\n",
      "train loss:0.218569617196269\n",
      "train loss:0.11094179631979761\n",
      "train loss:0.06992481955939024\n",
      "train loss:0.23906566478695834\n",
      "train loss:0.2317004662919699\n",
      "train loss:0.1253040240170319\n",
      "train loss:0.0958616436971264\n",
      "train loss:0.191375063385635\n",
      "train loss:0.13186478295448753\n",
      "train loss:0.10107261762852345\n",
      "train loss:0.22728998484155533\n",
      "train loss:0.282848538664662\n",
      "train loss:0.16948025862808636\n",
      "train loss:0.09915889707586377\n",
      "train loss:0.18168845425159186\n",
      "train loss:0.10793036550743648\n",
      "train loss:0.14153346844280795\n",
      "train loss:0.07735971898417772\n",
      "train loss:0.07756679858900582\n",
      "train loss:0.14321644607936945\n",
      "train loss:0.19161177035888688\n",
      "train loss:0.1100949054211242\n",
      "train loss:0.1374673980848162\n",
      "train loss:0.2270915204555423\n",
      "train loss:0.13462200618887527\n",
      "train loss:0.12102288620206882\n",
      "train loss:0.19038616454993765\n",
      "train loss:0.1393374750956373\n",
      "train loss:0.10370909212293271\n",
      "train loss:0.1380509188276135\n",
      "train loss:0.2267817175566493\n",
      "train loss:0.17272448113037345\n",
      "train loss:0.10260375426071354\n",
      "train loss:0.25749228002379176\n",
      "train loss:0.09751795677698065\n",
      "train loss:0.20949169844428048\n",
      "train loss:0.10884475432105288\n",
      "train loss:0.07927598650305705\n",
      "train loss:0.18028648907632625\n",
      "train loss:0.20488585513009144\n",
      "train loss:0.14517326095863078\n",
      "train loss:0.23504592830806068\n",
      "train loss:0.11825875802590483\n",
      "train loss:0.15610384203866645\n",
      "train loss:0.09194852811682372\n",
      "train loss:0.160103248002717\n",
      "train loss:0.12073485498715204\n",
      "train loss:0.1363273747854414\n",
      "train loss:0.06452463407595461\n",
      "train loss:0.10666384535014553\n",
      "train loss:0.20926043558729662\n",
      "train loss:0.14738566898109007\n",
      "train loss:0.09304578276934766\n",
      "train loss:0.05341823383019234\n",
      "train loss:0.1609564654950753\n",
      "train loss:0.06887786154888716\n",
      "train loss:0.27758916001026074\n",
      "train loss:0.060706060131597794\n",
      "train loss:0.12447419449877888\n",
      "train loss:0.16491755096795216\n",
      "train loss:0.18031796118911556\n",
      "train loss:0.04444049078048559\n",
      "train loss:0.15005700601015143\n",
      "train loss:0.05365419657083737\n",
      "train loss:0.07414164486217173\n",
      "train loss:0.09532421921719951\n",
      "train loss:0.2215451412878949\n",
      "train loss:0.18786442879257742\n",
      "train loss:0.18267766938254798\n",
      "train loss:0.22491106549653658\n",
      "train loss:0.162098728192405\n",
      "train loss:0.09570459409657045\n",
      "train loss:0.14716639434032497\n",
      "train loss:0.12353132863389561\n",
      "train loss:0.14390209009209073\n",
      "train loss:0.15461279976690717\n",
      "train loss:0.15263061021057414\n",
      "train loss:0.0903813667323747\n",
      "train loss:0.14725917462206392\n",
      "train loss:0.12712318982182363\n",
      "train loss:0.1702235770895461\n",
      "train loss:0.09432516214415122\n",
      "train loss:0.11173696897485907\n",
      "train loss:0.19407940854745728\n",
      "train loss:0.2500250285734408\n",
      "train loss:0.16231108856316886\n",
      "train loss:0.13961668511932868\n",
      "train loss:0.25992586458957356\n",
      "train loss:0.05451591411883744\n",
      "train loss:0.12269887925887538\n",
      "train loss:0.18166356314523743\n",
      "train loss:0.1199574902168039\n",
      "train loss:0.16152101400526422\n",
      "train loss:0.13449787761015164\n",
      "train loss:0.2014815223957315\n",
      "train loss:0.12876465608244983\n",
      "train loss:0.16311869412538896\n",
      "train loss:0.09320400824392225\n",
      "train loss:0.1569332529542799\n",
      "train loss:0.06642442816153026\n",
      "train loss:0.1375406903271987\n",
      "train loss:0.2148810780689874\n",
      "train loss:0.10249159114623607\n",
      "train loss:0.07723533292978431\n",
      "train loss:0.15628468073373022\n",
      "train loss:0.1304287122806425\n",
      "train loss:0.18660760022720368\n",
      "train loss:0.06429630578937866\n",
      "train loss:0.18931279213263114\n",
      "train loss:0.05867124810578755\n",
      "train loss:0.10687444311997459\n",
      "train loss:0.1656611285882142\n",
      "train loss:0.15702047903568508\n",
      "train loss:0.12880887742020453\n",
      "train loss:0.08956084308884797\n",
      "train loss:0.10700003665627861\n",
      "train loss:0.11021393309737755\n",
      "train loss:0.06805835130207806\n",
      "train loss:0.18928102853461568\n",
      "train loss:0.07450771634049838\n",
      "train loss:0.09203741899264341\n",
      "train loss:0.18042602321435866\n",
      "train loss:0.08676508686219425\n",
      "train loss:0.16014999945964375\n",
      "train loss:0.08380305124106087\n",
      "train loss:0.06707448378417977\n",
      "train loss:0.15163415956999693\n",
      "train loss:0.3093423272968741\n",
      "train loss:0.2976115692433562\n",
      "train loss:0.12495547756557887\n",
      "train loss:0.15205427785471548\n",
      "train loss:0.11936973792443739\n",
      "train loss:0.10488649719863145\n",
      "train loss:0.14240145799417692\n",
      "train loss:0.12467243179081802\n",
      "train loss:0.1777201850223786\n",
      "train loss:0.15248758548913735\n",
      "train loss:0.0819881069637618\n",
      "train loss:0.10550613116564472\n",
      "train loss:0.08511537244020044\n",
      "train loss:0.12921772215598265\n",
      "train loss:0.07271191288816166\n",
      "train loss:0.10956085802472507\n",
      "train loss:0.27486128349447936\n",
      "train loss:0.15492275046601733\n",
      "train loss:0.12966245593672787\n",
      "train loss:0.23338962122312448\n",
      "train loss:0.13616695435876847\n",
      "train loss:0.15415947936680233\n",
      "train loss:0.14437163919154192\n",
      "train loss:0.09838941889237703\n",
      "train loss:0.14550472666503844\n",
      "train loss:0.13956486091346648\n",
      "train loss:0.16569655869800676\n",
      "train loss:0.06324370991699946\n",
      "train loss:0.18656576049659365\n",
      "train loss:0.11120981676285155\n",
      "train loss:0.09112982618867133\n",
      "train loss:0.18695865392467861\n",
      "train loss:0.10650054025620173\n",
      "train loss:0.20083881807879944\n",
      "train loss:0.07968640019229074\n",
      "train loss:0.13195628378807206\n",
      "train loss:0.2134210982111374\n",
      "train loss:0.17605135307700837\n",
      "train loss:0.10867531855736386\n",
      "train loss:0.16514593584646453\n",
      "train loss:0.259791448231536\n",
      "train loss:0.11377698267708614\n",
      "train loss:0.09271458964077305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.22489852004027394\n",
      "train loss:0.2184266730055333\n",
      "train loss:0.18513475579439143\n",
      "train loss:0.08708314061620116\n",
      "train loss:0.18422483219688612\n",
      "train loss:0.11774573780390506\n",
      "train loss:0.12782045721191862\n",
      "train loss:0.1818758878611785\n",
      "train loss:0.06178713403580318\n",
      "train loss:0.07059648476872682\n",
      "train loss:0.11629094029279786\n",
      "train loss:0.11392401850431128\n",
      "train loss:0.09669276588196977\n",
      "train loss:0.11981985676926152\n",
      "train loss:0.0936754129560358\n",
      "train loss:0.13314812833387588\n",
      "train loss:0.14380476628131325\n",
      "train loss:0.11455174919576823\n",
      "train loss:0.1226301629925783\n",
      "train loss:0.13997064472451318\n",
      "train loss:0.12206485602045054\n",
      "train loss:0.10894188897059888\n",
      "train loss:0.19566342991376234\n",
      "train loss:0.13639311343285723\n",
      "train loss:0.16847652098131796\n",
      "train loss:0.13183389371862095\n",
      "train loss:0.0845459695141885\n",
      "train loss:0.2038313621486951\n",
      "train loss:0.10761359351553573\n",
      "train loss:0.07073790140934139\n",
      "train loss:0.12418379112791145\n",
      "train loss:0.05349983134874047\n",
      "train loss:0.09898458712027786\n",
      "train loss:0.12365994908460758\n",
      "train loss:0.1230970930085364\n",
      "train loss:0.10018769256373644\n",
      "train loss:0.1472648538405301\n",
      "train loss:0.06551236409396942\n",
      "=== epoch:6, train acc:0.957, test acc:0.946 ===, time:  94.93717503547668\n",
      "train loss:0.13727897246675716\n",
      "train loss:0.10304612495199311\n",
      "train loss:0.22559854202309282\n",
      "train loss:0.13498615921079055\n",
      "train loss:0.0924608355105335\n",
      "train loss:0.14916607544237026\n",
      "train loss:0.1376445493198753\n",
      "train loss:0.11737597353610188\n",
      "train loss:0.25845986784425884\n",
      "train loss:0.1060066648446745\n",
      "train loss:0.07145915708176848\n",
      "train loss:0.18900760941849515\n",
      "train loss:0.235248740386332\n",
      "train loss:0.24275038721539716\n",
      "train loss:0.12419741977798063\n",
      "train loss:0.1278476328780363\n",
      "train loss:0.1612903609984828\n",
      "train loss:0.05574234045409039\n",
      "train loss:0.1839107356939718\n",
      "train loss:0.14017052431290547\n",
      "train loss:0.09309967601309502\n",
      "train loss:0.12288033250598054\n",
      "train loss:0.3043265398051785\n",
      "train loss:0.13287728811235103\n",
      "train loss:0.14038647917467206\n",
      "train loss:0.1506570429161578\n",
      "train loss:0.12486084068363125\n",
      "train loss:0.16256438304746731\n",
      "train loss:0.17267678024900707\n",
      "train loss:0.10721024958143298\n",
      "train loss:0.13502784204047333\n",
      "train loss:0.15009061961520087\n",
      "train loss:0.20706654507364053\n",
      "train loss:0.1721730791533499\n",
      "train loss:0.16327513851423953\n",
      "train loss:0.14856000759608368\n",
      "train loss:0.10569178035975632\n",
      "train loss:0.20290887411746528\n",
      "train loss:0.0662385084184712\n",
      "train loss:0.15062743284788646\n",
      "train loss:0.14690332275373247\n",
      "train loss:0.09668534521173949\n",
      "train loss:0.14069942410505087\n",
      "train loss:0.09788248146257118\n",
      "train loss:0.20396855729330937\n",
      "train loss:0.07236586525880029\n",
      "train loss:0.14160690364259\n",
      "train loss:0.19853320700042268\n",
      "train loss:0.09855381736556082\n",
      "train loss:0.1058200552854709\n",
      "train loss:0.1909033607272621\n",
      "train loss:0.19389087518618575\n",
      "train loss:0.10083303345435946\n",
      "train loss:0.1133945312400434\n",
      "train loss:0.05231535628377673\n",
      "train loss:0.15742070029860503\n",
      "train loss:0.1127355920004208\n",
      "train loss:0.13292545523991586\n",
      "train loss:0.09782252419202471\n",
      "train loss:0.1901036442115812\n",
      "train loss:0.1018854706931221\n",
      "train loss:0.09206034259572\n",
      "train loss:0.11651821617736127\n",
      "train loss:0.2313109619432842\n",
      "train loss:0.09208122439375713\n",
      "train loss:0.2424862621237053\n",
      "train loss:0.08533983980024348\n",
      "train loss:0.11473689883695712\n",
      "train loss:0.11432875615915933\n",
      "train loss:0.21109039462838172\n",
      "train loss:0.11065913120889831\n",
      "train loss:0.2174253927516719\n",
      "train loss:0.1964897250824975\n",
      "train loss:0.13024618730303855\n",
      "train loss:0.08964197893653499\n",
      "train loss:0.10739173156845945\n",
      "train loss:0.06509958532488791\n",
      "train loss:0.16950206285642122\n",
      "train loss:0.1309962551990857\n",
      "train loss:0.1775718685263202\n",
      "train loss:0.11212024510123689\n",
      "train loss:0.07515947832985187\n",
      "train loss:0.17411774661115523\n",
      "train loss:0.16246396349784717\n",
      "train loss:0.08428394480590631\n",
      "train loss:0.18584238322231092\n",
      "train loss:0.08645314791843414\n",
      "train loss:0.17531698952057728\n",
      "train loss:0.10082468820583441\n",
      "train loss:0.11975770898383606\n",
      "train loss:0.1291417929760832\n",
      "train loss:0.09908103272631885\n",
      "train loss:0.11986345295113451\n",
      "train loss:0.24487099919158806\n",
      "train loss:0.06934077483530637\n",
      "train loss:0.13641647145572766\n",
      "train loss:0.1226397446688388\n",
      "train loss:0.08532695524058369\n",
      "train loss:0.08357981542750136\n",
      "train loss:0.16814562687513315\n",
      "train loss:0.1450187464032589\n",
      "train loss:0.14154905518863864\n",
      "train loss:0.09301938633317607\n",
      "train loss:0.1023186861414602\n",
      "train loss:0.08643250522634338\n",
      "train loss:0.10150237322836418\n",
      "train loss:0.14213855041447115\n",
      "train loss:0.0859262790796518\n",
      "train loss:0.21089400121913798\n",
      "train loss:0.17670129856152741\n",
      "train loss:0.17026039545369226\n",
      "train loss:0.06030726757314289\n",
      "train loss:0.09369544417239434\n",
      "train loss:0.09450522191966877\n",
      "train loss:0.2096115749181662\n",
      "train loss:0.07369533048226617\n",
      "train loss:0.17003205940242413\n",
      "train loss:0.13065249562041806\n",
      "train loss:0.21580522123972495\n",
      "train loss:0.10100297426849117\n",
      "train loss:0.12057090989511966\n",
      "train loss:0.20210760071520537\n",
      "train loss:0.0927325576239818\n",
      "train loss:0.07611109400561508\n",
      "train loss:0.08641346003960373\n",
      "train loss:0.15917989269902394\n",
      "train loss:0.0910832532114782\n",
      "train loss:0.12157986504248694\n",
      "train loss:0.20889393574671108\n",
      "train loss:0.1207594077017752\n",
      "train loss:0.07069140101220137\n",
      "train loss:0.18038084529670895\n",
      "train loss:0.2005203656150702\n",
      "train loss:0.11550952037773905\n",
      "train loss:0.18123104652503128\n",
      "train loss:0.12892970444747526\n",
      "train loss:0.12909006544032153\n",
      "train loss:0.191657167817886\n",
      "train loss:0.169260663149995\n",
      "train loss:0.21231479208968998\n",
      "train loss:0.15559189581520502\n",
      "train loss:0.10790101583712301\n",
      "train loss:0.12288192911951855\n",
      "train loss:0.24621339684138047\n",
      "train loss:0.13113676007526653\n",
      "train loss:0.08474098184010172\n",
      "train loss:0.14578945167561508\n",
      "train loss:0.13213866389539677\n",
      "train loss:0.13431957444959802\n",
      "train loss:0.11468598954279255\n",
      "train loss:0.12692893918840048\n",
      "train loss:0.1426217907286345\n",
      "train loss:0.23603160051706015\n",
      "train loss:0.04731505214213366\n",
      "train loss:0.14144300384207947\n",
      "train loss:0.05770202240770542\n",
      "train loss:0.09884242790097755\n",
      "train loss:0.2575603378564731\n",
      "train loss:0.3051312169889709\n",
      "train loss:0.2090381081782337\n",
      "train loss:0.12039537219393079\n",
      "train loss:0.12390663486048677\n",
      "train loss:0.17390066265824217\n",
      "train loss:0.1309868794554936\n",
      "train loss:0.12066577602469142\n",
      "train loss:0.034299526315593604\n",
      "train loss:0.09099149096336605\n",
      "train loss:0.08428228569637476\n",
      "train loss:0.19317834504185985\n",
      "train loss:0.1279560265609683\n",
      "train loss:0.1201491157347429\n",
      "train loss:0.13466911427666095\n",
      "train loss:0.1364598984867084\n",
      "train loss:0.09295282409301267\n",
      "train loss:0.1743947106349789\n",
      "train loss:0.15608607784091724\n",
      "train loss:0.08834259039127083\n",
      "train loss:0.12100513148333002\n",
      "train loss:0.19093042911824645\n",
      "train loss:0.16679885579770545\n",
      "train loss:0.069721544759382\n",
      "train loss:0.12747552779450047\n",
      "train loss:0.10414705831100536\n",
      "train loss:0.2030476127282644\n",
      "train loss:0.11955509937208833\n",
      "train loss:0.10203831568729248\n",
      "train loss:0.07054425266651601\n",
      "train loss:0.17359956739645074\n",
      "train loss:0.16718193698153566\n",
      "train loss:0.026192599364880498\n",
      "train loss:0.1834664974616647\n",
      "train loss:0.17086417972884227\n",
      "train loss:0.09140986226783147\n",
      "train loss:0.171895554262524\n",
      "train loss:0.11793236752626512\n",
      "train loss:0.11805404569207685\n",
      "train loss:0.1672940976980933\n",
      "train loss:0.13943319499034076\n",
      "train loss:0.16652394653977315\n",
      "train loss:0.14419806207868682\n",
      "train loss:0.1291891233789864\n",
      "train loss:0.09367922681834782\n",
      "train loss:0.1462542519587282\n",
      "train loss:0.13416085885282653\n",
      "train loss:0.16534127502732585\n",
      "train loss:0.16265896419078665\n",
      "train loss:0.16039420767148418\n",
      "train loss:0.15328874226886635\n",
      "train loss:0.12701451432658392\n",
      "train loss:0.110056036352809\n",
      "train loss:0.11849989599957476\n",
      "train loss:0.10668920853264559\n",
      "train loss:0.09525350938769982\n",
      "train loss:0.10435326393395158\n",
      "train loss:0.1258653919757803\n",
      "train loss:0.12179725536968933\n",
      "train loss:0.11445004250355756\n",
      "train loss:0.11774700864782092\n",
      "train loss:0.1491952359596577\n",
      "train loss:0.23477621440130647\n",
      "train loss:0.12699477931042874\n",
      "train loss:0.17447093126486188\n",
      "train loss:0.09269409053889355\n",
      "train loss:0.130618723225744\n",
      "train loss:0.18652676316781014\n",
      "train loss:0.17414030058694088\n",
      "train loss:0.10361573650232464\n",
      "train loss:0.11699811912472045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.13889765023565137\n",
      "train loss:0.0867794096158936\n",
      "train loss:0.06857509278214492\n",
      "train loss:0.22053997265453582\n",
      "train loss:0.21505197234531961\n",
      "train loss:0.13508841889279055\n",
      "train loss:0.09855976742596932\n",
      "train loss:0.15338511747685626\n",
      "train loss:0.09370240004157429\n",
      "train loss:0.11668094334597033\n",
      "train loss:0.1932107483773252\n",
      "train loss:0.15449511261336202\n",
      "train loss:0.1965211432494404\n",
      "train loss:0.1618788841855848\n",
      "train loss:0.08276493632125934\n",
      "train loss:0.11712335538170489\n",
      "train loss:0.30917485394045396\n",
      "train loss:0.17881336314470403\n",
      "train loss:0.1366869920806404\n",
      "train loss:0.09105833288787428\n",
      "train loss:0.07471706234542298\n",
      "train loss:0.06627702579815607\n",
      "train loss:0.12440963342762984\n",
      "train loss:0.07116317337567453\n",
      "train loss:0.21475606801778802\n",
      "train loss:0.11132164763912251\n",
      "train loss:0.12478663995130618\n",
      "train loss:0.13646011102623362\n",
      "train loss:0.1697377708175508\n",
      "train loss:0.1071515958307403\n",
      "train loss:0.07414749371655555\n",
      "train loss:0.10673071127637547\n",
      "train loss:0.11410622357489707\n",
      "train loss:0.15138248136098165\n",
      "train loss:0.1396325888203102\n",
      "train loss:0.14030211659951902\n",
      "train loss:0.05884614936052783\n",
      "train loss:0.08053074847149386\n",
      "train loss:0.08756088223296066\n",
      "train loss:0.07406322694592843\n",
      "train loss:0.1794328411480542\n",
      "train loss:0.19269790346988583\n",
      "train loss:0.03047281104953406\n",
      "train loss:0.07135518260156189\n",
      "train loss:0.17289885560399362\n",
      "train loss:0.07959269610786424\n",
      "train loss:0.13414507394945777\n",
      "train loss:0.11678408347778445\n",
      "train loss:0.10735804666901365\n",
      "train loss:0.08681558823275125\n",
      "train loss:0.1326079409795533\n",
      "train loss:0.16377020295295\n",
      "train loss:0.14947345487851268\n",
      "train loss:0.07054669598967972\n",
      "train loss:0.0732009618765198\n",
      "train loss:0.12737703157315006\n",
      "train loss:0.08242762344991929\n",
      "train loss:0.1279047668289362\n",
      "train loss:0.16700171239300712\n",
      "train loss:0.06225479716505323\n",
      "train loss:0.1223661008962613\n",
      "train loss:0.1276232464580805\n",
      "train loss:0.12813479086761576\n",
      "train loss:0.20560785863616737\n",
      "train loss:0.13317559358413264\n",
      "train loss:0.07585265253572841\n",
      "train loss:0.20495153400391034\n",
      "train loss:0.1132412804726264\n",
      "train loss:0.12465062090101586\n",
      "train loss:0.17356759266009525\n",
      "train loss:0.1508776379615698\n",
      "train loss:0.12233464859609212\n",
      "train loss:0.2542027188585036\n",
      "train loss:0.15981423577952156\n",
      "train loss:0.06894462193106193\n",
      "train loss:0.1362316075253429\n",
      "train loss:0.15201862918050638\n",
      "train loss:0.13513071799393597\n",
      "train loss:0.14123326858536225\n",
      "train loss:0.17039892748879404\n",
      "train loss:0.1441073240237137\n",
      "train loss:0.14338042663033548\n",
      "train loss:0.1310271630520128\n",
      "train loss:0.1515489738436096\n",
      "train loss:0.13266461100987492\n",
      "train loss:0.08249152217139483\n",
      "train loss:0.03750855645141605\n",
      "train loss:0.2295787351258477\n",
      "train loss:0.11452507115057071\n",
      "train loss:0.13100950091532687\n",
      "train loss:0.11440710448838805\n",
      "train loss:0.10993200426754406\n",
      "train loss:0.17145037332493093\n",
      "train loss:0.21350357049727364\n",
      "train loss:0.1066483124075633\n",
      "train loss:0.1071652272895618\n",
      "train loss:0.1436299598259776\n",
      "train loss:0.10653692055767021\n",
      "train loss:0.17706555071710484\n",
      "train loss:0.11802201826482889\n",
      "train loss:0.09955953705360346\n",
      "train loss:0.07060338294925156\n",
      "train loss:0.09193158762896525\n",
      "train loss:0.08959389299747986\n",
      "train loss:0.09941440076695686\n",
      "train loss:0.11435380163501957\n",
      "train loss:0.1895969253058133\n",
      "train loss:0.14579947638015953\n",
      "train loss:0.06968454473189453\n",
      "train loss:0.09677870336066935\n",
      "train loss:0.15115485610005808\n",
      "train loss:0.06489012560025757\n",
      "train loss:0.1695768666168677\n",
      "train loss:0.09439998474121485\n",
      "train loss:0.07779185859868226\n",
      "train loss:0.149111067095368\n",
      "train loss:0.24108598602648992\n",
      "train loss:0.10918691242870487\n",
      "train loss:0.08375408841194072\n",
      "train loss:0.14993776767349717\n",
      "train loss:0.11099039045768298\n",
      "train loss:0.08618824168624607\n",
      "train loss:0.2625543125709504\n",
      "train loss:0.2612762794914827\n",
      "train loss:0.11499098871570586\n",
      "train loss:0.16360482788961753\n",
      "train loss:0.13716777136927394\n",
      "train loss:0.14575315923372612\n",
      "train loss:0.13960615080150923\n",
      "train loss:0.13787380426614254\n",
      "train loss:0.3642019499881388\n",
      "train loss:0.0726251358660459\n",
      "train loss:0.20879339053277654\n",
      "train loss:0.17207426956342967\n",
      "train loss:0.06934038453900136\n",
      "train loss:0.049810457825547695\n",
      "train loss:0.08502424305727191\n",
      "train loss:0.07551801622204816\n",
      "train loss:0.21441626463685645\n",
      "train loss:0.10191850431245461\n",
      "train loss:0.18743558199583987\n",
      "train loss:0.09988549260190278\n",
      "train loss:0.10719595143643622\n",
      "train loss:0.1663001457177462\n",
      "train loss:0.09075354491499293\n",
      "train loss:0.0743350475537642\n",
      "train loss:0.23880333657194527\n",
      "train loss:0.054412496011463224\n",
      "train loss:0.09183729759768026\n",
      "train loss:0.12202931707418474\n",
      "train loss:0.07908636263256784\n",
      "train loss:0.21158087027409375\n",
      "train loss:0.2194122489175354\n",
      "train loss:0.1216502354163275\n",
      "train loss:0.10669552785432133\n",
      "train loss:0.10572600035647164\n",
      "train loss:0.20071811296635236\n",
      "train loss:0.07737949629442659\n",
      "train loss:0.16948870538845717\n",
      "train loss:0.07215536406585571\n",
      "train loss:0.0863552521923175\n",
      "train loss:0.0950508872540914\n",
      "train loss:0.1269736000372731\n",
      "train loss:0.12038383531515623\n",
      "train loss:0.12213316066439893\n",
      "train loss:0.119217774772781\n",
      "train loss:0.0948066013995981\n",
      "train loss:0.1248430479468744\n",
      "train loss:0.07196830029983257\n",
      "train loss:0.1677000388907518\n",
      "train loss:0.08033964085827294\n",
      "train loss:0.13886938554731565\n",
      "train loss:0.27558362823318605\n",
      "train loss:0.06824703902511171\n",
      "train loss:0.11266785674396682\n",
      "train loss:0.22971947795374312\n",
      "train loss:0.09517178395432038\n",
      "train loss:0.03566614424940722\n",
      "train loss:0.13257785886259218\n",
      "train loss:0.08929533711575215\n",
      "train loss:0.16375853667088308\n",
      "train loss:0.15148998622195534\n",
      "train loss:0.11450089689108506\n",
      "train loss:0.09741161650889124\n",
      "train loss:0.14620467487461686\n",
      "train loss:0.15102992401666193\n",
      "train loss:0.279524535849627\n",
      "train loss:0.1361884514606224\n",
      "train loss:0.1829468374423266\n",
      "train loss:0.11799214115845415\n",
      "train loss:0.06000591113064245\n",
      "train loss:0.2934848801993788\n",
      "train loss:0.17669164494832143\n",
      "train loss:0.11537724236050081\n",
      "train loss:0.0680734918581851\n",
      "train loss:0.11230892342516272\n",
      "train loss:0.11589497490057572\n",
      "train loss:0.1038679343085806\n",
      "train loss:0.17823468794289282\n",
      "train loss:0.16601745838373438\n",
      "train loss:0.11401897458551964\n",
      "train loss:0.08791748232113043\n",
      "train loss:0.13105748424732475\n",
      "train loss:0.13078481581256093\n",
      "train loss:0.07566968272389313\n",
      "train loss:0.22570708081692012\n",
      "train loss:0.13074966841763452\n",
      "train loss:0.13995262922726115\n",
      "train loss:0.23209193933204308\n",
      "train loss:0.06854974295348962\n",
      "train loss:0.1553964367417268\n",
      "train loss:0.0841259047034124\n",
      "train loss:0.0756820314468157\n",
      "train loss:0.1297013713745834\n",
      "train loss:0.13499203612794222\n",
      "train loss:0.17744920271508685\n",
      "train loss:0.07730537999867644\n",
      "train loss:0.16597852733334537\n",
      "train loss:0.12080468297816026\n",
      "train loss:0.10398191926729071\n",
      "train loss:0.1353681400483179\n",
      "train loss:0.06074125750954004\n",
      "train loss:0.11826234452533767\n",
      "train loss:0.12638413605366716\n",
      "train loss:0.12459075749274236\n",
      "train loss:0.1286086064654753\n",
      "train loss:0.16611088592745557\n",
      "train loss:0.15840892070012738\n",
      "train loss:0.07706293795128548\n",
      "train loss:0.07405788748138303\n",
      "train loss:0.07126223466072873\n",
      "train loss:0.11140915914917525\n",
      "train loss:0.09280784910739535\n",
      "train loss:0.06363029235338793\n",
      "train loss:0.09851526291169846\n",
      "train loss:0.11662904769529027\n",
      "train loss:0.181586342327545\n",
      "train loss:0.12507381223834918\n",
      "train loss:0.11239206197743774\n",
      "train loss:0.11051668809864794\n",
      "train loss:0.08604312661480847\n",
      "train loss:0.11969381104757025\n",
      "train loss:0.14449402713885165\n",
      "train loss:0.06783054734189678\n",
      "train loss:0.08505759118420464\n",
      "train loss:0.15214689351209318\n",
      "train loss:0.06322090599182772\n",
      "train loss:0.2617422118477111\n",
      "train loss:0.08258227609828898\n",
      "train loss:0.11710800301820296\n",
      "train loss:0.06470917717727508\n",
      "train loss:0.1168727694217104\n",
      "train loss:0.10692141987454688\n",
      "train loss:0.13915390882896456\n",
      "train loss:0.20633994190008564\n",
      "train loss:0.23923873916208535\n",
      "train loss:0.08313903072931068\n",
      "train loss:0.1576305326863935\n",
      "train loss:0.12540804943739287\n",
      "train loss:0.17844707779153765\n",
      "train loss:0.14539907909449554\n",
      "train loss:0.19243298544438253\n",
      "train loss:0.1994559153987926\n",
      "train loss:0.13062788854421195\n",
      "train loss:0.055551835867797106\n",
      "train loss:0.11838741170637787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11369839166268939\n",
      "train loss:0.057448379833363414\n",
      "train loss:0.13299288687036057\n",
      "train loss:0.14514395457143964\n",
      "train loss:0.09242188986150515\n",
      "train loss:0.07565039277033335\n",
      "train loss:0.10670028455846026\n",
      "train loss:0.17311706545025024\n",
      "train loss:0.1511680732594514\n",
      "train loss:0.20221908398410857\n",
      "train loss:0.09512560128221001\n",
      "train loss:0.1809333465455088\n",
      "train loss:0.10281189079801306\n",
      "train loss:0.12252979536515679\n",
      "train loss:0.1922789450913099\n",
      "train loss:0.23420325187147262\n",
      "train loss:0.04640413441687751\n",
      "train loss:0.18397688926914882\n",
      "train loss:0.13523193467507283\n",
      "train loss:0.13270925745852163\n",
      "train loss:0.2140375208176586\n",
      "train loss:0.06638814317230955\n",
      "train loss:0.18606801880822577\n",
      "train loss:0.1382456691973018\n",
      "train loss:0.1473842829416337\n",
      "train loss:0.14811797886314604\n",
      "train loss:0.1100203431690955\n",
      "train loss:0.07250175212133865\n",
      "train loss:0.08129623462679789\n",
      "train loss:0.11289726854530391\n",
      "train loss:0.19908044214834958\n",
      "train loss:0.09023709827745117\n",
      "train loss:0.07274139943546613\n",
      "train loss:0.11605762934624247\n",
      "train loss:0.12163134578955681\n",
      "train loss:0.13176623381230773\n",
      "train loss:0.08945236076082909\n",
      "train loss:0.15188729235926346\n",
      "train loss:0.10425072402276366\n",
      "train loss:0.15301752741124883\n",
      "train loss:0.10137115071645543\n",
      "train loss:0.14978014590518207\n",
      "train loss:0.17975980797141008\n",
      "train loss:0.11747930380891575\n",
      "train loss:0.18271375763169115\n",
      "train loss:0.13791465463176233\n",
      "train loss:0.1888264313459946\n",
      "train loss:0.1157441616133932\n",
      "train loss:0.06356904697473978\n",
      "train loss:0.12273688723361709\n",
      "train loss:0.11826494426302321\n",
      "train loss:0.1743240990405878\n",
      "train loss:0.12847351231532086\n",
      "train loss:0.09960230464835967\n",
      "train loss:0.04973241295710791\n",
      "train loss:0.10948364899094759\n",
      "train loss:0.05488342480107496\n",
      "train loss:0.17737727431124878\n",
      "train loss:0.09463040464662606\n",
      "train loss:0.13809527220320472\n",
      "train loss:0.06396579659028583\n",
      "train loss:0.04896574203150043\n",
      "train loss:0.12068037393160809\n",
      "train loss:0.10344484605535084\n",
      "train loss:0.23413130766662815\n",
      "train loss:0.07481112037819089\n",
      "train loss:0.11360316213977723\n",
      "train loss:0.11284554096253929\n",
      "train loss:0.12524403064648384\n",
      "train loss:0.07312857995985417\n",
      "train loss:0.10660980307551572\n",
      "train loss:0.0637958335751971\n",
      "train loss:0.06641962045723047\n",
      "train loss:0.09696362124117991\n",
      "train loss:0.16554873694999572\n",
      "train loss:0.06442777201323455\n",
      "train loss:0.08021195235269506\n",
      "train loss:0.17396468815444824\n",
      "train loss:0.07651090671135113\n",
      "train loss:0.05429704746416889\n",
      "train loss:0.1351362422586314\n",
      "train loss:0.1318447750807221\n",
      "train loss:0.11667408984874117\n",
      "train loss:0.19027372736587192\n",
      "train loss:0.13176115624590382\n",
      "train loss:0.13987104927703917\n",
      "train loss:0.05787298878089699\n",
      "train loss:0.14471712069477005\n",
      "train loss:0.19529100652135142\n",
      "train loss:0.116552125818775\n",
      "train loss:0.09484170122617341\n",
      "train loss:0.08355856711082135\n",
      "train loss:0.09721178447528801\n",
      "train loss:0.12699830171858614\n",
      "train loss:0.16913108526212284\n",
      "train loss:0.11651759267257247\n",
      "train loss:0.09581784498773814\n",
      "train loss:0.054607214031530675\n",
      "train loss:0.1605428418027761\n",
      "train loss:0.15654336287671133\n",
      "train loss:0.08892602019153681\n",
      "train loss:0.25055384255352997\n",
      "train loss:0.10638178428250565\n",
      "train loss:0.09928254189423134\n",
      "train loss:0.14116345056885607\n",
      "train loss:0.08399676579745284\n",
      "=== epoch:7, train acc:0.958, test acc:0.955 ===, time:  114.10611486434937\n",
      "train loss:0.1558899257324788\n",
      "train loss:0.11042723389644714\n",
      "train loss:0.15192576520935255\n",
      "train loss:0.25291244476749003\n",
      "train loss:0.07900489853180777\n",
      "train loss:0.08813616612230099\n",
      "train loss:0.08949387102837077\n",
      "train loss:0.08682595519274372\n",
      "train loss:0.13119257944787394\n",
      "train loss:0.17845400551468418\n",
      "train loss:0.0913107344967145\n",
      "train loss:0.11339203828766552\n",
      "train loss:0.13791692533292138\n",
      "train loss:0.07183140826567999\n",
      "train loss:0.15586089844939616\n",
      "train loss:0.07548675391243262\n",
      "train loss:0.08183911751416843\n",
      "train loss:0.1116945347340706\n",
      "train loss:0.2035937927923865\n",
      "train loss:0.07511433908969967\n",
      "train loss:0.2515641526495347\n",
      "train loss:0.10463922869449288\n",
      "train loss:0.10439333678550308\n",
      "train loss:0.27680885553109336\n",
      "train loss:0.05986153036872393\n",
      "train loss:0.16133718387284224\n",
      "train loss:0.05895436571725134\n",
      "train loss:0.14096705042393212\n",
      "train loss:0.11801667046574763\n",
      "train loss:0.13971229423280324\n",
      "train loss:0.21513417707196122\n",
      "train loss:0.08437151174387916\n",
      "train loss:0.08642374989679275\n",
      "train loss:0.1077129516862403\n",
      "train loss:0.1748669611867212\n",
      "train loss:0.09988933195793027\n",
      "train loss:0.08395685536138822\n",
      "train loss:0.19395947603153002\n",
      "train loss:0.14299198545783917\n",
      "train loss:0.09779817527604838\n",
      "train loss:0.06948099605478783\n",
      "train loss:0.1765342055425859\n",
      "train loss:0.19742549379176913\n",
      "train loss:0.11078919986600322\n",
      "train loss:0.11309519953017036\n",
      "train loss:0.14299519467471716\n",
      "train loss:0.11167833160722175\n",
      "train loss:0.27714002181788855\n",
      "train loss:0.17069136412440425\n",
      "train loss:0.0875290317639683\n",
      "train loss:0.1844572445223542\n",
      "train loss:0.10759364866560989\n",
      "train loss:0.0988120447077884\n",
      "train loss:0.1377889338164066\n",
      "train loss:0.07917977292131656\n",
      "train loss:0.20376951305757662\n",
      "train loss:0.10132893598408989\n",
      "train loss:0.19285748366157718\n",
      "train loss:0.08837270803738657\n",
      "train loss:0.0788160116437415\n",
      "train loss:0.08048625583847718\n",
      "train loss:0.08291601789708668\n",
      "train loss:0.17298606525953109\n",
      "train loss:0.07575674683232421\n",
      "train loss:0.10099971113744534\n",
      "train loss:0.13406113431055602\n",
      "train loss:0.1337201081454719\n",
      "train loss:0.18629345073109388\n",
      "train loss:0.06867528403706809\n",
      "train loss:0.11963373483042693\n",
      "train loss:0.20908267063648908\n",
      "train loss:0.1388194897041905\n",
      "train loss:0.13629834554966405\n",
      "train loss:0.06696582660207126\n",
      "train loss:0.20905071308592127\n",
      "train loss:0.05328729020286291\n",
      "train loss:0.07524565329828353\n",
      "train loss:0.1438288902450654\n",
      "train loss:0.21492700929073055\n",
      "train loss:0.23783630272509795\n",
      "train loss:0.14436734719032931\n",
      "train loss:0.13500959833207482\n",
      "train loss:0.06419072289881672\n",
      "train loss:0.1910069927306368\n",
      "train loss:0.09184094152345837\n",
      "train loss:0.12276848974332744\n",
      "train loss:0.10435870221571934\n",
      "train loss:0.09826787145441354\n",
      "train loss:0.10538148704807435\n",
      "train loss:0.10779285156883553\n",
      "train loss:0.11533064464302707\n",
      "train loss:0.10611867536712685\n",
      "train loss:0.14646893611606362\n",
      "train loss:0.20190682030279244\n",
      "train loss:0.09357446907977417\n",
      "train loss:0.10258758829061279\n",
      "train loss:0.14712071972850085\n",
      "train loss:0.09350978243473629\n",
      "train loss:0.11576393148849394\n",
      "train loss:0.11867582862562105\n",
      "train loss:0.03251326540263172\n",
      "train loss:0.10459543668578396\n",
      "train loss:0.06676450900559167\n",
      "train loss:0.16851008551051355\n",
      "train loss:0.1062099288036757\n",
      "train loss:0.14690732983564167\n",
      "train loss:0.04813789919440247\n",
      "train loss:0.16026543244126376\n",
      "train loss:0.17623754593748497\n",
      "train loss:0.10695096866531024\n",
      "train loss:0.1093685664256819\n",
      "train loss:0.09283778728464354\n",
      "train loss:0.06858065034219181\n",
      "train loss:0.07352092329879442\n",
      "train loss:0.17037402187764117\n",
      "train loss:0.09639531602839557\n",
      "train loss:0.07790960574295155\n",
      "train loss:0.17662699768448475\n",
      "train loss:0.2982656517155842\n",
      "train loss:0.08137284979631801\n",
      "train loss:0.1255651470941801\n",
      "train loss:0.17170342938494643\n",
      "train loss:0.15226925417245923\n",
      "train loss:0.11391873829555232\n",
      "train loss:0.16600393888892204\n",
      "train loss:0.10175621057785175\n",
      "train loss:0.0768416766223293\n",
      "train loss:0.12289634189786117\n",
      "train loss:0.09830638909971755\n",
      "train loss:0.07912901377949634\n",
      "train loss:0.120806323068525\n",
      "train loss:0.04630436548561704\n",
      "train loss:0.1513063696155129\n",
      "train loss:0.25851674969802724\n",
      "train loss:0.05863479125254851\n",
      "train loss:0.13339976035483952\n",
      "train loss:0.13801755308266\n",
      "train loss:0.09771510911825601\n",
      "train loss:0.0664930586527514\n",
      "train loss:0.08765112042734739\n",
      "train loss:0.06464138839618784\n",
      "train loss:0.09283683413915739\n",
      "train loss:0.08660986445777405\n",
      "train loss:0.1374698867351772\n",
      "train loss:0.0834060020433931\n",
      "train loss:0.10705395691050583\n",
      "train loss:0.1790411067052239\n",
      "train loss:0.09505913057186016\n",
      "train loss:0.1296688377577964\n",
      "train loss:0.11454319860661383\n",
      "train loss:0.0649206313857047\n",
      "train loss:0.22438720318858046\n",
      "train loss:0.15567796590785973\n",
      "train loss:0.09367780996864716\n",
      "train loss:0.09448926126946104\n",
      "train loss:0.1343645528522922\n",
      "train loss:0.05532162135650712\n",
      "train loss:0.20935021215403737\n",
      "train loss:0.09861587152653202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06577425605018865\n",
      "train loss:0.0762856840545527\n",
      "train loss:0.21343785572386287\n",
      "train loss:0.14082510983408508\n",
      "train loss:0.05712201425312351\n",
      "train loss:0.1181510394182031\n",
      "train loss:0.20963444111436805\n",
      "train loss:0.13470627248142916\n",
      "train loss:0.04403852909332829\n",
      "train loss:0.121635630253198\n",
      "train loss:0.1119451558260332\n",
      "train loss:0.057871622036072747\n",
      "train loss:0.1608100172768025\n",
      "train loss:0.11583635060178032\n",
      "train loss:0.1263827149295005\n",
      "train loss:0.09762261762225005\n",
      "train loss:0.17409095838167754\n",
      "train loss:0.06889005746107885\n",
      "train loss:0.10782516930562693\n",
      "train loss:0.04227348687601993\n",
      "train loss:0.17101024822480906\n",
      "train loss:0.08726619190889302\n",
      "train loss:0.09863665273970425\n",
      "train loss:0.229019259380887\n",
      "train loss:0.11302325061821467\n",
      "train loss:0.20440051740623652\n",
      "train loss:0.09381194131069874\n",
      "train loss:0.18878287882012337\n",
      "train loss:0.0865636097057353\n",
      "train loss:0.08256924235522003\n",
      "train loss:0.04945116541944803\n",
      "train loss:0.1386226101755887\n",
      "train loss:0.13910907411303092\n",
      "train loss:0.06399945649119543\n",
      "train loss:0.11650301272467332\n",
      "train loss:0.15081648773600567\n",
      "train loss:0.15981437424108957\n",
      "train loss:0.1870978741077863\n",
      "train loss:0.19666113125063903\n",
      "train loss:0.04677153300287259\n",
      "train loss:0.045525120649734276\n",
      "train loss:0.18940537713073297\n",
      "train loss:0.10694324050315329\n",
      "train loss:0.13121730942085758\n",
      "train loss:0.04533219489618937\n",
      "train loss:0.14868012731102975\n",
      "train loss:0.13608601945020088\n",
      "train loss:0.04833146083908464\n",
      "train loss:0.07441027644875904\n",
      "train loss:0.16110986276246428\n",
      "train loss:0.11347035492328626\n",
      "train loss:0.051682597430254405\n",
      "train loss:0.152560629542421\n",
      "train loss:0.17761287644792748\n",
      "train loss:0.11110038314205078\n",
      "train loss:0.10634275342448189\n",
      "train loss:0.04755361090281296\n",
      "train loss:0.12233192300028171\n",
      "train loss:0.06403949685048818\n",
      "train loss:0.07939550770196357\n",
      "train loss:0.21143441526307147\n",
      "train loss:0.07664712177032583\n",
      "train loss:0.08930533557302552\n",
      "train loss:0.15125996512197318\n",
      "train loss:0.18500580097762384\n",
      "train loss:0.23632287012841607\n",
      "train loss:0.1080970847176841\n",
      "train loss:0.1240510037198482\n",
      "train loss:0.14879086021793062\n",
      "train loss:0.14726304800887097\n",
      "train loss:0.0780271585618277\n",
      "train loss:0.12059928972149782\n",
      "train loss:0.14070927728209479\n",
      "train loss:0.13841055613182898\n",
      "train loss:0.13993338425905263\n",
      "train loss:0.09478951308105525\n",
      "train loss:0.12983191584490536\n",
      "train loss:0.12763702484950867\n",
      "train loss:0.06185234673127261\n",
      "train loss:0.079074314280939\n",
      "train loss:0.06521685143363537\n",
      "train loss:0.1445247993373466\n",
      "train loss:0.08761071517168581\n",
      "train loss:0.07259957100253507\n",
      "train loss:0.09073939794669802\n",
      "train loss:0.1752243174970173\n",
      "train loss:0.1046100689813937\n",
      "train loss:0.10375762233589737\n",
      "train loss:0.13297464211076993\n",
      "train loss:0.03142942772981341\n",
      "train loss:0.09117617479245471\n",
      "train loss:0.03540563854837224\n",
      "train loss:0.07590488828567193\n",
      "train loss:0.08657626312117453\n",
      "train loss:0.05431602217956184\n",
      "train loss:0.20545468171396317\n",
      "train loss:0.10020478753309944\n",
      "train loss:0.11180164042921131\n",
      "train loss:0.0840200755903347\n",
      "train loss:0.09757185333501953\n",
      "train loss:0.028094464432754904\n",
      "train loss:0.050435067320554444\n",
      "train loss:0.14198776512100564\n",
      "train loss:0.08991765733105715\n",
      "train loss:0.15584156110983202\n",
      "train loss:0.05404511598927182\n",
      "train loss:0.14696327376795598\n",
      "train loss:0.25486762715376515\n",
      "train loss:0.10018164252486587\n",
      "train loss:0.1809717588301151\n",
      "train loss:0.10319119226251057\n",
      "train loss:0.11544604518736837\n",
      "train loss:0.10056342973831646\n",
      "train loss:0.17430892342861437\n",
      "train loss:0.05478150106554149\n",
      "train loss:0.10029246265879616\n",
      "train loss:0.1290436604423194\n",
      "train loss:0.15930246962686376\n",
      "train loss:0.09599042550931056\n",
      "train loss:0.05589279850795652\n",
      "train loss:0.13031149615601956\n",
      "train loss:0.13889481271248144\n",
      "train loss:0.04742638321904497\n",
      "train loss:0.13802990439940033\n",
      "train loss:0.11446981182076882\n",
      "train loss:0.16351652861878754\n",
      "train loss:0.2262628735303338\n",
      "train loss:0.10853209246616709\n",
      "train loss:0.161589246937727\n",
      "train loss:0.10987347097571012\n",
      "train loss:0.15377160571254936\n",
      "train loss:0.14295531527201263\n",
      "train loss:0.12255147948332965\n",
      "train loss:0.08355339904212776\n",
      "train loss:0.07519819113363468\n",
      "train loss:0.07500451614804395\n",
      "train loss:0.08157558341905471\n",
      "train loss:0.10321231660898357\n",
      "train loss:0.0670731013411756\n",
      "train loss:0.09772966832921476\n",
      "train loss:0.133578418630121\n",
      "train loss:0.0562521190760888\n",
      "train loss:0.12926488054546703\n",
      "train loss:0.07905027555200916\n",
      "train loss:0.1028024737651336\n",
      "train loss:0.09619408202012053\n",
      "train loss:0.09234727403594746\n",
      "train loss:0.17929982712001696\n",
      "train loss:0.14603394934790875\n",
      "train loss:0.07013930243197775\n",
      "train loss:0.15487604823516432\n",
      "train loss:0.26075777607949396\n",
      "train loss:0.06448445412616573\n",
      "train loss:0.06694847409355983\n",
      "train loss:0.108610059947762\n",
      "train loss:0.1463054572373583\n",
      "train loss:0.07055673553195323\n",
      "train loss:0.13944004851229708\n",
      "train loss:0.07675850159963163\n",
      "train loss:0.14794421682680073\n",
      "train loss:0.1331972806494263\n",
      "train loss:0.10744291413292975\n",
      "train loss:0.19198060632447972\n",
      "train loss:0.046309514158290314\n",
      "train loss:0.09788275061233516\n",
      "train loss:0.18115727080874894\n",
      "train loss:0.05361062848014374\n",
      "train loss:0.20069068235430962\n",
      "train loss:0.11579856219126348\n",
      "train loss:0.18095638796097005\n",
      "train loss:0.20151469024506988\n",
      "train loss:0.10378121746304973\n",
      "train loss:0.08956779678114048\n",
      "train loss:0.02341164376476114\n",
      "train loss:0.1945468389331295\n",
      "train loss:0.17284562223464775\n",
      "train loss:0.13769222325105981\n",
      "train loss:0.06489231968960157\n",
      "train loss:0.0629630261090165\n",
      "train loss:0.09929036831367709\n",
      "train loss:0.27124005600867424\n",
      "train loss:0.12531368557730327\n",
      "train loss:0.1667513294335189\n",
      "train loss:0.07348394872700068\n",
      "train loss:0.10010353216157515\n",
      "train loss:0.139301205714652\n",
      "train loss:0.19542225866831966\n",
      "train loss:0.13812270900972087\n",
      "train loss:0.11495047711075009\n",
      "train loss:0.09389527017078853\n",
      "train loss:0.0594567690718127\n",
      "train loss:0.07386513329309094\n",
      "train loss:0.05810152203557429\n",
      "train loss:0.10597143758100462\n",
      "train loss:0.0953594890557696\n",
      "train loss:0.07585459026789901\n",
      "train loss:0.0315395467172191\n",
      "train loss:0.1627405067701325\n",
      "train loss:0.08394586641553285\n",
      "train loss:0.1607651315477035\n",
      "train loss:0.16709597465264825\n",
      "train loss:0.14188975681518307\n",
      "train loss:0.14202360120960159\n",
      "train loss:0.10808285853447576\n",
      "train loss:0.11595846683417013\n",
      "train loss:0.21612367403987942\n",
      "train loss:0.18133395769414073\n",
      "train loss:0.13544581540016426\n",
      "train loss:0.09391025695881032\n",
      "train loss:0.10367528995019538\n",
      "train loss:0.12980460081973233\n",
      "train loss:0.12727440759300654\n",
      "train loss:0.09287214971262242\n",
      "train loss:0.12783526341560703\n",
      "train loss:0.05945376788464551\n",
      "train loss:0.10664761259336751\n",
      "train loss:0.06456568287687608\n",
      "train loss:0.20349490916022483\n",
      "train loss:0.11181601279853082\n",
      "train loss:0.07859948428339904\n",
      "train loss:0.10654537510738725\n",
      "train loss:0.11328240448566884\n",
      "train loss:0.05480839858801559\n",
      "train loss:0.14883883518270966\n",
      "train loss:0.16153779047606168\n",
      "train loss:0.1906916492471478\n",
      "train loss:0.056765672192902634\n",
      "train loss:0.07619632366893683\n",
      "train loss:0.11007350054782565\n",
      "train loss:0.07363704683098261\n",
      "train loss:0.12942074777259682\n",
      "train loss:0.15148959130280817\n",
      "train loss:0.12884199935785579\n",
      "train loss:0.09691623409168874\n",
      "train loss:0.12239309986933922\n",
      "train loss:0.06707544031542616\n",
      "train loss:0.028254986231611892\n",
      "train loss:0.06399235511751986\n",
      "train loss:0.06370751871568549\n",
      "train loss:0.05944146161260874\n",
      "train loss:0.1891353926902377\n",
      "train loss:0.09600470136115845\n",
      "train loss:0.10525278787274361\n",
      "train loss:0.09885984474380102\n",
      "train loss:0.11249478764672158\n",
      "train loss:0.05274595109445191\n",
      "train loss:0.07250692710507574\n",
      "train loss:0.04547326891121155\n",
      "train loss:0.1450776839482893\n",
      "train loss:0.20292142848023142\n",
      "train loss:0.0663157053780395\n",
      "train loss:0.13827650309429193\n",
      "train loss:0.07830037047560649\n",
      "train loss:0.09418423051813404\n",
      "train loss:0.14835175327049252\n",
      "train loss:0.04059652601034434\n",
      "train loss:0.06945907821134262\n",
      "train loss:0.1573361219337309\n",
      "train loss:0.18393088245302225\n",
      "train loss:0.08843167846204412\n",
      "train loss:0.11344175035467345\n",
      "train loss:0.14653185608842506\n",
      "train loss:0.07133641781455809\n",
      "train loss:0.022997320176811678\n",
      "train loss:0.09875473396239723\n",
      "train loss:0.022061774338615517\n",
      "train loss:0.15000388021103825\n",
      "train loss:0.20286910878184486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.043994211030032176\n",
      "train loss:0.08353220426153156\n",
      "train loss:0.10483986482654173\n",
      "train loss:0.10572551044977824\n",
      "train loss:0.10665119984408308\n",
      "train loss:0.21507018824827534\n",
      "train loss:0.16764475521791483\n",
      "train loss:0.11716624937633424\n",
      "train loss:0.10436980775305742\n",
      "train loss:0.08232835155290796\n",
      "train loss:0.07301971627836938\n",
      "train loss:0.1824808424998138\n",
      "train loss:0.1110512507516889\n",
      "train loss:0.06036717801544014\n",
      "train loss:0.05905789805179691\n",
      "train loss:0.14477614230096278\n",
      "train loss:0.07498784962738797\n",
      "train loss:0.2728603526200862\n",
      "train loss:0.1165162895969983\n",
      "train loss:0.023133925095643076\n",
      "train loss:0.16170782309174708\n",
      "train loss:0.27295552815021107\n",
      "train loss:0.09584690533730131\n",
      "train loss:0.05094991567866127\n",
      "train loss:0.08909018595849467\n",
      "train loss:0.05474172782436429\n",
      "train loss:0.11170471361626881\n",
      "train loss:0.0682714747394732\n",
      "train loss:0.16936249320590865\n",
      "train loss:0.10159673940438699\n",
      "train loss:0.11587729283042622\n",
      "train loss:0.07160308121898816\n",
      "train loss:0.03706540191854972\n",
      "train loss:0.21697362025002054\n",
      "train loss:0.1129999859919815\n",
      "train loss:0.03879866741286677\n",
      "train loss:0.09841572042403005\n",
      "train loss:0.07623494121430135\n",
      "train loss:0.08478778218277315\n",
      "train loss:0.10728756644190686\n",
      "train loss:0.0689935599819072\n",
      "train loss:0.0683107809913876\n",
      "train loss:0.13843930423353537\n",
      "train loss:0.1450086136069039\n",
      "train loss:0.19482691256993195\n",
      "train loss:0.05731726729069453\n",
      "train loss:0.2757858217874238\n",
      "train loss:0.14400639565504122\n",
      "train loss:0.09371606712159412\n",
      "train loss:0.12819233741808353\n",
      "train loss:0.07648653037836285\n",
      "train loss:0.06605101542115502\n",
      "train loss:0.08271429863579013\n",
      "train loss:0.08907937300345563\n",
      "train loss:0.1047127082084939\n",
      "train loss:0.147348705591616\n",
      "train loss:0.07752658998458851\n",
      "train loss:0.06781845351617004\n",
      "train loss:0.1467412784959615\n",
      "train loss:0.07168487026246484\n",
      "train loss:0.10233953671124545\n",
      "train loss:0.0691248851510363\n",
      "train loss:0.09963745771966889\n",
      "train loss:0.10834518504036789\n",
      "train loss:0.07310015572447227\n",
      "train loss:0.06312787203908045\n",
      "train loss:0.11738092974909753\n",
      "train loss:0.051778608747695486\n",
      "train loss:0.25099640714349225\n",
      "train loss:0.084321381783406\n",
      "train loss:0.07287182469592816\n",
      "train loss:0.14057050415395828\n",
      "train loss:0.16609394299276134\n",
      "train loss:0.08016508689383979\n",
      "train loss:0.025256200198771606\n",
      "train loss:0.08900712263922626\n",
      "train loss:0.07339564378652842\n",
      "train loss:0.10774214663818894\n",
      "train loss:0.13107074602215232\n",
      "train loss:0.12380947718363125\n",
      "train loss:0.1297791125913001\n",
      "train loss:0.12432617771014791\n",
      "train loss:0.09713777199311814\n",
      "train loss:0.05117878227882734\n",
      "train loss:0.06236735681330309\n",
      "train loss:0.10503861367016107\n",
      "train loss:0.10624710402960752\n",
      "train loss:0.21526871714935467\n",
      "train loss:0.08001170586576464\n",
      "train loss:0.10040719082551716\n",
      "train loss:0.12477682724843074\n",
      "train loss:0.11607381867777075\n",
      "train loss:0.17508301810441984\n",
      "train loss:0.14147726575753175\n",
      "train loss:0.12071845430473248\n",
      "train loss:0.11134741119729037\n",
      "train loss:0.15682970351624984\n",
      "train loss:0.11703824195858038\n",
      "train loss:0.08795538816856435\n",
      "train loss:0.1829625728511908\n",
      "train loss:0.07083245652550647\n",
      "train loss:0.12017666808143428\n",
      "train loss:0.05266777547348786\n",
      "train loss:0.11316337227489642\n",
      "train loss:0.057599613909794664\n",
      "train loss:0.16405916863238815\n",
      "train loss:0.14421254791539842\n",
      "train loss:0.07701212578588489\n",
      "train loss:0.1504389938874758\n",
      "train loss:0.12027571474939666\n",
      "train loss:0.09434622463613256\n",
      "train loss:0.16421479793567728\n",
      "train loss:0.09471467597670846\n",
      "train loss:0.09437343392805804\n",
      "train loss:0.17596724578193626\n",
      "train loss:0.15008011727883297\n",
      "train loss:0.09055095020041376\n",
      "train loss:0.08778346011226368\n",
      "train loss:0.07955429443066456\n",
      "train loss:0.09003842785304292\n",
      "train loss:0.12702215929612584\n",
      "train loss:0.09940792263174647\n",
      "train loss:0.10944252867503951\n",
      "train loss:0.11236404266192045\n",
      "train loss:0.20406396109681413\n",
      "train loss:0.10901811318836602\n",
      "train loss:0.11342933243111399\n",
      "train loss:0.19088523725550452\n",
      "train loss:0.05438921277086112\n",
      "train loss:0.07857378098115371\n",
      "train loss:0.08817627993859362\n",
      "train loss:0.17022022156627337\n",
      "train loss:0.11450827903046078\n",
      "train loss:0.03644475177562018\n",
      "train loss:0.08656456518481699\n",
      "train loss:0.15738860565255103\n",
      "train loss:0.1368827813452112\n",
      "train loss:0.06281329626969394\n",
      "train loss:0.193885176425005\n",
      "train loss:0.1448733251698734\n",
      "train loss:0.13121884138127746\n",
      "train loss:0.05894558383794887\n",
      "train loss:0.10044264644110978\n",
      "train loss:0.06536577003647599\n",
      "train loss:0.10348660223153412\n",
      "train loss:0.12758325976498308\n",
      "train loss:0.05696897163339523\n",
      "train loss:0.02732770389833711\n",
      "train loss:0.11783906572102629\n",
      "train loss:0.09300134297604787\n",
      "train loss:0.18994829449340161\n",
      "train loss:0.15257481235900408\n",
      "train loss:0.07761942317429218\n",
      "train loss:0.15470573747645927\n",
      "train loss:0.1964658489496413\n",
      "train loss:0.06317347789739246\n",
      "train loss:0.14153516866206156\n",
      "train loss:0.0587667201430709\n",
      "train loss:0.2641973512696039\n",
      "train loss:0.05900455041847648\n",
      "train loss:0.07342752787323586\n",
      "train loss:0.10364729233668635\n",
      "train loss:0.22219067617315288\n",
      "train loss:0.21039572804446444\n",
      "train loss:0.126724482843738\n",
      "train loss:0.10399193496193648\n",
      "train loss:0.1262962690881547\n",
      "train loss:0.12478159540979285\n",
      "train loss:0.0757394653902956\n",
      "train loss:0.20444666103309683\n",
      "train loss:0.04250631436853835\n",
      "train loss:0.10878258298444901\n",
      "train loss:0.09091055429192281\n",
      "=== epoch:8, train acc:0.963, test acc:0.949 ===, time:  133.14580631256104\n",
      "train loss:0.23457238790002521\n",
      "train loss:0.32692788977160364\n",
      "train loss:0.06341907108285161\n",
      "train loss:0.12569352606191445\n",
      "train loss:0.1645487506640093\n",
      "train loss:0.0871518871557118\n",
      "train loss:0.1524097191747698\n",
      "train loss:0.0475775662136648\n",
      "train loss:0.19583712004272585\n",
      "train loss:0.08910578328328818\n",
      "train loss:0.15090986362405148\n",
      "train loss:0.10796871849716577\n",
      "train loss:0.07448875414255449\n",
      "train loss:0.06482093705753772\n",
      "train loss:0.17070771621423536\n",
      "train loss:0.15485548409102257\n",
      "train loss:0.16989185141005078\n",
      "train loss:0.08913096357584703\n",
      "train loss:0.08806793230264329\n",
      "train loss:0.07484131022059178\n",
      "train loss:0.15366398918331942\n",
      "train loss:0.054157877616664366\n",
      "train loss:0.08842181496032124\n",
      "train loss:0.04922623877115199\n",
      "train loss:0.1807985209257652\n",
      "train loss:0.20919254749872593\n",
      "train loss:0.18749889908106873\n",
      "train loss:0.061238318147311094\n",
      "train loss:0.12198509462123448\n",
      "train loss:0.08974052173240767\n",
      "train loss:0.10362544308946302\n",
      "train loss:0.07849077489216265\n",
      "train loss:0.0918938753761595\n",
      "train loss:0.10622277547681495\n",
      "train loss:0.15277902891146947\n",
      "train loss:0.06822946373735266\n",
      "train loss:0.07974824865218137\n",
      "train loss:0.101776393962397\n",
      "train loss:0.13841690088621383\n",
      "train loss:0.1606333138561453\n",
      "train loss:0.08602009769889564\n",
      "train loss:0.0819279115844178\n",
      "train loss:0.10584847413062354\n",
      "train loss:0.12096937311761695\n",
      "train loss:0.08365274494857321\n",
      "train loss:0.06212480756180685\n",
      "train loss:0.07451444478637213\n",
      "train loss:0.1146254137688654\n",
      "train loss:0.10857744030932025\n",
      "train loss:0.12066177669779057\n",
      "train loss:0.12422415610580248\n",
      "train loss:0.07956192745702195\n",
      "train loss:0.06249027987282124\n",
      "train loss:0.06792296958411809\n",
      "train loss:0.12442194239834686\n",
      "train loss:0.0579018286429655\n",
      "train loss:0.07964541814428025\n",
      "train loss:0.11820066674612806\n",
      "train loss:0.10525160887343663\n",
      "train loss:0.16403475643669385\n",
      "train loss:0.07341532613795788\n",
      "train loss:0.04416557985815537\n",
      "train loss:0.06945890762791718\n",
      "train loss:0.10955597555993554\n",
      "train loss:0.07610809782049718\n",
      "train loss:0.10855347195099987\n",
      "train loss:0.13817890012383044\n",
      "train loss:0.15339463682613105\n",
      "train loss:0.20289054470780324\n",
      "train loss:0.10308130668629577\n",
      "train loss:0.10866782825199768\n",
      "train loss:0.042077427702990014\n",
      "train loss:0.1285800439298906\n",
      "train loss:0.16071891612563147\n",
      "train loss:0.07215640924949132\n",
      "train loss:0.07458062198600976\n",
      "train loss:0.16622277152842557\n",
      "train loss:0.05456191682118515\n",
      "train loss:0.059019070968453956\n",
      "train loss:0.10380759593675475\n",
      "train loss:0.07438617346793702\n",
      "train loss:0.1742293796306322\n",
      "train loss:0.08920725277092306\n",
      "train loss:0.10673401708567105\n",
      "train loss:0.08953641586059373\n",
      "train loss:0.05158539701889464\n",
      "train loss:0.14622479638162483\n",
      "train loss:0.07385704217114879\n",
      "train loss:0.15763689123527447\n",
      "train loss:0.12596441297670188\n",
      "train loss:0.13839688903620076\n",
      "train loss:0.11824268724838292\n",
      "train loss:0.05382666057172121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07373755655236819\n",
      "train loss:0.10106588012372235\n",
      "train loss:0.12494384022127335\n",
      "train loss:0.07327892018407801\n",
      "train loss:0.17601687395431118\n",
      "train loss:0.08720033846737364\n",
      "train loss:0.12274182873880482\n",
      "train loss:0.13137711234853613\n",
      "train loss:0.09744337468116275\n",
      "train loss:0.15742470485560836\n",
      "train loss:0.05605871184232785\n",
      "train loss:0.04532655226752755\n",
      "train loss:0.09304401588098063\n",
      "train loss:0.13179792991748626\n",
      "train loss:0.06456534033398258\n",
      "train loss:0.08722509457544649\n",
      "train loss:0.09079526905829818\n",
      "train loss:0.07815274389373632\n",
      "train loss:0.08770233713383835\n",
      "train loss:0.19130926732800657\n",
      "train loss:0.10298594126696965\n",
      "train loss:0.1613923024411413\n",
      "train loss:0.11284176205690918\n",
      "train loss:0.11189571701294504\n",
      "train loss:0.1344248075430265\n",
      "train loss:0.11178400782312167\n",
      "train loss:0.16274967125172132\n",
      "train loss:0.07063444882445193\n",
      "train loss:0.22865547077073942\n",
      "train loss:0.05722352423928381\n",
      "train loss:0.10874346994359979\n",
      "train loss:0.06278272128167206\n",
      "train loss:0.08173452565563977\n",
      "train loss:0.08389564457420487\n",
      "train loss:0.2707410902425349\n",
      "train loss:0.12844295926976626\n",
      "train loss:0.05010119594802395\n",
      "train loss:0.12401353625135114\n",
      "train loss:0.11881023906335947\n",
      "train loss:0.12843308323672478\n",
      "train loss:0.11327556584157807\n",
      "train loss:0.1585640252051109\n",
      "train loss:0.093974974934444\n",
      "train loss:0.05805890829629448\n",
      "train loss:0.1015078539429847\n",
      "train loss:0.0509367231834313\n",
      "train loss:0.12772432809509882\n",
      "train loss:0.08590553726918322\n",
      "train loss:0.14573342641471643\n",
      "train loss:0.04962229607354462\n",
      "train loss:0.06052065199597798\n",
      "train loss:0.14009057718539297\n",
      "train loss:0.08790618404060004\n",
      "train loss:0.07785233249572417\n",
      "train loss:0.08004434211709839\n",
      "train loss:0.07216144840061757\n",
      "train loss:0.11432216408166766\n",
      "train loss:0.09419134550035252\n",
      "train loss:0.12952354130863142\n",
      "train loss:0.0283107717191224\n",
      "train loss:0.0986952252717392\n",
      "train loss:0.04359983292947022\n",
      "train loss:0.09439661189471195\n",
      "train loss:0.09395060028455106\n",
      "train loss:0.0845080612191025\n",
      "train loss:0.03299924286995787\n",
      "train loss:0.13284325191888396\n",
      "train loss:0.10077995001546801\n",
      "train loss:0.04629293189823645\n",
      "train loss:0.12974668366372527\n",
      "train loss:0.15204347436956453\n",
      "train loss:0.10145845385913972\n",
      "train loss:0.13996270260490948\n",
      "train loss:0.10290900258775774\n",
      "train loss:0.08067823097664548\n",
      "train loss:0.04839123374113008\n",
      "train loss:0.2199815714268401\n",
      "train loss:0.2929068292748989\n",
      "train loss:0.20490944513138132\n",
      "train loss:0.08028483521152228\n",
      "train loss:0.07398275073781183\n",
      "train loss:0.13448821075264383\n",
      "train loss:0.033237101473950786\n",
      "train loss:0.11479095461362174\n",
      "train loss:0.10471569430542749\n",
      "train loss:0.11275425383124484\n",
      "train loss:0.1277718833268086\n",
      "train loss:0.034541471604735224\n",
      "train loss:0.12266191278775213\n",
      "train loss:0.1417182602493045\n",
      "train loss:0.1299498245351211\n",
      "train loss:0.04315880408523348\n",
      "train loss:0.08228532608861115\n",
      "train loss:0.1553443099429621\n",
      "train loss:0.13618860201512198\n",
      "train loss:0.05893768907406412\n",
      "train loss:0.12253568973926839\n",
      "train loss:0.10289522515069813\n",
      "train loss:0.0667572245058436\n",
      "train loss:0.12395850221096007\n",
      "train loss:0.055882906679910756\n",
      "train loss:0.11736420172728904\n",
      "train loss:0.13371463204536696\n",
      "train loss:0.12298106004282658\n",
      "train loss:0.08176209722669471\n",
      "train loss:0.09625195926186844\n",
      "train loss:0.12613175971346344\n",
      "train loss:0.17728377831770842\n",
      "train loss:0.09889177009863667\n",
      "train loss:0.1334573946143436\n",
      "train loss:0.06552914075778989\n",
      "train loss:0.17974975126538328\n",
      "train loss:0.0806035338931507\n",
      "train loss:0.1796627292550456\n",
      "train loss:0.044409385775511984\n",
      "train loss:0.23506142905428992\n",
      "train loss:0.09146452805372368\n",
      "train loss:0.20376651020255285\n",
      "train loss:0.10211689761140302\n",
      "train loss:0.06673102162725991\n",
      "train loss:0.153015328121634\n",
      "train loss:0.10664471943237039\n",
      "train loss:0.11809541824228485\n",
      "train loss:0.17951548973455125\n",
      "train loss:0.15835951682328417\n",
      "train loss:0.06766657559158976\n",
      "train loss:0.07422186533783207\n",
      "train loss:0.08407341396465898\n",
      "train loss:0.10011771268464761\n",
      "train loss:0.14614681941137875\n",
      "train loss:0.15343088159997872\n",
      "train loss:0.1416753499435733\n",
      "train loss:0.06341609417375584\n",
      "train loss:0.18179590034602383\n",
      "train loss:0.11121278810657512\n",
      "train loss:0.19764689058660173\n",
      "train loss:0.12471726956117563\n",
      "train loss:0.0521333029586972\n",
      "train loss:0.031498119431777535\n",
      "train loss:0.059258987570795146\n",
      "train loss:0.05265019910511148\n",
      "train loss:0.08890432496825092\n",
      "train loss:0.06747543202116715\n",
      "train loss:0.11847725812816817\n",
      "train loss:0.0898895931473165\n",
      "train loss:0.11918533891116308\n",
      "train loss:0.061266739069910384\n",
      "train loss:0.1559556794379289\n",
      "train loss:0.0877948064618457\n",
      "train loss:0.1286994839940668\n",
      "train loss:0.01954199737286177\n",
      "train loss:0.20778281522791192\n",
      "train loss:0.0765660551891435\n",
      "train loss:0.10388535848677063\n",
      "train loss:0.0732131720821101\n",
      "train loss:0.263391756842682\n",
      "train loss:0.06867655480440821\n",
      "train loss:0.12351693419224549\n",
      "train loss:0.16947491610642867\n",
      "train loss:0.12411587965575879\n",
      "train loss:0.10369291523234715\n",
      "train loss:0.07487302401260341\n",
      "train loss:0.09835237285055319\n",
      "train loss:0.12700229383835424\n",
      "train loss:0.06423571220356611\n",
      "train loss:0.10453625496227886\n",
      "train loss:0.21382810946901834\n",
      "train loss:0.14241176870745187\n",
      "train loss:0.08411877906809695\n",
      "train loss:0.16161860837419287\n",
      "train loss:0.10993315851372885\n",
      "train loss:0.1483241810862567\n",
      "train loss:0.07292684726173303\n",
      "train loss:0.15928208451494502\n",
      "train loss:0.17352881236779585\n",
      "train loss:0.08209855030726201\n",
      "train loss:0.04929460305420141\n",
      "train loss:0.059859053250009814\n",
      "train loss:0.10847107620597927\n",
      "train loss:0.040916655151585914\n",
      "train loss:0.016596698332694605\n",
      "train loss:0.12514007101955396\n",
      "train loss:0.15515551232363325\n",
      "train loss:0.06778760378548765\n",
      "train loss:0.1059048901324214\n",
      "train loss:0.040897163285731605\n",
      "train loss:0.13300975873886964\n",
      "train loss:0.0627617700925643\n",
      "train loss:0.06770424090097352\n",
      "train loss:0.1130136518000509\n",
      "train loss:0.12449585818441423\n",
      "train loss:0.08374346711570692\n",
      "train loss:0.10328896681878447\n",
      "train loss:0.13928524104697826\n",
      "train loss:0.11339022120853157\n",
      "train loss:0.11136290868258072\n",
      "train loss:0.10072896349235849\n",
      "train loss:0.13743515426126413\n",
      "train loss:0.11840527723653368\n",
      "train loss:0.05152280501374347\n",
      "train loss:0.17281540387279992\n",
      "train loss:0.14882193755556897\n",
      "train loss:0.11217643993188994\n",
      "train loss:0.09850480052326305\n",
      "train loss:0.12262856909736158\n",
      "train loss:0.1445082637964416\n",
      "train loss:0.06041017451945434\n",
      "train loss:0.06950124369873346\n",
      "train loss:0.09747850725537287\n",
      "train loss:0.02272033820289109\n",
      "train loss:0.06913311688612582\n",
      "train loss:0.14602558377077504\n",
      "train loss:0.12554175477011914\n",
      "train loss:0.1054858155597065\n",
      "train loss:0.07154644390933823\n",
      "train loss:0.05948085458387118\n",
      "train loss:0.12187820738965835\n",
      "train loss:0.09202135070399174\n",
      "train loss:0.10820804256923303\n",
      "train loss:0.24202393390261903\n",
      "train loss:0.24954411435779683\n",
      "train loss:0.09762639229051526\n",
      "train loss:0.15987375320192967\n",
      "train loss:0.10101129193460875\n",
      "train loss:0.1032189195687018\n",
      "train loss:0.1674103539786605\n",
      "train loss:0.04802739477612171\n",
      "train loss:0.14768301400431633\n",
      "train loss:0.06838251135725235\n",
      "train loss:0.10714351893733573\n",
      "train loss:0.060606586473131545\n",
      "train loss:0.08103326130977707\n",
      "train loss:0.10636580162300517\n",
      "train loss:0.11954083660096729\n",
      "train loss:0.17120897509799002\n",
      "train loss:0.09592052048117143\n",
      "train loss:0.09542903584294679\n",
      "train loss:0.09284971615190822\n",
      "train loss:0.171277708561031\n",
      "train loss:0.05727117967279411\n",
      "train loss:0.05046444741846165\n",
      "train loss:0.1620558313370368\n",
      "train loss:0.056656376821773755\n",
      "train loss:0.08587323922300102\n",
      "train loss:0.06305653928149973\n",
      "train loss:0.10370826945570161\n",
      "train loss:0.13721779035921386\n",
      "train loss:0.10352555362196242\n",
      "train loss:0.05605089168384278\n",
      "train loss:0.0358142591133602\n",
      "train loss:0.06401043763253524\n",
      "train loss:0.17144465401558848\n",
      "train loss:0.03910300479452849\n",
      "train loss:0.14285016969318665\n",
      "train loss:0.11285681494972248\n",
      "train loss:0.09735739066926305\n",
      "train loss:0.17156112183853597\n",
      "train loss:0.10332340160198003\n",
      "train loss:0.06176511659189907\n",
      "train loss:0.18257932124383938\n",
      "train loss:0.11922727605295792\n",
      "train loss:0.07674044598540547\n",
      "train loss:0.10411025421033912\n",
      "train loss:0.15019866586149352\n",
      "train loss:0.19569743541259071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10051199380580302\n",
      "train loss:0.061715697284847264\n",
      "train loss:0.06785148097657215\n",
      "train loss:0.0845493259276851\n",
      "train loss:0.10230632695880486\n",
      "train loss:0.06034909597921714\n",
      "train loss:0.08923843637512753\n",
      "train loss:0.15903994909483554\n",
      "train loss:0.07283354866340311\n",
      "train loss:0.21263356713673975\n",
      "train loss:0.16072662650858802\n",
      "train loss:0.12807034780250684\n",
      "train loss:0.052786627699684736\n",
      "train loss:0.16637556257308742\n",
      "train loss:0.08257386496291227\n",
      "train loss:0.10687640189357937\n",
      "train loss:0.13152866784741102\n",
      "train loss:0.08030679938328361\n",
      "train loss:0.15022382152973324\n",
      "train loss:0.08320682494081633\n",
      "train loss:0.069567158512218\n",
      "train loss:0.05957378818802188\n",
      "train loss:0.14676309601405058\n",
      "train loss:0.09255703502786534\n",
      "train loss:0.1072304588691359\n",
      "train loss:0.07365302559518361\n",
      "train loss:0.03651259491835805\n",
      "train loss:0.09466113318064862\n",
      "train loss:0.1755263720637477\n",
      "train loss:0.05689143965693175\n",
      "train loss:0.06634415089612784\n",
      "train loss:0.14728706167936922\n",
      "train loss:0.10718939353483281\n",
      "train loss:0.07999642119373028\n",
      "train loss:0.1307399819996029\n",
      "train loss:0.07599824074757852\n",
      "train loss:0.15594873077604357\n",
      "train loss:0.17586906941300579\n",
      "train loss:0.11255006116491949\n",
      "train loss:0.1222614972556481\n",
      "train loss:0.050972840778473076\n",
      "train loss:0.16411452093057544\n",
      "train loss:0.10761127633576688\n",
      "train loss:0.05596105177586892\n",
      "train loss:0.12771706011002376\n",
      "train loss:0.12126854971941228\n",
      "train loss:0.21675952260808032\n",
      "train loss:0.17386368203612193\n",
      "train loss:0.08757247187007092\n",
      "train loss:0.13776770893624954\n",
      "train loss:0.0834542542947148\n",
      "train loss:0.02936032279235769\n",
      "train loss:0.04128407358464304\n",
      "train loss:0.05986142534187036\n",
      "train loss:0.10407951693032126\n",
      "train loss:0.12683451982247576\n",
      "train loss:0.1823735162011788\n",
      "train loss:0.07403374918813617\n",
      "train loss:0.05471048146602957\n",
      "train loss:0.14506851298351114\n",
      "train loss:0.10396491001612475\n",
      "train loss:0.06689320014689326\n",
      "train loss:0.07988561220523994\n",
      "train loss:0.054100252676348604\n",
      "train loss:0.042469324635290476\n",
      "train loss:0.07337409900994021\n",
      "train loss:0.1424753005538949\n",
      "train loss:0.12558013079194896\n",
      "train loss:0.05552714207774307\n",
      "train loss:0.13451530871183523\n",
      "train loss:0.1524614711541898\n",
      "train loss:0.11317044112839952\n",
      "train loss:0.038411611547937825\n",
      "train loss:0.02770554393870321\n",
      "train loss:0.0781202742032131\n",
      "train loss:0.074065417067976\n",
      "train loss:0.15367343552639462\n",
      "train loss:0.11929273446847674\n",
      "train loss:0.06433686466749704\n",
      "train loss:0.09766250780593962\n",
      "train loss:0.05988620179360865\n",
      "train loss:0.11168709179447807\n",
      "train loss:0.11835281053074292\n",
      "train loss:0.08834571780469953\n",
      "train loss:0.12113391370144252\n",
      "train loss:0.1354499312949029\n",
      "train loss:0.12425327821368418\n",
      "train loss:0.08766571361348077\n",
      "train loss:0.0722550685429002\n",
      "train loss:0.11345631622350644\n",
      "train loss:0.04280791380745372\n",
      "train loss:0.14860607349547567\n",
      "train loss:0.11727985941839902\n",
      "train loss:0.15501885745596558\n",
      "train loss:0.08510957023802457\n",
      "train loss:0.11363547339015342\n",
      "train loss:0.1194551482079588\n",
      "train loss:0.2732840430012341\n",
      "train loss:0.11225137942701391\n",
      "train loss:0.11408863319193452\n",
      "train loss:0.0786711638874094\n",
      "train loss:0.07634316376383592\n",
      "train loss:0.11235610652117936\n",
      "train loss:0.10990018447747524\n",
      "train loss:0.16049957606885407\n",
      "train loss:0.061005876244127226\n",
      "train loss:0.09646570436673972\n",
      "train loss:0.1305192249264207\n",
      "train loss:0.10177072199554077\n",
      "train loss:0.08573193873599727\n",
      "train loss:0.055548175880628055\n",
      "train loss:0.19071699255055072\n",
      "train loss:0.057832931026462225\n",
      "train loss:0.08915987768691223\n",
      "train loss:0.04983953180944347\n",
      "train loss:0.06456499220097901\n",
      "train loss:0.04738462358533449\n",
      "train loss:0.0601656404652479\n",
      "train loss:0.06744991186558752\n",
      "train loss:0.05680166954004329\n",
      "train loss:0.07763862965926753\n",
      "train loss:0.14739162289886448\n",
      "train loss:0.0964866955757123\n",
      "train loss:0.08237315070758468\n",
      "train loss:0.10274013602552139\n",
      "train loss:0.14444642248155848\n",
      "train loss:0.1490346638534656\n",
      "train loss:0.17531264264917923\n",
      "train loss:0.1246100935160477\n",
      "train loss:0.08969098668742471\n",
      "train loss:0.10824642417590816\n",
      "train loss:0.13597680587841773\n",
      "train loss:0.13624522198469596\n",
      "train loss:0.12554902076978466\n",
      "train loss:0.10455706224914676\n",
      "train loss:0.11252146557608342\n",
      "train loss:0.07340680794671037\n",
      "train loss:0.0435970601279092\n",
      "train loss:0.1214864763448544\n",
      "train loss:0.08428719577823136\n",
      "train loss:0.05117641171599242\n",
      "train loss:0.15071262232601126\n",
      "train loss:0.07696829344537583\n",
      "train loss:0.0708841738603597\n",
      "train loss:0.13785448545022488\n",
      "train loss:0.0508702875679524\n",
      "train loss:0.0804010762261259\n",
      "train loss:0.07301968430940348\n",
      "train loss:0.09811007338993435\n",
      "train loss:0.10341546608317788\n",
      "train loss:0.13191729145009634\n",
      "train loss:0.04581706495118574\n",
      "train loss:0.1389984096338423\n",
      "train loss:0.0707690538701768\n",
      "train loss:0.07383296041269793\n",
      "train loss:0.036166019369486754\n",
      "train loss:0.12838296720692743\n",
      "train loss:0.144212878613015\n",
      "train loss:0.10396301943564171\n",
      "train loss:0.059197033087402436\n",
      "train loss:0.08487715465473201\n",
      "train loss:0.1310776045650873\n",
      "train loss:0.14773153527362065\n",
      "train loss:0.15574048760258977\n",
      "train loss:0.18932714846891724\n",
      "train loss:0.10191728283223057\n",
      "train loss:0.10423463026590431\n",
      "train loss:0.15989511275481974\n",
      "train loss:0.06318336664595198\n",
      "train loss:0.128249885133793\n",
      "train loss:0.10322237163636334\n",
      "train loss:0.07290648249100347\n",
      "train loss:0.06405166205164028\n",
      "train loss:0.23236762943652473\n",
      "train loss:0.03645018167464184\n",
      "train loss:0.1607226861480221\n",
      "train loss:0.1067493577072007\n",
      "train loss:0.07144373790277549\n",
      "train loss:0.08692921261597364\n",
      "train loss:0.087432678748252\n",
      "train loss:0.12361253339970536\n",
      "train loss:0.06254563641939086\n",
      "train loss:0.08858892591101487\n",
      "train loss:0.13129226321876997\n",
      "train loss:0.1029136528318247\n",
      "train loss:0.05482969338387439\n",
      "train loss:0.05923196987286384\n",
      "train loss:0.1318828367814412\n",
      "train loss:0.04318696179825768\n",
      "train loss:0.057106821945987665\n",
      "train loss:0.10190900969135479\n",
      "train loss:0.09124751217987828\n",
      "train loss:0.13923292607725904\n",
      "train loss:0.06211614725028532\n",
      "train loss:0.08755408480670342\n",
      "train loss:0.072743103271716\n",
      "train loss:0.11870962750725872\n",
      "train loss:0.06418632476629478\n",
      "train loss:0.09590156953841694\n",
      "train loss:0.10602362316353124\n",
      "train loss:0.16206207359689348\n",
      "train loss:0.12623571392159763\n",
      "train loss:0.09323127276874571\n",
      "train loss:0.04811179682184305\n",
      "train loss:0.09308425110400603\n",
      "train loss:0.05564490791279691\n",
      "train loss:0.1572091961620479\n",
      "train loss:0.02275241616777029\n",
      "train loss:0.09486188295495283\n",
      "train loss:0.07221374009963158\n",
      "train loss:0.14333268075355263\n",
      "train loss:0.12891508272286795\n",
      "train loss:0.16793538808262945\n",
      "train loss:0.0701264035551746\n",
      "train loss:0.07769850483108369\n",
      "train loss:0.030797318220208033\n",
      "train loss:0.1389853860576351\n",
      "train loss:0.05060706009520418\n",
      "train loss:0.03912412841380377\n",
      "train loss:0.09495371085357857\n",
      "train loss:0.10457248979733422\n",
      "train loss:0.07825756960293297\n",
      "train loss:0.04773615359707725\n",
      "train loss:0.14739682674597104\n",
      "train loss:0.18406055497478874\n",
      "train loss:0.0837182456906851\n",
      "train loss:0.136507444529803\n",
      "train loss:0.045572887436106393\n",
      "train loss:0.22709086858715305\n",
      "train loss:0.050064871952485275\n",
      "train loss:0.07475073021391275\n",
      "train loss:0.08052841546160737\n",
      "train loss:0.08675335027003568\n",
      "train loss:0.056235620909733476\n",
      "train loss:0.13763075785031842\n",
      "train loss:0.1062201782766547\n",
      "train loss:0.10627255250178747\n",
      "train loss:0.08552023813693642\n",
      "train loss:0.18592462885161837\n",
      "train loss:0.06822458314155228\n",
      "train loss:0.04462352895197739\n",
      "train loss:0.10166617021257972\n",
      "=== epoch:9, train acc:0.962, test acc:0.955 ===, time:  152.97432041168213\n",
      "train loss:0.09213104700522246\n",
      "train loss:0.05902671548928326\n",
      "train loss:0.06945699787381059\n",
      "train loss:0.09767086388130158\n",
      "train loss:0.10211339934215373\n",
      "train loss:0.06523647656925582\n",
      "train loss:0.08418976222018854\n",
      "train loss:0.09899224652394337\n",
      "train loss:0.09789667199281117\n",
      "train loss:0.25421115285176876\n",
      "train loss:0.16192125529386744\n",
      "train loss:0.12254413183525034\n",
      "train loss:0.1558910145576896\n",
      "train loss:0.14318684136389373\n",
      "train loss:0.04980181462209603\n",
      "train loss:0.09650071184411851\n",
      "train loss:0.09058848236908829\n",
      "train loss:0.1538632116098081\n",
      "train loss:0.04436006380785325\n",
      "train loss:0.043585529399865174\n",
      "train loss:0.12063370275855678\n",
      "train loss:0.06139906608447662\n",
      "train loss:0.1088854610472513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.058601678547971464\n",
      "train loss:0.12336913869852864\n",
      "train loss:0.09781010244054503\n",
      "train loss:0.13755877959060916\n",
      "train loss:0.09337914066407653\n",
      "train loss:0.07560636052750593\n",
      "train loss:0.07928165746376326\n",
      "train loss:0.07650643073896574\n",
      "train loss:0.18007769092639536\n",
      "train loss:0.1242247078878115\n",
      "train loss:0.10220353396950184\n",
      "train loss:0.1343155480877977\n",
      "train loss:0.0852508242782512\n",
      "train loss:0.11715155553479888\n",
      "train loss:0.05794184177324097\n",
      "train loss:0.0869897364608822\n",
      "train loss:0.1653052786111825\n",
      "train loss:0.08056780049947487\n",
      "train loss:0.06568440220380785\n",
      "train loss:0.09106521736215255\n",
      "train loss:0.08125353916264558\n",
      "train loss:0.14424180788789978\n",
      "train loss:0.17576125365504516\n",
      "train loss:0.16705266013832545\n",
      "train loss:0.0724225558897503\n",
      "train loss:0.12487187531930527\n",
      "train loss:0.06709993603439356\n",
      "train loss:0.058652142834514774\n",
      "train loss:0.13864224248472015\n",
      "train loss:0.10875389609760563\n",
      "train loss:0.05240462174689608\n",
      "train loss:0.11300997746413816\n",
      "train loss:0.09292341038140157\n",
      "train loss:0.12789204222080647\n",
      "train loss:0.132942891801951\n",
      "train loss:0.07955821099471702\n",
      "train loss:0.22029004434839627\n",
      "train loss:0.10068927455589176\n",
      "train loss:0.08395818763775079\n",
      "train loss:0.04386434925412761\n",
      "train loss:0.09085078159164663\n",
      "train loss:0.04858356604553263\n",
      "train loss:0.06537933051615143\n",
      "train loss:0.0983819468465608\n",
      "train loss:0.07161288155273059\n",
      "train loss:0.11209522963694508\n",
      "train loss:0.06715758345058767\n",
      "train loss:0.10888692570983141\n",
      "train loss:0.0782323280885557\n",
      "train loss:0.09696019007131525\n",
      "train loss:0.1806667201706283\n",
      "train loss:0.07503295369567564\n",
      "train loss:0.05231024071342084\n",
      "train loss:0.06781281318325799\n",
      "train loss:0.11544795659985665\n",
      "train loss:0.03723043029510015\n",
      "train loss:0.14858546950200835\n",
      "train loss:0.04269637601879876\n",
      "train loss:0.10808949810121084\n",
      "train loss:0.09809200859239421\n",
      "train loss:0.12288419757791652\n",
      "train loss:0.11333057495993641\n",
      "train loss:0.0659698088762456\n",
      "train loss:0.05212095906495682\n",
      "train loss:0.11517552153563976\n",
      "train loss:0.12507427503211832\n",
      "train loss:0.12054286490660662\n",
      "train loss:0.15244805279284915\n",
      "train loss:0.06314840419784347\n",
      "train loss:0.12157920366856584\n",
      "train loss:0.10478172853159169\n",
      "train loss:0.04293873214911317\n",
      "train loss:0.08525870001929395\n",
      "train loss:0.11855430044491864\n",
      "train loss:0.07954354922143933\n",
      "train loss:0.11307869769893628\n",
      "train loss:0.11116724638029296\n",
      "train loss:0.08440263295376318\n",
      "train loss:0.10018825524008156\n",
      "train loss:0.06294908034956931\n",
      "train loss:0.03425427329024156\n",
      "train loss:0.0677015767350054\n",
      "train loss:0.13811725187820253\n",
      "train loss:0.1741601951870325\n",
      "train loss:0.07286791960800533\n",
      "train loss:0.06271864247501541\n",
      "train loss:0.04065663177836409\n",
      "train loss:0.11557665462347731\n",
      "train loss:0.13369547545218796\n",
      "train loss:0.06168227003699757\n",
      "train loss:0.12116601676714646\n",
      "train loss:0.061515675651135006\n",
      "train loss:0.07181842633115325\n",
      "train loss:0.02537647970474057\n",
      "train loss:0.14466698309171164\n",
      "train loss:0.09583643198316992\n",
      "train loss:0.12835438533581928\n",
      "train loss:0.04006383092579293\n",
      "train loss:0.1871386820270309\n",
      "train loss:0.09565869738006844\n",
      "train loss:0.09759934301058847\n",
      "train loss:0.09894287853055772\n",
      "train loss:0.09683501008103806\n",
      "train loss:0.07827031167740146\n",
      "train loss:0.08902460090856615\n",
      "train loss:0.08866783496538588\n",
      "train loss:0.07722422578256151\n",
      "train loss:0.06270612919716419\n",
      "train loss:0.0741187346443822\n",
      "train loss:0.08777644138166561\n",
      "train loss:0.07581512749737197\n",
      "train loss:0.10420072570791548\n",
      "train loss:0.1403577684830642\n",
      "train loss:0.08041134252209657\n",
      "train loss:0.047180772694253824\n",
      "train loss:0.11419029115943735\n",
      "train loss:0.053124970048135725\n",
      "train loss:0.15943151220037585\n",
      "train loss:0.05490435123747691\n",
      "train loss:0.057770130429326\n",
      "train loss:0.04882247445803287\n",
      "train loss:0.2499426825804695\n",
      "train loss:0.06893785083434642\n",
      "train loss:0.1556389788145911\n",
      "train loss:0.09568964109306384\n",
      "train loss:0.08467683360015772\n",
      "train loss:0.03602791618717989\n",
      "train loss:0.10079843088550522\n",
      "train loss:0.09572980733976647\n",
      "train loss:0.08170247564925852\n",
      "train loss:0.06795186520006229\n",
      "train loss:0.18366918185281564\n",
      "train loss:0.15943967351131463\n",
      "train loss:0.040346489071496384\n",
      "train loss:0.05234552537973612\n",
      "train loss:0.08992683854193326\n",
      "train loss:0.061901330215087126\n",
      "train loss:0.08740507188678809\n",
      "train loss:0.07061660412339094\n",
      "train loss:0.10885357031608306\n",
      "train loss:0.10796314075463409\n",
      "train loss:0.10493091613452533\n",
      "train loss:0.18238443014170408\n",
      "train loss:0.06084306061561838\n",
      "train loss:0.10774989518743489\n",
      "train loss:0.09922850665262471\n",
      "train loss:0.07843074606152639\n",
      "train loss:0.03857111590739236\n",
      "train loss:0.12004680908823946\n",
      "train loss:0.09181755933913865\n",
      "train loss:0.15939094012571198\n",
      "train loss:0.09903111099555653\n",
      "train loss:0.14171522719989885\n",
      "train loss:0.06520743260877626\n",
      "train loss:0.04092442712465164\n",
      "train loss:0.08933891240414338\n",
      "train loss:0.025952950256856577\n",
      "train loss:0.06435987341758699\n",
      "train loss:0.04730270533269214\n",
      "train loss:0.1774923305028708\n",
      "train loss:0.11995430084533804\n",
      "train loss:0.10663047487531813\n",
      "train loss:0.02907711966118983\n",
      "train loss:0.05123381844068335\n",
      "train loss:0.09729324057725236\n",
      "train loss:0.07596303531586014\n",
      "train loss:0.10473822928368481\n",
      "train loss:0.09763955491999657\n",
      "train loss:0.09678439825857417\n",
      "train loss:0.17554518970325586\n",
      "train loss:0.09817956267060285\n",
      "train loss:0.2520259189410499\n",
      "train loss:0.048714093899750066\n",
      "train loss:0.12667867204198224\n",
      "train loss:0.13007123119747951\n",
      "train loss:0.04531328241426969\n",
      "train loss:0.048569936078796935\n",
      "train loss:0.07051524742179616\n",
      "train loss:0.030558459521697244\n",
      "train loss:0.08600399133342002\n",
      "train loss:0.053592907117760644\n",
      "train loss:0.05847878476154631\n",
      "train loss:0.047918313849857584\n",
      "train loss:0.051358920317994536\n",
      "train loss:0.06135327405646062\n",
      "train loss:0.051292590588968796\n",
      "train loss:0.07729944592698347\n",
      "train loss:0.06447593073836776\n",
      "train loss:0.05814182602249216\n",
      "train loss:0.21193503932942015\n",
      "train loss:0.17800222340608457\n",
      "train loss:0.08545266858133489\n",
      "train loss:0.10450919310589107\n",
      "train loss:0.10185492081646365\n",
      "train loss:0.2957905976895941\n",
      "train loss:0.11723144994061499\n",
      "train loss:0.09330429755008243\n",
      "train loss:0.05795722338428235\n",
      "train loss:0.13079017302758802\n",
      "train loss:0.1673259978914663\n",
      "train loss:0.16877977092694735\n",
      "train loss:0.10507370040435336\n",
      "train loss:0.0809857808078079\n",
      "train loss:0.05053634406142638\n",
      "train loss:0.03807284773190482\n",
      "train loss:0.20072307287831495\n",
      "train loss:0.10931715648568856\n",
      "train loss:0.0995074608159789\n",
      "train loss:0.09263396038475373\n",
      "train loss:0.08090486301436581\n",
      "train loss:0.12479208732148912\n",
      "train loss:0.08096414329988041\n",
      "train loss:0.0499181710787577\n",
      "train loss:0.07535235803298583\n",
      "train loss:0.03903436820096727\n",
      "train loss:0.07365091035021598\n",
      "train loss:0.20777179623408956\n",
      "train loss:0.14847145994999672\n",
      "train loss:0.1291785081724125\n",
      "train loss:0.11161761366356736\n",
      "train loss:0.17269983197410724\n",
      "train loss:0.0498997679001403\n",
      "train loss:0.05273089668654976\n",
      "train loss:0.0490620321511317\n",
      "train loss:0.06156743697036271\n",
      "train loss:0.10657796656962072\n",
      "train loss:0.05848326674084938\n",
      "train loss:0.06975915797038315\n",
      "train loss:0.09914511864746903\n",
      "train loss:0.08290504493999734\n",
      "train loss:0.04434102932756161\n",
      "train loss:0.06442091237502895\n",
      "train loss:0.19683775346172488\n",
      "train loss:0.06160524659791127\n",
      "train loss:0.06352447819442887\n",
      "train loss:0.178823803258669\n",
      "train loss:0.09481095017904063\n",
      "train loss:0.1276652735600085\n",
      "train loss:0.09892106994454158\n",
      "train loss:0.02969882435578446\n",
      "train loss:0.15643571211926421\n",
      "train loss:0.15949895795454538\n",
      "train loss:0.031636516488003336\n",
      "train loss:0.0763001485763374\n",
      "train loss:0.11386412369575974\n",
      "train loss:0.08506942018368922\n",
      "train loss:0.08396377217569716\n",
      "train loss:0.0652781206350041\n",
      "train loss:0.08009642038157973\n",
      "train loss:0.03011377966562876\n",
      "train loss:0.18461853144194534\n",
      "train loss:0.07738648408876593\n",
      "train loss:0.1406115075833389\n",
      "train loss:0.1323482341230694\n",
      "train loss:0.14367246678892015\n",
      "train loss:0.10325614780321186\n",
      "train loss:0.11325342463702345\n",
      "train loss:0.032165793954816134\n",
      "train loss:0.22115925668817393\n",
      "train loss:0.09215818299471437\n",
      "train loss:0.06648525441634909\n",
      "train loss:0.08115593760882218\n",
      "train loss:0.14130969421374426\n",
      "train loss:0.0940864160466715\n",
      "train loss:0.15430474244070724\n",
      "train loss:0.07292368923138307\n",
      "train loss:0.03901225515699299\n",
      "train loss:0.024497539635716447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.13315988004180926\n",
      "train loss:0.1920932070858999\n",
      "train loss:0.11562862361228542\n",
      "train loss:0.06532412458506241\n",
      "train loss:0.05806307304105248\n",
      "train loss:0.12991573862383754\n",
      "train loss:0.14967219585243058\n",
      "train loss:0.06428142934287537\n",
      "train loss:0.05010749353637123\n",
      "train loss:0.052092315556002744\n",
      "train loss:0.07810978252925213\n",
      "train loss:0.07389106596370401\n",
      "train loss:0.10947695753928594\n",
      "train loss:0.06156562467414502\n",
      "train loss:0.12934252796722565\n",
      "train loss:0.08228545948233121\n",
      "train loss:0.0963465269179486\n",
      "train loss:0.16297910771953983\n",
      "train loss:0.08789970101610885\n",
      "train loss:0.07816657605878316\n",
      "train loss:0.11123897629660684\n",
      "train loss:0.08293547771600798\n",
      "train loss:0.07132505726488399\n",
      "train loss:0.06638559160211223\n",
      "train loss:0.05778853942676889\n",
      "train loss:0.12104365663105973\n",
      "train loss:0.15254356683335593\n",
      "train loss:0.13473799823974553\n",
      "train loss:0.07310227145673998\n",
      "train loss:0.08465548556045961\n",
      "train loss:0.16750900797629825\n",
      "train loss:0.11947765540493657\n",
      "train loss:0.06758840218012428\n",
      "train loss:0.07813526166220483\n",
      "train loss:0.04178601287948403\n",
      "train loss:0.039754526897959025\n",
      "train loss:0.09442617502852474\n",
      "train loss:0.041404915431955874\n",
      "train loss:0.09834262713405321\n",
      "train loss:0.09064809706396997\n",
      "train loss:0.05457017365132926\n",
      "train loss:0.07360242290542666\n",
      "train loss:0.08096577089670424\n",
      "train loss:0.14437948889163596\n",
      "train loss:0.07567864871453289\n",
      "train loss:0.10300505967888529\n",
      "train loss:0.09391006262003296\n",
      "train loss:0.0667977493475274\n",
      "train loss:0.04977755481886669\n",
      "train loss:0.06392801963949432\n",
      "train loss:0.08843478726256658\n",
      "train loss:0.1613098298869663\n",
      "train loss:0.05699554658979162\n",
      "train loss:0.1163152338407538\n",
      "train loss:0.07294397780049039\n",
      "train loss:0.13092580558217395\n",
      "train loss:0.07956991971233769\n",
      "train loss:0.1582595057300469\n",
      "train loss:0.05337397448650817\n",
      "train loss:0.10982058058881083\n",
      "train loss:0.1648878257832785\n",
      "train loss:0.09845454613467529\n",
      "train loss:0.09424217801644931\n",
      "train loss:0.11925305858559357\n",
      "train loss:0.07992406673085706\n",
      "train loss:0.09603667957707271\n",
      "train loss:0.14697205777711048\n",
      "train loss:0.16844543781137644\n",
      "train loss:0.036623048401685045\n",
      "train loss:0.19428633595086897\n",
      "train loss:0.07660183874002671\n",
      "train loss:0.11320704433323779\n",
      "train loss:0.1151289967389802\n",
      "train loss:0.07936894540641298\n",
      "train loss:0.05348395632610067\n",
      "train loss:0.060786776360343284\n",
      "train loss:0.11367032234501068\n",
      "train loss:0.0830887833263347\n",
      "train loss:0.21153233693119358\n",
      "train loss:0.1340846750325715\n",
      "train loss:0.07973275844378536\n",
      "train loss:0.06405987835764111\n",
      "train loss:0.05158201772800561\n",
      "train loss:0.11218737077549196\n",
      "train loss:0.12861734993407622\n",
      "train loss:0.06327145926484662\n",
      "train loss:0.09860207864243259\n",
      "train loss:0.022394880759630004\n",
      "train loss:0.023659270388313836\n",
      "train loss:0.15231948873410864\n",
      "train loss:0.19161114598828974\n",
      "train loss:0.10701369037622754\n",
      "train loss:0.07817253116739903\n",
      "train loss:0.08340963394419028\n",
      "train loss:0.14801432270541107\n",
      "train loss:0.07303055455760747\n",
      "train loss:0.03033222722508726\n",
      "train loss:0.08597148761147869\n",
      "train loss:0.07185317653628105\n",
      "train loss:0.10903069434235603\n",
      "train loss:0.039089121166977076\n",
      "train loss:0.15676877668941008\n",
      "train loss:0.11290590788544787\n",
      "train loss:0.04425013739665232\n",
      "train loss:0.09057929425037425\n",
      "train loss:0.11478718457302946\n",
      "train loss:0.16087361831490432\n",
      "train loss:0.05483142167996512\n",
      "train loss:0.07928873432954042\n",
      "train loss:0.1702274197961013\n",
      "train loss:0.039623148279821246\n",
      "train loss:0.06097944461363167\n",
      "train loss:0.09119764344247877\n",
      "train loss:0.05321238980295624\n",
      "train loss:0.11836140148114163\n",
      "train loss:0.09342673539347493\n",
      "train loss:0.10838508332705736\n",
      "train loss:0.11637072799732577\n",
      "train loss:0.0654459506805412\n",
      "train loss:0.040392287648903624\n",
      "train loss:0.07349464909642156\n",
      "train loss:0.10538883026417269\n",
      "train loss:0.06231670107645359\n",
      "train loss:0.08266418604489706\n",
      "train loss:0.03212152055069583\n",
      "train loss:0.11028392194750895\n",
      "train loss:0.12944444182571319\n",
      "train loss:0.04918719701837892\n",
      "train loss:0.0530305972948291\n",
      "train loss:0.11730689874027167\n",
      "train loss:0.04610424043726699\n",
      "train loss:0.14381115619805532\n",
      "train loss:0.1084361603179884\n",
      "train loss:0.08493982989153101\n",
      "train loss:0.09620937853477302\n",
      "train loss:0.05720898862915866\n",
      "train loss:0.18763424841376686\n",
      "train loss:0.08424831598116295\n",
      "train loss:0.13219902493665422\n",
      "train loss:0.10003681328280634\n",
      "train loss:0.10649092256571904\n",
      "train loss:0.09355693932233182\n",
      "train loss:0.08404885340437473\n",
      "train loss:0.062297005708792874\n",
      "train loss:0.09948965401862951\n",
      "train loss:0.1394492551901089\n",
      "train loss:0.05604686399358009\n",
      "train loss:0.08126793239379121\n",
      "train loss:0.07649836055723318\n",
      "train loss:0.09111112035329866\n",
      "train loss:0.06503860412508766\n",
      "train loss:0.04984122275109826\n",
      "train loss:0.05002691674543816\n",
      "train loss:0.1723353192374777\n",
      "train loss:0.03854421894896021\n",
      "train loss:0.10283297516262524\n",
      "train loss:0.05538598079746767\n",
      "train loss:0.033140622245104806\n",
      "train loss:0.08419442484903447\n",
      "train loss:0.08675373183475052\n",
      "train loss:0.054616440186795435\n",
      "train loss:0.13081261775130107\n",
      "train loss:0.056292137208859734\n",
      "train loss:0.06668259623174128\n",
      "train loss:0.06582187025349506\n",
      "train loss:0.047650722950092136\n",
      "train loss:0.10097530504207115\n",
      "train loss:0.050667045209129256\n",
      "train loss:0.08639387601934753\n",
      "train loss:0.10268817067661509\n",
      "train loss:0.10179507296409847\n",
      "train loss:0.14324431931326045\n",
      "train loss:0.0858877695082437\n",
      "train loss:0.09060940602474045\n",
      "train loss:0.09073204856205304\n",
      "train loss:0.03876511529837664\n",
      "train loss:0.08065841743669551\n",
      "train loss:0.11452993827475969\n",
      "train loss:0.08122592335103317\n",
      "train loss:0.09286182798834856\n",
      "train loss:0.032938106006856725\n",
      "train loss:0.040086707464847056\n",
      "train loss:0.12270350204198835\n",
      "train loss:0.06408036082568828\n",
      "train loss:0.10372263459561969\n",
      "train loss:0.057407532669697676\n",
      "train loss:0.14517673007808074\n",
      "train loss:0.10425648037454559\n",
      "train loss:0.03496294390050117\n",
      "train loss:0.06828375406372195\n",
      "train loss:0.04121366606232508\n",
      "train loss:0.14984839045404305\n",
      "train loss:0.08615891826592458\n",
      "train loss:0.10897254177178015\n",
      "train loss:0.10421676149964522\n",
      "train loss:0.1387272691624496\n",
      "train loss:0.06714338068657316\n",
      "train loss:0.0945095645258206\n",
      "train loss:0.042345361014067634\n",
      "train loss:0.08260781701648179\n",
      "train loss:0.11760339455389475\n",
      "train loss:0.12282295914142205\n",
      "train loss:0.10019893328844075\n",
      "train loss:0.17332031072255627\n",
      "train loss:0.05019207409528666\n",
      "train loss:0.0383000889418143\n",
      "train loss:0.1333534130400179\n",
      "train loss:0.1256686818580286\n",
      "train loss:0.12248887806919105\n",
      "train loss:0.09892219159471019\n",
      "train loss:0.05445953610778237\n",
      "train loss:0.028229837259930474\n",
      "train loss:0.1989197818164301\n",
      "train loss:0.09904358649081163\n",
      "train loss:0.08468952578455263\n",
      "train loss:0.030251809185283404\n",
      "train loss:0.08411903962441132\n",
      "train loss:0.25097604216966024\n",
      "train loss:0.016014478690005753\n",
      "train loss:0.15928880766079917\n",
      "train loss:0.09064196273498977\n",
      "train loss:0.14420558072871767\n",
      "train loss:0.09315579520140592\n",
      "train loss:0.1233318059120653\n",
      "train loss:0.06454414741397341\n",
      "train loss:0.1563066341067054\n",
      "train loss:0.11708534287126242\n",
      "train loss:0.05504208734069583\n",
      "train loss:0.12379550721857266\n",
      "train loss:0.0877695225215034\n",
      "train loss:0.07777546488522354\n",
      "train loss:0.054955378383096\n",
      "train loss:0.05893185518817936\n",
      "train loss:0.17901853597009887\n",
      "train loss:0.07474101333938776\n",
      "train loss:0.022649281771988904\n",
      "train loss:0.17401610094967662\n",
      "train loss:0.1140653889012599\n",
      "train loss:0.0503625235214222\n",
      "train loss:0.04439670787857209\n",
      "train loss:0.07502470314772781\n",
      "train loss:0.042899859868471724\n",
      "train loss:0.2120484598723926\n",
      "train loss:0.10923583260208364\n",
      "train loss:0.12247180113724086\n",
      "train loss:0.06560545094412235\n",
      "train loss:0.18456067220661537\n",
      "train loss:0.06041412534511683\n",
      "train loss:0.1321432973252235\n",
      "train loss:0.07230553963715085\n",
      "train loss:0.1046289364593255\n",
      "train loss:0.10233178952489932\n",
      "train loss:0.08491795238714323\n",
      "train loss:0.08371837300546627\n",
      "train loss:0.08543450167813088\n",
      "train loss:0.0694434639007733\n",
      "train loss:0.08371303218169153\n",
      "train loss:0.25191641910525303\n",
      "train loss:0.04986866174106547\n",
      "train loss:0.22081190916130072\n",
      "train loss:0.12246382022667257\n",
      "train loss:0.09139472719690149\n",
      "train loss:0.07407824169398315\n",
      "train loss:0.2099298832290827\n",
      "train loss:0.11271575139250296\n",
      "train loss:0.12781690394688222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1452470222288392\n",
      "train loss:0.12579077761882107\n",
      "train loss:0.03580562496921311\n",
      "train loss:0.18229559070966972\n",
      "train loss:0.12908367303017262\n",
      "train loss:0.028577116460095548\n",
      "train loss:0.05595919398859021\n",
      "train loss:0.1502959495317694\n",
      "train loss:0.06391630280371027\n",
      "train loss:0.1273754035018229\n",
      "train loss:0.03940879497908892\n",
      "train loss:0.10930224116846982\n",
      "train loss:0.10271264980111044\n",
      "train loss:0.06941090649771123\n",
      "train loss:0.1144086638027483\n",
      "train loss:0.08030285011712321\n",
      "train loss:0.02926214843638411\n",
      "train loss:0.10696252496155538\n",
      "train loss:0.071613131568518\n",
      "train loss:0.08895864359575871\n",
      "train loss:0.049478539569856726\n",
      "train loss:0.07856302992570054\n",
      "train loss:0.1430025352459665\n",
      "train loss:0.04204242667166527\n",
      "train loss:0.1582823320950103\n",
      "train loss:0.15649525805848205\n",
      "train loss:0.09301263449403674\n",
      "train loss:0.07225374514394417\n",
      "train loss:0.15367028594500698\n",
      "train loss:0.12960560368806792\n",
      "train loss:0.1298601574089291\n",
      "train loss:0.07051139153262284\n",
      "train loss:0.06719377036219415\n",
      "train loss:0.05456628669169538\n",
      "train loss:0.06307995647618932\n",
      "train loss:0.08296228465712313\n",
      "train loss:0.0435770286916457\n",
      "train loss:0.0328982005278474\n",
      "train loss:0.09429531463071124\n",
      "train loss:0.03892232797658071\n",
      "train loss:0.10325323337041308\n",
      "train loss:0.16793347738906317\n",
      "train loss:0.22860508966160648\n",
      "=== epoch:10, train acc:0.966, test acc:0.963 ===, time:  172.39638471603394\n",
      "train loss:0.0924721529246945\n",
      "train loss:0.09456355924898441\n",
      "train loss:0.04754208904021251\n",
      "train loss:0.1517065579995293\n",
      "train loss:0.15561291298373012\n",
      "train loss:0.09302265953927087\n",
      "train loss:0.0642817472227409\n",
      "train loss:0.07809293083850931\n",
      "train loss:0.19609300758620904\n",
      "train loss:0.0627760781291841\n",
      "train loss:0.03624647159191199\n",
      "train loss:0.10822818539926458\n",
      "train loss:0.10531184404993663\n",
      "train loss:0.04029761249729824\n",
      "train loss:0.05813819103277326\n",
      "train loss:0.037399524688554134\n",
      "train loss:0.10199458730825234\n",
      "train loss:0.0795640375821995\n",
      "train loss:0.1254046086871543\n",
      "train loss:0.11679391084759755\n",
      "train loss:0.04451923896516476\n",
      "train loss:0.046208044899878994\n",
      "train loss:0.19023468263585014\n",
      "train loss:0.13492285113631564\n",
      "train loss:0.03023472089383406\n",
      "train loss:0.09627092727214658\n",
      "train loss:0.04128320558539797\n",
      "train loss:0.06499702675438951\n",
      "train loss:0.026221005377287283\n",
      "train loss:0.052333402908484074\n",
      "train loss:0.12528995111970953\n",
      "train loss:0.09117196979529049\n",
      "train loss:0.05476808993983275\n",
      "train loss:0.0661937672760597\n",
      "train loss:0.14365277583845396\n",
      "train loss:0.04338944329180777\n",
      "train loss:0.06276626676638998\n",
      "train loss:0.12591369765861127\n",
      "train loss:0.05162623078865448\n",
      "train loss:0.0862478988140418\n",
      "train loss:0.05322269543146714\n",
      "train loss:0.12153021138301963\n",
      "train loss:0.09407494789601907\n",
      "train loss:0.04470700533190094\n",
      "train loss:0.07014227288303845\n",
      "train loss:0.1338777469592506\n",
      "train loss:0.14786006748159947\n",
      "train loss:0.052724830727936205\n",
      "train loss:0.13746212046942527\n",
      "train loss:0.05917461341890639\n",
      "train loss:0.14689134502726836\n",
      "train loss:0.06988225479790343\n",
      "train loss:0.15153065979413619\n",
      "train loss:0.04177168774147644\n",
      "train loss:0.13754016903991043\n",
      "train loss:0.2605690822546304\n",
      "train loss:0.13115843670898317\n",
      "train loss:0.1292512984003201\n",
      "train loss:0.06173442779944899\n",
      "train loss:0.12321342157868015\n",
      "train loss:0.09787402636677062\n",
      "train loss:0.10921719919919642\n",
      "train loss:0.04348208491007435\n",
      "train loss:0.08875688803010247\n",
      "train loss:0.15347860067173025\n",
      "train loss:0.08110757973469296\n",
      "train loss:0.05932228037438486\n",
      "train loss:0.09375510499125694\n",
      "train loss:0.11224595149699265\n",
      "train loss:0.03431801444194017\n",
      "train loss:0.05498199605765595\n",
      "train loss:0.102125261517293\n",
      "train loss:0.07804213757019651\n",
      "train loss:0.1011363534554727\n",
      "train loss:0.11827985671653178\n",
      "train loss:0.02752318744448778\n",
      "train loss:0.13478942463760524\n",
      "train loss:0.0767336031673222\n",
      "train loss:0.028495636436466323\n",
      "train loss:0.07077044296414176\n",
      "train loss:0.05584907387245454\n",
      "train loss:0.11558305200976582\n",
      "train loss:0.12568310851929854\n",
      "train loss:0.04873059908260286\n",
      "train loss:0.08564265447235452\n",
      "train loss:0.10758697616221319\n",
      "train loss:0.062051811957322574\n",
      "train loss:0.07479854271971048\n",
      "train loss:0.05856253402940306\n",
      "train loss:0.15165868817507497\n",
      "train loss:0.05039221447882053\n",
      "train loss:0.08168570017409497\n",
      "train loss:0.06675770078029876\n",
      "train loss:0.08698168410448855\n",
      "train loss:0.09511402126222392\n",
      "train loss:0.07827498703654096\n",
      "train loss:0.046860151330630144\n",
      "train loss:0.08054144704330098\n",
      "train loss:0.1662681124142327\n",
      "train loss:0.1257486125167512\n",
      "train loss:0.07439638981157187\n",
      "train loss:0.05377246400707738\n",
      "train loss:0.06045145410373233\n",
      "train loss:0.043126737342853626\n",
      "train loss:0.07401009725298281\n",
      "train loss:0.09578731821736237\n",
      "train loss:0.09292039515186121\n",
      "train loss:0.10093829775479936\n",
      "train loss:0.10967919028089362\n",
      "train loss:0.15429858208306357\n",
      "train loss:0.15282659190724215\n",
      "train loss:0.1098858569259128\n",
      "train loss:0.03673765723925029\n",
      "train loss:0.08001281272999344\n",
      "train loss:0.11010061921163665\n",
      "train loss:0.09798388945834674\n",
      "train loss:0.11283220572978886\n",
      "train loss:0.07322125722432264\n",
      "train loss:0.10755243854647852\n",
      "train loss:0.044889380871348555\n",
      "train loss:0.0857478700579868\n",
      "train loss:0.1126485281414077\n",
      "train loss:0.05893614196694659\n",
      "train loss:0.06589313858419686\n",
      "train loss:0.11748731058805499\n",
      "train loss:0.12470782316225927\n",
      "train loss:0.10602180044805895\n",
      "train loss:0.03957636529696341\n",
      "train loss:0.05489460314731225\n",
      "train loss:0.11494541375712304\n",
      "train loss:0.04037140921900595\n",
      "train loss:0.043778647064845695\n",
      "train loss:0.1530866434110613\n",
      "train loss:0.05983748958499763\n",
      "train loss:0.09095390262557931\n",
      "train loss:0.15591535943692592\n",
      "train loss:0.15004736532162863\n",
      "train loss:0.22219117084547158\n",
      "train loss:0.07706085444647047\n",
      "train loss:0.08181406565692952\n",
      "train loss:0.05351676474305217\n",
      "train loss:0.06166068951555357\n",
      "train loss:0.16174742548341686\n",
      "train loss:0.03384218369614731\n",
      "train loss:0.03885307049432852\n",
      "train loss:0.11521797720574661\n",
      "train loss:0.035542756507194594\n",
      "train loss:0.11189211401832021\n",
      "train loss:0.06069750216300267\n",
      "train loss:0.08702392291990278\n",
      "train loss:0.08123406035646268\n",
      "train loss:0.04018193370957244\n",
      "train loss:0.044527559105570394\n",
      "train loss:0.03432616848236036\n",
      "train loss:0.05505391112868614\n",
      "train loss:0.11292579594923507\n",
      "train loss:0.10230100716708349\n",
      "train loss:0.08560210678380221\n",
      "train loss:0.15971868525937163\n",
      "train loss:0.15638618297998538\n",
      "train loss:0.09296196202584416\n",
      "train loss:0.13034020742745472\n",
      "train loss:0.09328791165083457\n",
      "train loss:0.08682915821744772\n",
      "train loss:0.05413578316387357\n",
      "train loss:0.03240256566361135\n",
      "train loss:0.17319837536981683\n",
      "train loss:0.03749744780491781\n",
      "train loss:0.04978224648210506\n",
      "train loss:0.07858958196997183\n",
      "train loss:0.048627682057805405\n",
      "train loss:0.057371097923613376\n",
      "train loss:0.08405729196822044\n",
      "train loss:0.15797175881743455\n",
      "train loss:0.15895877786553597\n",
      "train loss:0.11505380489948346\n",
      "train loss:0.02604683957172606\n",
      "train loss:0.170915180428931\n",
      "train loss:0.13828402651983165\n",
      "train loss:0.034575804241023175\n",
      "train loss:0.11134021718949558\n",
      "train loss:0.09739261957895405\n",
      "train loss:0.14057580362182662\n",
      "train loss:0.08224431790894908\n",
      "train loss:0.04880935763035766\n",
      "train loss:0.10137213685422647\n",
      "train loss:0.09951987013475128\n",
      "train loss:0.0985888166881138\n",
      "train loss:0.056921409901485726\n",
      "train loss:0.07516052637178164\n",
      "train loss:0.06831814350841084\n",
      "train loss:0.18074857518497073\n",
      "train loss:0.048527136625335726\n",
      "train loss:0.04679105151460159\n",
      "train loss:0.0603202579212318\n",
      "train loss:0.05709019400207584\n",
      "train loss:0.027328248980076943\n",
      "train loss:0.09189317629033457\n",
      "train loss:0.1873958419412105\n",
      "train loss:0.04350843541436396\n",
      "train loss:0.14399391525114594\n",
      "train loss:0.05666185546049798\n",
      "train loss:0.07740498531398116\n",
      "train loss:0.11116926381430199\n",
      "train loss:0.04233001263071103\n",
      "train loss:0.09114208482629081\n",
      "train loss:0.1517728885251493\n",
      "train loss:0.1341180405337426\n",
      "train loss:0.04199741684133676\n",
      "train loss:0.0582631782554877\n",
      "train loss:0.1290773774071127\n",
      "train loss:0.04796422294073597\n",
      "train loss:0.05668254187542229\n",
      "train loss:0.09036193979214863\n",
      "train loss:0.13015229465227837\n",
      "train loss:0.04337794778724691\n",
      "train loss:0.059604062108206415\n",
      "train loss:0.02864992045401301\n",
      "train loss:0.12737271484249002\n",
      "train loss:0.10622790709394289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.16399596615854783\n",
      "train loss:0.1904151311061047\n",
      "train loss:0.05104341179106269\n",
      "train loss:0.03249177816151882\n",
      "train loss:0.06894028400489698\n",
      "train loss:0.04766478723985814\n",
      "train loss:0.016864425218258067\n",
      "train loss:0.08993372583602381\n",
      "train loss:0.12822268894715771\n",
      "train loss:0.039526105460254264\n",
      "train loss:0.07201786459482608\n",
      "train loss:0.07731128911724207\n",
      "train loss:0.0215458309815526\n",
      "train loss:0.17996569062007123\n",
      "train loss:0.13924685579998952\n",
      "train loss:0.08852896977812293\n",
      "train loss:0.056827573875878674\n",
      "train loss:0.0963731768122595\n",
      "train loss:0.036844014849095184\n",
      "train loss:0.09025799509460886\n",
      "train loss:0.11843983727945616\n",
      "train loss:0.09000632679900077\n",
      "train loss:0.12719358756156543\n",
      "train loss:0.16711437438676588\n",
      "train loss:0.07388872056996781\n",
      "train loss:0.0790225457351918\n",
      "train loss:0.07564730336774284\n",
      "train loss:0.06993882622424086\n",
      "train loss:0.07428941547455321\n",
      "train loss:0.16937843250967205\n",
      "train loss:0.13161990365753243\n",
      "train loss:0.10414427685125\n",
      "train loss:0.05178892252519025\n",
      "train loss:0.10963932102160667\n",
      "train loss:0.06764863090734993\n",
      "train loss:0.06321224028819517\n",
      "train loss:0.08510702834904249\n",
      "train loss:0.13550280588392608\n",
      "train loss:0.045978227615393635\n",
      "train loss:0.11313250432578922\n",
      "train loss:0.07191738751585915\n",
      "train loss:0.04795137398025386\n",
      "train loss:0.07109346396053116\n",
      "train loss:0.08639885622464862\n",
      "train loss:0.08119073924087368\n",
      "train loss:0.055849802555920015\n",
      "train loss:0.10134391087467001\n",
      "train loss:0.06381677465542568\n",
      "train loss:0.0812120359125907\n",
      "train loss:0.019600105880908204\n",
      "train loss:0.08130162438656678\n",
      "train loss:0.0371010696838329\n",
      "train loss:0.052054826944909455\n",
      "train loss:0.06389689623550308\n",
      "train loss:0.12544868459884856\n",
      "train loss:0.06443196270258382\n",
      "train loss:0.0434169364238746\n",
      "train loss:0.0997651463309894\n",
      "train loss:0.05981431659249879\n",
      "train loss:0.10083213727063303\n",
      "train loss:0.06349183775824649\n",
      "train loss:0.037896821724146636\n",
      "train loss:0.09795513732544342\n",
      "train loss:0.10365913255785361\n",
      "train loss:0.05758751639770324\n",
      "train loss:0.04945618307003121\n",
      "train loss:0.0608762941205158\n",
      "train loss:0.1550727140684262\n",
      "train loss:0.08586730711660585\n",
      "train loss:0.09742452527175013\n",
      "train loss:0.08331768723992518\n",
      "train loss:0.10224406245669519\n",
      "train loss:0.041341826534702406\n",
      "train loss:0.08811078538866793\n",
      "train loss:0.09547274729301101\n",
      "train loss:0.05980193940558981\n",
      "train loss:0.11800743693357964\n",
      "train loss:0.027680255410096\n",
      "train loss:0.08168555259750049\n",
      "train loss:0.09636689076806125\n",
      "train loss:0.17520737199785938\n",
      "train loss:0.08961118509843292\n",
      "train loss:0.07595125745620195\n",
      "train loss:0.07233881817249489\n",
      "train loss:0.05525681010815974\n",
      "train loss:0.14653613236905808\n",
      "train loss:0.12387695091540538\n",
      "train loss:0.06362581150742058\n",
      "train loss:0.13408416105310764\n",
      "train loss:0.0492200752370052\n",
      "train loss:0.05032615933521374\n",
      "train loss:0.04568853473405911\n",
      "train loss:0.02414339545264693\n",
      "train loss:0.08289193675448096\n",
      "train loss:0.04185335308132143\n",
      "train loss:0.1474346043195151\n",
      "train loss:0.11042088684554599\n",
      "train loss:0.06697650094802153\n",
      "train loss:0.059393686301772004\n",
      "train loss:0.06725451174940697\n",
      "train loss:0.057322279013701564\n",
      "train loss:0.23339393768830713\n",
      "train loss:0.1270832108397779\n",
      "train loss:0.06181680232572107\n",
      "train loss:0.15972193389163222\n",
      "train loss:0.03503768229070898\n",
      "train loss:0.16692006024204573\n",
      "train loss:0.13144297069109095\n",
      "train loss:0.05059832823798613\n",
      "train loss:0.10876476789413711\n",
      "train loss:0.026615919425509237\n",
      "train loss:0.07600778412424913\n",
      "train loss:0.10519367376422778\n",
      "train loss:0.047893458588036925\n",
      "train loss:0.08594074026250308\n",
      "train loss:0.09022159206167821\n",
      "train loss:0.07361498582320508\n",
      "train loss:0.11049120399519037\n",
      "train loss:0.05381319925218188\n",
      "train loss:0.0443895127353721\n",
      "train loss:0.017152829788253124\n",
      "train loss:0.06694652546335393\n",
      "train loss:0.08481884819406582\n",
      "train loss:0.0870817030610756\n",
      "train loss:0.08052771531357544\n",
      "train loss:0.07403381040617775\n",
      "train loss:0.06379336575593189\n",
      "train loss:0.12497912915865907\n",
      "train loss:0.06470795499454192\n",
      "train loss:0.11886619932552991\n",
      "train loss:0.059194040995781794\n",
      "train loss:0.0948674944175231\n",
      "train loss:0.11466319837960609\n",
      "train loss:0.12045105388343959\n",
      "train loss:0.05057048414702586\n",
      "train loss:0.0926570430145044\n",
      "train loss:0.07421330104244732\n",
      "train loss:0.13694900944655017\n",
      "train loss:0.1212552862398218\n",
      "train loss:0.125082738760237\n",
      "train loss:0.0713563642551658\n",
      "train loss:0.04129875366127109\n",
      "train loss:0.23224281520142026\n",
      "train loss:0.13704499251323984\n",
      "train loss:0.05139045541147097\n",
      "train loss:0.09791935060966125\n",
      "train loss:0.09175681484914873\n",
      "train loss:0.05627029989744859\n",
      "train loss:0.06125791150111609\n",
      "train loss:0.0734869509566571\n",
      "train loss:0.09303101440102887\n",
      "train loss:0.13810096225550544\n",
      "train loss:0.14586814708956883\n",
      "train loss:0.07928814714788794\n",
      "train loss:0.04408220467458378\n",
      "train loss:0.15087094986962973\n",
      "train loss:0.04082761754004885\n",
      "train loss:0.12263692590782047\n",
      "train loss:0.049636498119537985\n",
      "train loss:0.10320618333508952\n",
      "train loss:0.061319588613412\n",
      "train loss:0.05338717981088442\n",
      "train loss:0.1734120004592928\n",
      "train loss:0.145898944050128\n",
      "train loss:0.04704095827285914\n",
      "train loss:0.04594306180370524\n",
      "train loss:0.1233616270655925\n",
      "train loss:0.06326571299635647\n",
      "train loss:0.11834244812008318\n",
      "train loss:0.05254599917880576\n",
      "train loss:0.11706114792823712\n",
      "train loss:0.06666114171394444\n",
      "train loss:0.06438685542615709\n",
      "train loss:0.06515771942651616\n",
      "train loss:0.06114405876771581\n",
      "train loss:0.06113318995373183\n",
      "train loss:0.14271775587240992\n",
      "train loss:0.10617840928195772\n",
      "train loss:0.04567077268174028\n",
      "train loss:0.11198412121654808\n",
      "train loss:0.16088456632939374\n",
      "train loss:0.12251809781489603\n",
      "train loss:0.04688179090917349\n",
      "train loss:0.07844984882265309\n",
      "train loss:0.10592065718536517\n",
      "train loss:0.11064200577706748\n",
      "train loss:0.024255247318238006\n",
      "train loss:0.08864899808094596\n",
      "train loss:0.1604267659006147\n",
      "train loss:0.1266148705160914\n",
      "train loss:0.029636404663134885\n",
      "train loss:0.06990389801881862\n",
      "train loss:0.05476437782838767\n",
      "train loss:0.05973354254799115\n",
      "train loss:0.05088986707936224\n",
      "train loss:0.10734261023261558\n",
      "train loss:0.04496483333017005\n",
      "train loss:0.0667064096191561\n",
      "train loss:0.08505026552910885\n",
      "train loss:0.11565536299127134\n",
      "train loss:0.06502147487002823\n",
      "train loss:0.06641412785103862\n",
      "train loss:0.022221272418454542\n",
      "train loss:0.09772837458754056\n",
      "train loss:0.044922965943454546\n",
      "train loss:0.15031856906311702\n",
      "train loss:0.05175162990974247\n",
      "train loss:0.13822995492946036\n",
      "train loss:0.053806610760719575\n",
      "train loss:0.10282017999158448\n",
      "train loss:0.07446781901149563\n",
      "train loss:0.20494709409202647\n",
      "train loss:0.08479876980023898\n",
      "train loss:0.118530981748297\n",
      "train loss:0.05112633143169276\n",
      "train loss:0.09050800738156653\n",
      "train loss:0.08491519229746664\n",
      "train loss:0.0570592226697634\n",
      "train loss:0.07267170118868216\n",
      "train loss:0.05681672844937584\n",
      "train loss:0.10365854678450262\n",
      "train loss:0.06588903213421238\n",
      "train loss:0.06253317139896436\n",
      "train loss:0.07170683560278542\n",
      "train loss:0.09645532883065774\n",
      "train loss:0.1187628932704633\n",
      "train loss:0.060970499970616106\n",
      "train loss:0.08284102299106227\n",
      "train loss:0.14331728085698114\n",
      "train loss:0.079879255124141\n",
      "train loss:0.07115942212765825\n",
      "train loss:0.10191978746142086\n",
      "train loss:0.056048605588986146\n",
      "train loss:0.10544662269335289\n",
      "train loss:0.038376360933172635\n",
      "train loss:0.15662765110268553\n",
      "train loss:0.055375705406908386\n",
      "train loss:0.05577778394706514\n",
      "train loss:0.05604425569789021\n",
      "train loss:0.11885939067786516\n",
      "train loss:0.18018277515008307\n",
      "train loss:0.0858710233292252\n",
      "train loss:0.0777935811477214\n",
      "train loss:0.07927755386624764\n",
      "train loss:0.11911138848159149\n",
      "train loss:0.09528488143413788\n",
      "train loss:0.0586505927567579\n",
      "train loss:0.0480033745749347\n",
      "train loss:0.08010600321075848\n",
      "train loss:0.13777021261717584\n",
      "train loss:0.06191307887140694\n",
      "train loss:0.1388079979917391\n",
      "train loss:0.07719309817003722\n",
      "train loss:0.10012091729051847\n",
      "train loss:0.08968147824007237\n",
      "train loss:0.08855066659312659\n",
      "train loss:0.049202811948225005\n",
      "train loss:0.045140959323915354\n",
      "train loss:0.08311117424196414\n",
      "train loss:0.13206065394143002\n",
      "train loss:0.08251044564607912\n",
      "train loss:0.10589767260976979\n",
      "train loss:0.03580170888581725\n",
      "train loss:0.03250328387876022\n",
      "train loss:0.14554180812995915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07196084476364072\n",
      "train loss:0.08753674547305178\n",
      "train loss:0.043675386139496224\n",
      "train loss:0.11509923117985454\n",
      "train loss:0.12630764719406884\n",
      "train loss:0.10367250836664162\n",
      "train loss:0.08224972978636505\n",
      "train loss:0.11009478808005538\n",
      "train loss:0.0690406241056766\n",
      "train loss:0.08423882439807213\n",
      "train loss:0.04791315878737084\n",
      "train loss:0.04806731597327995\n",
      "train loss:0.03952817366776899\n",
      "train loss:0.048425143555971946\n",
      "train loss:0.05276430235366215\n",
      "train loss:0.0536156851267384\n",
      "train loss:0.07826499908966075\n",
      "train loss:0.06320709901395091\n",
      "train loss:0.14371620387238837\n",
      "train loss:0.014049334179977531\n",
      "train loss:0.05966988443289723\n",
      "train loss:0.15546563950212705\n",
      "train loss:0.14736442360245114\n",
      "train loss:0.07637240241681659\n",
      "train loss:0.05805717916039132\n",
      "train loss:0.05313140291946203\n",
      "train loss:0.185664358611009\n",
      "train loss:0.11781966347713262\n",
      "train loss:0.060240171174414575\n",
      "train loss:0.02993770707804295\n",
      "train loss:0.04255946928976082\n",
      "train loss:0.05248871416853767\n",
      "train loss:0.06894289232893115\n",
      "train loss:0.09644007979720615\n",
      "train loss:0.06338325973611555\n",
      "train loss:0.07669644251167321\n",
      "train loss:0.09563866991549831\n",
      "train loss:0.07963963452447227\n",
      "train loss:0.08652889416015844\n",
      "train loss:0.12035184364239576\n",
      "train loss:0.05728774643011496\n",
      "train loss:0.15894770680299936\n",
      "train loss:0.05309243116018928\n",
      "train loss:0.077668916764135\n",
      "train loss:0.06275428876432705\n",
      "train loss:0.07749675244414701\n",
      "train loss:0.07139843217592773\n",
      "train loss:0.11349485686721471\n",
      "train loss:0.034812040637159467\n",
      "train loss:0.1046993718558768\n",
      "train loss:0.05938287044145801\n",
      "train loss:0.11360090169945099\n",
      "train loss:0.1137740000078849\n",
      "train loss:0.07217885640192734\n",
      "train loss:0.1367393506448304\n",
      "train loss:0.04831237316997912\n",
      "train loss:0.052814316463592394\n",
      "train loss:0.08949959169473265\n",
      "train loss:0.056346605798057794\n",
      "train loss:0.04404066147396126\n",
      "train loss:0.08438026668661358\n",
      "train loss:0.0630495325050693\n",
      "train loss:0.0818502813898978\n",
      "train loss:0.09322564520306215\n",
      "train loss:0.07176200290265969\n",
      "train loss:0.030432043833628776\n",
      "train loss:0.07414543468276664\n",
      "train loss:0.10206976150287182\n",
      "train loss:0.05338668295294695\n",
      "train loss:0.12479206791079403\n",
      "train loss:0.0918164416082534\n",
      "train loss:0.046494477471331556\n",
      "train loss:0.04758032313889401\n",
      "train loss:0.13265383762200103\n",
      "train loss:0.07162088556895212\n",
      "train loss:0.04202709784652025\n",
      "train loss:0.08818757601465567\n",
      "train loss:0.07553857401445647\n",
      "train loss:0.0679021687309694\n",
      "train loss:0.11839878915626115\n",
      "train loss:0.0880234985949964\n",
      "train loss:0.060955818079533576\n",
      "train loss:0.12151225013805089\n",
      "train loss:0.09527672989203227\n",
      "train loss:0.1567530052500872\n",
      "train loss:0.14614947781465498\n",
      "train loss:0.08828607055533717\n",
      "train loss:0.037319796391284\n",
      "train loss:0.06569879365061064\n",
      "train loss:0.045590201803733806\n",
      "train loss:0.14087199363975175\n",
      "train loss:0.10270091301615582\n",
      "train loss:0.08933874073911938\n",
      "train loss:0.10475063687535352\n",
      "train loss:0.16894422539634146\n",
      "train loss:0.055617559160199566\n",
      "train loss:0.0650336513512479\n",
      "train loss:0.09254773068714252\n",
      "train loss:0.13261362258650566\n",
      "train loss:0.07270347476438295\n",
      "train loss:0.03607563606435676\n",
      "train loss:0.05908312829610577\n",
      "train loss:0.14478050937960926\n",
      "train loss:0.04542481910663332\n",
      "train loss:0.08040214585796851\n",
      "train loss:0.16649430433547313\n",
      "train loss:0.1770457455927957\n",
      "train loss:0.037904086523857995\n",
      "train loss:0.05570045820877189\n",
      "train loss:0.09306554541524292\n",
      "train loss:0.08315720918927182\n",
      "train loss:0.04270410351962072\n",
      "train loss:0.0770790178646942\n",
      "train loss:0.13407226871895087\n",
      "train loss:0.03972377362394447\n",
      "=== epoch:11, train acc:0.962, test acc:0.962 ===, time:  192.04379558563232\n",
      "train loss:0.08062279937477608\n",
      "train loss:0.04162348871705101\n",
      "train loss:0.10401098647057283\n",
      "train loss:0.056303534026325874\n",
      "train loss:0.09180147016649377\n",
      "train loss:0.04716954726591356\n",
      "train loss:0.09741057622501641\n",
      "train loss:0.07649663966572176\n",
      "train loss:0.09798716397613397\n",
      "train loss:0.03463905009656657\n",
      "train loss:0.05786874925425039\n",
      "train loss:0.1224669595444965\n",
      "train loss:0.03624615092517265\n",
      "train loss:0.08125367436703634\n",
      "train loss:0.08153665682856637\n",
      "train loss:0.08264242739736818\n",
      "train loss:0.12447192228419285\n",
      "train loss:0.0769519382195775\n",
      "train loss:0.10689974624186434\n",
      "train loss:0.10015894498101341\n",
      "train loss:0.07287417683862586\n",
      "train loss:0.13518277957800082\n",
      "train loss:0.07702772804444043\n",
      "train loss:0.12140343001848963\n",
      "train loss:0.06822358932620103\n",
      "train loss:0.047905916990031126\n",
      "train loss:0.06551008346266018\n",
      "train loss:0.13194369608091047\n",
      "train loss:0.04410723596790899\n",
      "train loss:0.10217780978396147\n",
      "train loss:0.10053155485226468\n",
      "train loss:0.034104497687026634\n",
      "train loss:0.18488456327146177\n",
      "train loss:0.08539899140690574\n",
      "train loss:0.05086069910755946\n",
      "train loss:0.12557596399011625\n",
      "train loss:0.054080572274774946\n",
      "train loss:0.03285895257566758\n",
      "train loss:0.10723689194485424\n",
      "train loss:0.11747177097943712\n",
      "train loss:0.04665054871645895\n",
      "train loss:0.043626967656088755\n",
      "train loss:0.12245295451018197\n",
      "train loss:0.061597138332423744\n",
      "train loss:0.04589050262299793\n",
      "train loss:0.21658418563610113\n",
      "train loss:0.02191988071634117\n",
      "train loss:0.053347542250277755\n",
      "train loss:0.08387042724610842\n",
      "train loss:0.13449694165115836\n",
      "train loss:0.13820540174673387\n",
      "train loss:0.14091577820277235\n",
      "train loss:0.09018039486771295\n",
      "train loss:0.05504995069244046\n",
      "train loss:0.12811858910669083\n",
      "train loss:0.0687582687121207\n",
      "train loss:0.05688058771020561\n",
      "train loss:0.08979549789338073\n",
      "train loss:0.11654638070379898\n",
      "train loss:0.07454395240696839\n",
      "train loss:0.10104803139398344\n",
      "train loss:0.05290532776404864\n",
      "train loss:0.1263936437563977\n",
      "train loss:0.03020126817163114\n",
      "train loss:0.10076460265084837\n",
      "train loss:0.1034754056463219\n",
      "train loss:0.10426381907285352\n",
      "train loss:0.06830510015027547\n",
      "train loss:0.08017112478335109\n",
      "train loss:0.03913602925253695\n",
      "train loss:0.06054412149619144\n",
      "train loss:0.06602700206348228\n",
      "train loss:0.09147606280327444\n",
      "train loss:0.05137458785068982\n",
      "train loss:0.056130083161186756\n",
      "train loss:0.14133814135997194\n",
      "train loss:0.09914451624069442\n",
      "train loss:0.07804705677529654\n",
      "train loss:0.0599322354009331\n",
      "train loss:0.08452907123469199\n",
      "train loss:0.04632521774770403\n",
      "train loss:0.09169403416441771\n",
      "train loss:0.05202274371002842\n",
      "train loss:0.10771711131530023\n",
      "train loss:0.09585165409285024\n",
      "train loss:0.1870074657213405\n",
      "train loss:0.17367580595833348\n",
      "train loss:0.02965856559244733\n",
      "train loss:0.13824799667883478\n",
      "train loss:0.04919741408615502\n",
      "train loss:0.08295323223192166\n",
      "train loss:0.13428483422386328\n",
      "train loss:0.14336330472645956\n",
      "train loss:0.13939035486742032\n",
      "train loss:0.0925966847277596\n",
      "train loss:0.04330306272505315\n",
      "train loss:0.04754221263707833\n",
      "train loss:0.04389328362188365\n",
      "train loss:0.12366289710417178\n",
      "train loss:0.08844599678320052\n",
      "train loss:0.11788789850533256\n",
      "train loss:0.13040199497656113\n",
      "train loss:0.09902702212428545\n",
      "train loss:0.09471230108695515\n",
      "train loss:0.06993645977801424\n",
      "train loss:0.05786951958059141\n",
      "train loss:0.08607823758481761\n",
      "train loss:0.058921295197576405\n",
      "train loss:0.08219162111361396\n",
      "train loss:0.06492153552243456\n",
      "train loss:0.08685059751136104\n",
      "train loss:0.11068268980990757\n",
      "train loss:0.07914241716459924\n",
      "train loss:0.051198308896640884\n",
      "train loss:0.10022616374385673\n",
      "train loss:0.04686849587649588\n",
      "train loss:0.08861466947474199\n",
      "train loss:0.06457186454513647\n",
      "train loss:0.09267523088373787\n",
      "train loss:0.06505951704951465\n",
      "train loss:0.10091770142829956\n",
      "train loss:0.02512642342901734\n",
      "train loss:0.07047708232788652\n",
      "train loss:0.04248967458032258\n",
      "train loss:0.07663215295921857\n",
      "train loss:0.09722554657947245\n",
      "train loss:0.07244836889775504\n",
      "train loss:0.06070839026220343\n",
      "train loss:0.07854629970071515\n",
      "train loss:0.05029515163848051\n",
      "train loss:0.10530922268174311\n",
      "train loss:0.04396069341306874\n",
      "train loss:0.0424417104100316\n",
      "train loss:0.11107964738413352\n",
      "train loss:0.04729022384527576\n",
      "train loss:0.18570825555383108\n",
      "train loss:0.1176196000051339\n",
      "train loss:0.12113005559021364\n",
      "train loss:0.05163184744128316\n",
      "train loss:0.05257769238665919\n",
      "train loss:0.07482815695772521\n",
      "train loss:0.12440195026984738\n",
      "train loss:0.04502136210008983\n",
      "train loss:0.12771449125737902\n",
      "train loss:0.03754912194489942\n",
      "train loss:0.1624074632007311\n",
      "train loss:0.09644027642683159\n",
      "train loss:0.17797032788578934\n",
      "train loss:0.07749694788589973\n",
      "train loss:0.02885301871368395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11607374644103126\n",
      "train loss:0.07636660053951945\n",
      "train loss:0.0391583450937546\n",
      "train loss:0.08491990950273441\n",
      "train loss:0.12189770225193439\n",
      "train loss:0.06259182417947398\n",
      "train loss:0.03296331112000342\n",
      "train loss:0.08193114044206426\n",
      "train loss:0.07740461122635364\n",
      "train loss:0.10983368612106854\n",
      "train loss:0.06128326914508518\n",
      "train loss:0.08009758578060491\n",
      "train loss:0.04170481834918307\n",
      "train loss:0.07850254324528516\n",
      "train loss:0.08608581415155016\n",
      "train loss:0.19335613893547152\n",
      "train loss:0.1504768583333803\n",
      "train loss:0.08243621625096853\n",
      "train loss:0.059115289527325116\n",
      "train loss:0.1315130635752136\n",
      "train loss:0.12298229099284848\n",
      "train loss:0.06764389928646299\n",
      "train loss:0.07340860496915286\n",
      "train loss:0.11131229263327118\n",
      "train loss:0.09369262018856224\n",
      "train loss:0.07892217237957137\n",
      "train loss:0.10819993506715932\n",
      "train loss:0.0952169377088051\n",
      "train loss:0.11193484943764133\n",
      "train loss:0.10787614920611331\n",
      "train loss:0.0602376745801615\n",
      "train loss:0.09789957721824263\n",
      "train loss:0.07543216897393953\n",
      "train loss:0.026605599753271737\n",
      "train loss:0.05318082532958795\n",
      "train loss:0.07578523326162453\n",
      "train loss:0.08253729008922366\n",
      "train loss:0.0903459055361109\n",
      "train loss:0.09328372318364397\n",
      "train loss:0.1242239950150924\n",
      "train loss:0.07422457848575247\n",
      "train loss:0.11938866586255259\n",
      "train loss:0.10645808076864804\n",
      "train loss:0.033311689886596864\n",
      "train loss:0.09989953551590938\n",
      "train loss:0.051401098760924\n",
      "train loss:0.07659532368829118\n",
      "train loss:0.10631045374031461\n",
      "train loss:0.11316717745795507\n",
      "train loss:0.04902682358809358\n",
      "train loss:0.06973337054219772\n",
      "train loss:0.06457825766090548\n",
      "train loss:0.04051821402739968\n",
      "train loss:0.052970202602920874\n",
      "train loss:0.10004550472774604\n",
      "train loss:0.11672120961585872\n",
      "train loss:0.1808581870070424\n",
      "train loss:0.03929993494524579\n",
      "train loss:0.07072748059940324\n",
      "train loss:0.07514242213909406\n",
      "train loss:0.1473655711074892\n",
      "train loss:0.0727168137460934\n",
      "train loss:0.10450353323959032\n",
      "train loss:0.05928016958672238\n",
      "train loss:0.09295755902134195\n",
      "train loss:0.04585585270813887\n",
      "train loss:0.12407124048364042\n",
      "train loss:0.043043092169034604\n",
      "train loss:0.07015724821654562\n",
      "train loss:0.08245140234219708\n",
      "train loss:0.11696951531242998\n",
      "train loss:0.040500539785304206\n",
      "train loss:0.16948741387519667\n",
      "train loss:0.08917394213213735\n",
      "train loss:0.06450376895345174\n",
      "train loss:0.04900916035690701\n",
      "train loss:0.056762703664232035\n",
      "train loss:0.07946085054611783\n",
      "train loss:0.02143044203592863\n",
      "train loss:0.041032648177198865\n",
      "train loss:0.06529856810626422\n",
      "train loss:0.03783103172034323\n",
      "train loss:0.12274426892956644\n",
      "train loss:0.07427389374180288\n",
      "train loss:0.05876950646183264\n",
      "train loss:0.09058442993341614\n",
      "train loss:0.11179172671627975\n",
      "train loss:0.06512014022855958\n",
      "train loss:0.0872549708613372\n",
      "train loss:0.18440216415252927\n",
      "train loss:0.11918964671141798\n",
      "train loss:0.04370958229110202\n",
      "train loss:0.07076889118432157\n",
      "train loss:0.06688814732453036\n",
      "train loss:0.08036959982986526\n",
      "train loss:0.023087493152514443\n",
      "train loss:0.06811752183173296\n",
      "train loss:0.03249787796443419\n",
      "train loss:0.1921395694002329\n",
      "train loss:0.04609300086728275\n",
      "train loss:0.0582469131715376\n",
      "train loss:0.10234251051658762\n",
      "train loss:0.11070339065200932\n",
      "train loss:0.06056747877143095\n",
      "train loss:0.05116296982721705\n",
      "train loss:0.17844101443302537\n",
      "train loss:0.09083119086251588\n",
      "train loss:0.07592820049680489\n",
      "train loss:0.0772967510486886\n",
      "train loss:0.04381270788741982\n",
      "train loss:0.07231275876773785\n",
      "train loss:0.1004308462661194\n",
      "train loss:0.028988104511389886\n",
      "train loss:0.09016193374127225\n",
      "train loss:0.07480991148477742\n",
      "train loss:0.1159946574253639\n",
      "train loss:0.105893171276763\n",
      "train loss:0.03777120337578448\n",
      "train loss:0.060427247997206356\n",
      "train loss:0.07687447086885345\n",
      "train loss:0.031123081953005564\n",
      "train loss:0.09380003611487457\n",
      "train loss:0.15563980451001044\n",
      "train loss:0.0286299358317785\n",
      "train loss:0.015019900350034974\n",
      "train loss:0.016857019022843037\n",
      "train loss:0.04363690612088665\n",
      "train loss:0.03335698814528539\n",
      "train loss:0.05206265409546035\n",
      "train loss:0.09266743557596756\n",
      "train loss:0.034475967781667796\n",
      "train loss:0.0888235434077163\n",
      "train loss:0.03645056874537644\n",
      "train loss:0.19631796656151504\n",
      "train loss:0.06515611546297785\n",
      "train loss:0.05029409223181516\n",
      "train loss:0.06912425780058028\n",
      "train loss:0.042048680907378094\n",
      "train loss:0.09898384570110887\n",
      "train loss:0.05919413525196638\n",
      "train loss:0.045418876914586334\n",
      "train loss:0.08429474195733083\n",
      "train loss:0.09565157546458523\n",
      "train loss:0.08435800414469397\n",
      "train loss:0.07485528434662536\n",
      "train loss:0.03787258535980367\n",
      "train loss:0.03671285782536101\n",
      "train loss:0.11658986666131842\n",
      "train loss:0.09294660646793586\n",
      "train loss:0.06468306426201328\n",
      "train loss:0.12422069109996295\n",
      "train loss:0.0677483574929274\n",
      "train loss:0.09288122512923862\n",
      "train loss:0.1266603260059151\n",
      "train loss:0.04442857159911848\n",
      "train loss:0.05469856135644251\n",
      "train loss:0.12309624559655678\n",
      "train loss:0.032720553100762245\n",
      "train loss:0.09583775878869293\n",
      "train loss:0.03181558362761757\n",
      "train loss:0.054276275374683325\n",
      "train loss:0.1150561296626158\n",
      "train loss:0.06877182002527323\n",
      "train loss:0.08207332490157064\n",
      "train loss:0.03772688618649434\n",
      "train loss:0.12335640104303895\n",
      "train loss:0.11853521507570605\n",
      "train loss:0.04685034168305521\n",
      "train loss:0.084060631391976\n",
      "train loss:0.1837809008336879\n",
      "train loss:0.08823374525862833\n",
      "train loss:0.06853713137482495\n",
      "train loss:0.1032184557528733\n",
      "train loss:0.07005642710098599\n",
      "train loss:0.07330777406483448\n",
      "train loss:0.04016298709089839\n",
      "train loss:0.10376811682942857\n",
      "train loss:0.07081183541768613\n",
      "train loss:0.14288319431395569\n",
      "train loss:0.10720622595557092\n",
      "train loss:0.08452229654418028\n",
      "train loss:0.08423617269497091\n",
      "train loss:0.17623180521148607\n",
      "train loss:0.06091963590271163\n",
      "train loss:0.0854861852903592\n",
      "train loss:0.11310393867563388\n",
      "train loss:0.027422807997002613\n",
      "train loss:0.03792312128818575\n",
      "train loss:0.02558796929716641\n",
      "train loss:0.05174600908857281\n",
      "train loss:0.035467851408223915\n",
      "train loss:0.0925262015892849\n",
      "train loss:0.06770105547975917\n",
      "train loss:0.04872711271415109\n",
      "train loss:0.10145064748882372\n",
      "train loss:0.06270825263175656\n",
      "train loss:0.09585444719947654\n",
      "train loss:0.04339624776927068\n",
      "train loss:0.10492400475933623\n",
      "train loss:0.05726630503433377\n",
      "train loss:0.04327425536301697\n",
      "train loss:0.05733301532315603\n",
      "train loss:0.13600443044931987\n",
      "train loss:0.025040890913303557\n",
      "train loss:0.04791663091581359\n",
      "train loss:0.08541658535518215\n",
      "train loss:0.04499274715059769\n",
      "train loss:0.09919450343354416\n",
      "train loss:0.06047223968195057\n",
      "train loss:0.08080989717961501\n",
      "train loss:0.02642621215469422\n",
      "train loss:0.08933395808925038\n",
      "train loss:0.07143711079021652\n",
      "train loss:0.0403627617371182\n",
      "train loss:0.061786088227375593\n",
      "train loss:0.09317630870140395\n",
      "train loss:0.06742855104367357\n",
      "train loss:0.042902144338075175\n",
      "train loss:0.042418994588479614\n",
      "train loss:0.08700030296861545\n",
      "train loss:0.24175360771586923\n",
      "train loss:0.06827590123326144\n",
      "train loss:0.06378766420188332\n",
      "train loss:0.09603221121892078\n",
      "train loss:0.052622329241070215\n",
      "train loss:0.032217484627597416\n",
      "train loss:0.055970582835266916\n",
      "train loss:0.1314790334000165\n",
      "train loss:0.05239517777247913\n",
      "train loss:0.08120049487401887\n",
      "train loss:0.09580743829442567\n",
      "train loss:0.06479846432089593\n",
      "train loss:0.11102249149043471\n",
      "train loss:0.05212975245889656\n",
      "train loss:0.05084981726075933\n",
      "train loss:0.13835752242495242\n",
      "train loss:0.05177352404528482\n",
      "train loss:0.20174055721158615\n",
      "train loss:0.05340583498153822\n",
      "train loss:0.08131298302104739\n",
      "train loss:0.11074996478438791\n",
      "train loss:0.10257289231480142\n",
      "train loss:0.049356068010775134\n",
      "train loss:0.06747044031392609\n",
      "train loss:0.06088027665688862\n",
      "train loss:0.1711037862049204\n",
      "train loss:0.1833547078424113\n",
      "train loss:0.13355231056320524\n",
      "train loss:0.10580545253940862\n",
      "train loss:0.1034075073328766\n",
      "train loss:0.07008739210441348\n",
      "train loss:0.11195899965525963\n",
      "train loss:0.08824444605394882\n",
      "train loss:0.0802031827775387\n",
      "train loss:0.09018682220894292\n",
      "train loss:0.031302598479818554\n",
      "train loss:0.08980150381900504\n",
      "train loss:0.08056510023791404\n",
      "train loss:0.07611139513752056\n",
      "train loss:0.15092234365079008\n",
      "train loss:0.03255725654701517\n",
      "train loss:0.02028959102671053\n",
      "train loss:0.12184772251928688\n",
      "train loss:0.08436871686389599\n",
      "train loss:0.08167853137487818\n",
      "train loss:0.10805081497962338\n",
      "train loss:0.12130058507143007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08981010904551459\n",
      "train loss:0.06298116390342944\n",
      "train loss:0.04558810938386416\n",
      "train loss:0.1251714871561021\n",
      "train loss:0.05566186715186983\n",
      "train loss:0.07382593336015053\n",
      "train loss:0.06196529905097817\n",
      "train loss:0.17996698708620784\n",
      "train loss:0.1079727580027874\n",
      "train loss:0.07647513593925137\n",
      "train loss:0.16341619246275096\n",
      "train loss:0.08405484480402782\n",
      "train loss:0.07599646747388598\n",
      "train loss:0.035740524418641215\n",
      "train loss:0.1745936926662585\n",
      "train loss:0.052963295992065236\n",
      "train loss:0.0502404153322712\n",
      "train loss:0.056419091894634205\n",
      "train loss:0.0821477689355849\n",
      "train loss:0.1542008967592246\n",
      "train loss:0.04270209213474882\n",
      "train loss:0.07495569335137037\n",
      "train loss:0.0872186435771255\n",
      "train loss:0.042207608757192115\n",
      "train loss:0.06789606668146081\n",
      "train loss:0.050946544793669446\n",
      "train loss:0.037466237565991156\n",
      "train loss:0.04968371034971285\n",
      "train loss:0.0753170315637338\n",
      "train loss:0.05066344182438595\n",
      "train loss:0.04762880403673287\n",
      "train loss:0.10574633352588768\n",
      "train loss:0.14645712960813972\n",
      "train loss:0.05608632903534829\n",
      "train loss:0.06853520246466491\n",
      "train loss:0.10067267071039651\n",
      "train loss:0.025242658585292465\n",
      "train loss:0.06844204975324841\n",
      "train loss:0.1545784040349209\n",
      "train loss:0.11531070122477033\n",
      "train loss:0.05523322312611891\n",
      "train loss:0.0861297647790423\n",
      "train loss:0.06900599221449429\n",
      "train loss:0.0864527626681747\n",
      "train loss:0.09765179044022224\n",
      "train loss:0.06903226459662078\n",
      "train loss:0.07722349805861589\n",
      "train loss:0.15562643477295027\n",
      "train loss:0.09348177716206515\n",
      "train loss:0.08078289025355763\n",
      "train loss:0.08891215597065667\n",
      "train loss:0.053235962262079994\n",
      "train loss:0.04834316972266719\n",
      "train loss:0.07109258877391669\n",
      "train loss:0.04476992883075777\n",
      "train loss:0.05522467951318035\n",
      "train loss:0.09259777501175455\n",
      "train loss:0.13356036927869525\n",
      "train loss:0.051584218348557184\n",
      "train loss:0.12470708338054193\n",
      "train loss:0.13728994652231574\n",
      "train loss:0.029896150215454755\n",
      "train loss:0.13349699505539522\n",
      "train loss:0.07948556379965056\n",
      "train loss:0.11963796375302069\n",
      "train loss:0.08297978464761611\n",
      "train loss:0.12973079655680528\n",
      "train loss:0.05311958549303569\n",
      "train loss:0.10513778873217813\n",
      "train loss:0.10928427009103689\n",
      "train loss:0.1459050857549481\n",
      "train loss:0.29820198985971164\n",
      "train loss:0.1453184976973089\n",
      "train loss:0.10830085177182468\n",
      "train loss:0.042508139119115364\n",
      "train loss:0.08385934783611024\n",
      "train loss:0.11939204720989177\n",
      "train loss:0.0859435378111238\n",
      "train loss:0.03191125182436938\n",
      "train loss:0.08143832037116522\n",
      "train loss:0.09972533184626867\n",
      "train loss:0.09026943524177193\n",
      "train loss:0.14652482649572415\n",
      "train loss:0.07120906365029044\n",
      "train loss:0.10716929115006937\n",
      "train loss:0.09669429407555097\n",
      "train loss:0.12930060534735724\n",
      "train loss:0.11234976342773187\n",
      "train loss:0.1738663080951399\n",
      "train loss:0.20657540877371905\n",
      "train loss:0.10729946569220482\n",
      "train loss:0.07658177691458398\n",
      "train loss:0.11111842760953344\n",
      "train loss:0.12100418587578637\n",
      "train loss:0.03718512890054158\n",
      "train loss:0.0848714755467011\n",
      "train loss:0.06068524927608206\n",
      "train loss:0.048662717351941255\n",
      "train loss:0.02228924169315115\n",
      "train loss:0.11800344378375101\n",
      "train loss:0.07713762347270256\n",
      "train loss:0.06717061759492463\n",
      "train loss:0.07085472984671992\n",
      "train loss:0.05194291708296026\n",
      "train loss:0.2026566842663856\n",
      "train loss:0.12179349407495149\n",
      "train loss:0.08835470049845705\n",
      "train loss:0.04980217576632477\n",
      "train loss:0.22030457369095263\n",
      "train loss:0.12823133140134282\n",
      "train loss:0.038846700264718086\n",
      "train loss:0.04497462845147706\n",
      "train loss:0.039038727578138754\n",
      "train loss:0.18840903450557042\n",
      "train loss:0.0397310629737194\n",
      "train loss:0.05438931257562646\n",
      "train loss:0.02841413526773268\n",
      "train loss:0.05880446393114616\n",
      "train loss:0.023242919678733057\n",
      "train loss:0.06855195388389368\n",
      "train loss:0.03861711099714878\n",
      "train loss:0.2262860666581231\n",
      "train loss:0.10886294350979109\n",
      "train loss:0.07719535188304755\n",
      "train loss:0.046123714805354134\n",
      "train loss:0.0681205579548909\n",
      "train loss:0.09179695629092618\n",
      "train loss:0.06582082699270687\n",
      "train loss:0.0303038650100339\n",
      "train loss:0.08226215429151135\n",
      "train loss:0.1723170151007132\n",
      "train loss:0.03127311157851054\n",
      "train loss:0.07404092476625483\n",
      "train loss:0.0826775310037247\n",
      "train loss:0.10275187929729246\n",
      "train loss:0.12086050165950107\n",
      "train loss:0.06494208628395431\n",
      "train loss:0.08617905893948002\n",
      "train loss:0.05910384373064103\n",
      "train loss:0.02984520479894758\n",
      "train loss:0.04949513928675366\n",
      "train loss:0.12231684436290599\n",
      "train loss:0.04629708553249121\n",
      "train loss:0.14693978364035973\n",
      "train loss:0.09406926587343872\n",
      "train loss:0.07858926572643017\n",
      "train loss:0.10202684158930149\n",
      "train loss:0.057356442461814365\n",
      "train loss:0.0703010803172812\n",
      "train loss:0.09359607559016672\n",
      "train loss:0.01900763317066821\n",
      "train loss:0.06571771818000795\n",
      "train loss:0.07578099538624194\n",
      "train loss:0.06648525950412199\n",
      "train loss:0.05695803579240181\n",
      "train loss:0.08985388084738415\n",
      "train loss:0.056550707763901135\n",
      "train loss:0.08448427464887233\n",
      "train loss:0.02947204139651754\n",
      "train loss:0.07696747656304784\n",
      "train loss:0.04093884381611494\n",
      "train loss:0.03665677561322911\n",
      "train loss:0.06238035921456426\n",
      "train loss:0.0890597017519187\n",
      "train loss:0.09828883876988477\n",
      "train loss:0.03421702668110491\n",
      "train loss:0.2373693851594046\n",
      "train loss:0.08471794169911735\n",
      "train loss:0.059759263721888535\n",
      "train loss:0.06420257160262546\n",
      "train loss:0.04338024409880933\n",
      "train loss:0.16548599925827429\n",
      "train loss:0.16210112564103074\n",
      "train loss:0.03273069130521043\n",
      "train loss:0.0578456551116038\n",
      "train loss:0.05154093691507401\n",
      "train loss:0.06975783442952192\n",
      "train loss:0.09906409334580699\n",
      "train loss:0.08372542342656368\n",
      "train loss:0.07656249670246537\n",
      "train loss:0.056368275597371384\n",
      "train loss:0.05742618022459167\n",
      "train loss:0.06459383325987919\n",
      "=== epoch:12, train acc:0.973, test acc:0.96 ===, time:  211.59825801849365\n",
      "train loss:0.11354131670090417\n",
      "train loss:0.07556470047183456\n",
      "train loss:0.07462513496351014\n",
      "train loss:0.03913428369115317\n",
      "train loss:0.10526954168531111\n",
      "train loss:0.08119391605383791\n",
      "train loss:0.05829945425917318\n",
      "train loss:0.08351095986947199\n",
      "train loss:0.10496253213895822\n",
      "train loss:0.02827922777260201\n",
      "train loss:0.10140177643535582\n",
      "train loss:0.06473466210888247\n",
      "train loss:0.013293030670025748\n",
      "train loss:0.09102125150943823\n",
      "train loss:0.07344008545173222\n",
      "train loss:0.12437338817828379\n",
      "train loss:0.04220374104296403\n",
      "train loss:0.032591120252016326\n",
      "train loss:0.15645911558826425\n",
      "train loss:0.03387541699416877\n",
      "train loss:0.10694233811194492\n",
      "train loss:0.06626407302088021\n",
      "train loss:0.042174354827066794\n",
      "train loss:0.060365372394495624\n",
      "train loss:0.1105579354752047\n",
      "train loss:0.027690097598599944\n",
      "train loss:0.07976811788753604\n",
      "train loss:0.036288891241692406\n",
      "train loss:0.09387012340588072\n",
      "train loss:0.03814164820083888\n",
      "train loss:0.10245922069980738\n",
      "train loss:0.09456271334411202\n",
      "train loss:0.10516137701373589\n",
      "train loss:0.11714325118782985\n",
      "train loss:0.16518211705296953\n",
      "train loss:0.08837044685265352\n",
      "train loss:0.0525328198233092\n",
      "train loss:0.07782758522004295\n",
      "train loss:0.17848758912906576\n",
      "train loss:0.10715857219831128\n",
      "train loss:0.09687239969502795\n",
      "train loss:0.022269556278919574\n",
      "train loss:0.07290206367668248\n",
      "train loss:0.055781982209022724\n",
      "train loss:0.10491588324396568\n",
      "train loss:0.03806215333665051\n",
      "train loss:0.01459413901981108\n",
      "train loss:0.15448403988641626\n",
      "train loss:0.05171942660516545\n",
      "train loss:0.042985513164990864\n",
      "train loss:0.03805023217889348\n",
      "train loss:0.04699135988545101\n",
      "train loss:0.05224425498394379\n",
      "train loss:0.10524995225976656\n",
      "train loss:0.04882199548150754\n",
      "train loss:0.10908235897824067\n",
      "train loss:0.07369773777301623\n",
      "train loss:0.06941716309784683\n",
      "train loss:0.14998433206982217\n",
      "train loss:0.07827488768229976\n",
      "train loss:0.10816061391563794\n",
      "train loss:0.10386764337574629\n",
      "train loss:0.0760864661151092\n",
      "train loss:0.1560751422270018\n",
      "train loss:0.058265838428952714\n",
      "train loss:0.10931450013471272\n",
      "train loss:0.1268441366493229\n",
      "train loss:0.11552589519120135\n",
      "train loss:0.06802947605218228\n",
      "train loss:0.019935800855894477\n",
      "train loss:0.09170448508465961\n",
      "train loss:0.09874321598123469\n",
      "train loss:0.09273364982099026\n",
      "train loss:0.08316762840657557\n",
      "train loss:0.024290293347272448\n",
      "train loss:0.05537304738591498\n",
      "train loss:0.10849310795854844\n",
      "train loss:0.12732362159916877\n",
      "train loss:0.03213070564266331\n",
      "train loss:0.054494194128176444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.039875941369282984\n",
      "train loss:0.07203153894896065\n",
      "train loss:0.14233581871371476\n",
      "train loss:0.10976679238240437\n",
      "train loss:0.1304888233431999\n",
      "train loss:0.16163742130931552\n",
      "train loss:0.052585461302999334\n",
      "train loss:0.06279555891281767\n",
      "train loss:0.09169259862288628\n",
      "train loss:0.0772513750746869\n",
      "train loss:0.1140673203877801\n",
      "train loss:0.06743272409777373\n",
      "train loss:0.035529798290772074\n",
      "train loss:0.03186567412825818\n",
      "train loss:0.0563568772873495\n",
      "train loss:0.046099974084213485\n",
      "train loss:0.09565355685512573\n",
      "train loss:0.11880818540265797\n",
      "train loss:0.04609378924988782\n",
      "train loss:0.029728097900559677\n",
      "train loss:0.13940361910598026\n",
      "train loss:0.0314259753149883\n",
      "train loss:0.07101121616928589\n",
      "train loss:0.09031098157579559\n",
      "train loss:0.06004706964276029\n",
      "train loss:0.14564944765153245\n",
      "train loss:0.06690581339213816\n",
      "train loss:0.044694343296429906\n",
      "train loss:0.0709590973958838\n",
      "train loss:0.04098160856707746\n",
      "train loss:0.046678014916394645\n",
      "train loss:0.09561945206561949\n",
      "train loss:0.21865841583286827\n",
      "train loss:0.017431617055705242\n",
      "train loss:0.04439690830022938\n",
      "train loss:0.14493172834515972\n",
      "train loss:0.05087449584489654\n",
      "train loss:0.06580348093296177\n",
      "train loss:0.04575068472186337\n",
      "train loss:0.09259468516310579\n",
      "train loss:0.09524162636946423\n",
      "train loss:0.1506629748018923\n",
      "train loss:0.0729569534355066\n",
      "train loss:0.0742522139442611\n",
      "train loss:0.05723767038134479\n",
      "train loss:0.06580797808577064\n",
      "train loss:0.10323840849263824\n",
      "train loss:0.03804900301567253\n",
      "train loss:0.050067558491491665\n",
      "train loss:0.03170634630346127\n",
      "train loss:0.048030391771922955\n",
      "train loss:0.07604041748578996\n",
      "train loss:0.1607462335813988\n",
      "train loss:0.06407575035443626\n",
      "train loss:0.0621119063072181\n",
      "train loss:0.04347442183168153\n",
      "train loss:0.015543661946332636\n",
      "train loss:0.14282675478261986\n",
      "train loss:0.032205071878390334\n",
      "train loss:0.10732936004065798\n",
      "train loss:0.04995686967945595\n",
      "train loss:0.09844975423328936\n",
      "train loss:0.09629239332565309\n",
      "train loss:0.0744461745190158\n",
      "train loss:0.050626096898826314\n",
      "train loss:0.09844105907226351\n",
      "train loss:0.0749785951729287\n",
      "train loss:0.06062020182409323\n",
      "train loss:0.09156554545757781\n",
      "train loss:0.055041454729436314\n",
      "train loss:0.18618629694884134\n",
      "train loss:0.16125827871913856\n",
      "train loss:0.03725494008488216\n",
      "train loss:0.03163038752352919\n",
      "train loss:0.07111447497783746\n",
      "train loss:0.04646498819837461\n",
      "train loss:0.06796355244026327\n",
      "train loss:0.04206520150698074\n",
      "train loss:0.1289491622305541\n",
      "train loss:0.062349015164537794\n",
      "train loss:0.05352269145283321\n",
      "train loss:0.13597006791671315\n",
      "train loss:0.07104744552443093\n",
      "train loss:0.07320827501169411\n",
      "train loss:0.12049763299108474\n",
      "train loss:0.13556700668164529\n",
      "train loss:0.049083872660744404\n",
      "train loss:0.061438460850411436\n",
      "train loss:0.052685268113384386\n",
      "train loss:0.08211637338199203\n",
      "train loss:0.06602261889707178\n",
      "train loss:0.05496862732711856\n",
      "train loss:0.02490516298681698\n",
      "train loss:0.2008557541283439\n",
      "train loss:0.03356401670797445\n",
      "train loss:0.0460787632075429\n",
      "train loss:0.030439863399226125\n",
      "train loss:0.25169686840157596\n",
      "train loss:0.18017608595628118\n",
      "train loss:0.13791180317111615\n",
      "train loss:0.0834641233444205\n",
      "train loss:0.13232865049601636\n",
      "train loss:0.07884755539946459\n",
      "train loss:0.04377262733767005\n",
      "train loss:0.16495811400127483\n",
      "train loss:0.0739340836957925\n",
      "train loss:0.07829975887984564\n",
      "train loss:0.06349437767445522\n",
      "train loss:0.17845311232658673\n",
      "train loss:0.048437524243426774\n",
      "train loss:0.05014965239152252\n",
      "train loss:0.06146160816678349\n",
      "train loss:0.08870276438376669\n",
      "train loss:0.05660246859489156\n",
      "train loss:0.05931675760960957\n",
      "train loss:0.053827993687802424\n",
      "train loss:0.02839215566493812\n",
      "train loss:0.07596788037714233\n",
      "train loss:0.031084009407618605\n",
      "train loss:0.0832623174509053\n",
      "train loss:0.15260424691596236\n",
      "train loss:0.05720861752534352\n",
      "train loss:0.10085730952114062\n",
      "train loss:0.06465344317922536\n",
      "train loss:0.09210397284170156\n",
      "train loss:0.0731679614365061\n",
      "train loss:0.10378619470635644\n",
      "train loss:0.058375860262983\n",
      "train loss:0.1146138656385076\n",
      "train loss:0.017596549932407703\n",
      "train loss:0.05467236749851303\n",
      "train loss:0.038695383804247155\n",
      "train loss:0.25509250251769905\n",
      "train loss:0.16162888235831155\n",
      "train loss:0.0903642539436145\n",
      "train loss:0.05463142716659842\n",
      "train loss:0.039509237535598374\n",
      "train loss:0.037946529685593706\n",
      "train loss:0.10612157949343672\n",
      "train loss:0.028520593016140114\n",
      "train loss:0.09097135019971708\n",
      "train loss:0.04552104378270868\n",
      "train loss:0.0411807399583964\n",
      "train loss:0.0904121003092421\n",
      "train loss:0.07249564663682045\n",
      "train loss:0.114372584158326\n",
      "train loss:0.05524446925615481\n",
      "train loss:0.0892391524550737\n",
      "train loss:0.08546453782926443\n",
      "train loss:0.05276612811808529\n",
      "train loss:0.034513193989309895\n",
      "train loss:0.02873572359659693\n",
      "train loss:0.09735902352073854\n",
      "train loss:0.029087893861682198\n",
      "train loss:0.03778676541275833\n",
      "train loss:0.12520126831644166\n",
      "train loss:0.04914653275867871\n",
      "train loss:0.08450735535969586\n",
      "train loss:0.055310954764613944\n",
      "train loss:0.11439623955702892\n",
      "train loss:0.036894972335485166\n",
      "train loss:0.06470549066155541\n",
      "train loss:0.03700327183480492\n",
      "train loss:0.09580908438949834\n",
      "train loss:0.0882050741772336\n",
      "train loss:0.0720432150285682\n",
      "train loss:0.07660118466017825\n",
      "train loss:0.061157377462213794\n",
      "train loss:0.0593559395809696\n",
      "train loss:0.07793591415378379\n",
      "train loss:0.08775522568618299\n",
      "train loss:0.02923544602626103\n",
      "train loss:0.18661760804905866\n",
      "train loss:0.027594799785360356\n",
      "train loss:0.04874908080845625\n",
      "train loss:0.06500657324685782\n",
      "train loss:0.06272522684594403\n",
      "train loss:0.048721541607410164\n",
      "train loss:0.11325110740003978\n",
      "train loss:0.09696876005459404\n",
      "train loss:0.08585771304214504\n",
      "train loss:0.054982121479641995\n",
      "train loss:0.021237279998602022\n",
      "train loss:0.07324849204075476\n",
      "train loss:0.032566361559911466\n",
      "train loss:0.02471371821262676\n",
      "train loss:0.057362496654474036\n",
      "train loss:0.06450205821789674\n",
      "train loss:0.08153559190417578\n",
      "train loss:0.06976459403281725\n",
      "train loss:0.08633713984770129\n",
      "train loss:0.15026056827509138\n",
      "train loss:0.08592542090028128\n",
      "train loss:0.1577460158120212\n",
      "train loss:0.05291435776750642\n",
      "train loss:0.1121621254422964\n",
      "train loss:0.03529361321769192\n",
      "train loss:0.07167209340137755\n",
      "train loss:0.07981054240132937\n",
      "train loss:0.080316860466249\n",
      "train loss:0.11620902862583572\n",
      "train loss:0.08447551637344063\n",
      "train loss:0.0253638721485046\n",
      "train loss:0.08392310307440808\n",
      "train loss:0.052775632951617496\n",
      "train loss:0.06273337153895354\n",
      "train loss:0.03471315420031434\n",
      "train loss:0.047106196998756004\n",
      "train loss:0.11088678357080237\n",
      "train loss:0.054129498165165116\n",
      "train loss:0.06374910303229935\n",
      "train loss:0.033565320740127746\n",
      "train loss:0.09010326083878771\n",
      "train loss:0.04446678719676555\n",
      "train loss:0.09263035362235979\n",
      "train loss:0.09721168731362781\n",
      "train loss:0.05181374917577295\n",
      "train loss:0.026872007259680156\n",
      "train loss:0.03738511399486952\n",
      "train loss:0.03794412928611953\n",
      "train loss:0.07400317097355964\n",
      "train loss:0.05221119309656502\n",
      "train loss:0.09540497969201527\n",
      "train loss:0.04432972459159221\n",
      "train loss:0.03525646209267158\n",
      "train loss:0.0809482986352231\n",
      "train loss:0.06562803733743294\n",
      "train loss:0.11915180990119227\n",
      "train loss:0.09663377982578662\n",
      "train loss:0.07508570106061803\n",
      "train loss:0.0857080990582063\n",
      "train loss:0.05553955008193103\n",
      "train loss:0.06422496092658665\n",
      "train loss:0.10557622893933823\n",
      "train loss:0.10182236740583232\n",
      "train loss:0.05571233526347383\n",
      "train loss:0.09864032582331514\n",
      "train loss:0.06671173603072245\n",
      "train loss:0.0603010699583994\n",
      "train loss:0.02428652025470876\n",
      "train loss:0.05426973100142199\n",
      "train loss:0.13159693551580776\n",
      "train loss:0.16447572120809922\n",
      "train loss:0.042540363118713696\n",
      "train loss:0.02667036563514315\n",
      "train loss:0.11989067654278152\n",
      "train loss:0.0521430440817312\n",
      "train loss:0.04640506759313631\n",
      "train loss:0.09917449775515365\n",
      "train loss:0.04394538014986254\n",
      "train loss:0.06270733930492431\n",
      "train loss:0.03367457957617595\n",
      "train loss:0.1220110852261072\n",
      "train loss:0.06779327150279249\n",
      "train loss:0.08319281846728833\n",
      "train loss:0.1555333026144886\n",
      "train loss:0.040359006128087904\n",
      "train loss:0.031901521189451394\n",
      "train loss:0.030787337279893544\n",
      "train loss:0.029773143353074648\n",
      "train loss:0.08418983906698133\n",
      "train loss:0.15947318177439962\n",
      "train loss:0.07841281916934341\n",
      "train loss:0.030203724610548717\n",
      "train loss:0.054935604470342805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.15937271285291207\n",
      "train loss:0.06230767361640528\n",
      "train loss:0.21084970408519205\n",
      "train loss:0.032964302498370054\n",
      "train loss:0.01626547035299649\n",
      "train loss:0.04882820030255366\n",
      "train loss:0.061586300104291114\n",
      "train loss:0.06714432950348734\n",
      "train loss:0.04975795686538533\n",
      "train loss:0.05382103804624472\n",
      "train loss:0.02192952994730647\n",
      "train loss:0.11598963326955927\n",
      "train loss:0.08218317239413254\n",
      "train loss:0.02787696820900422\n",
      "train loss:0.032783936792971174\n",
      "train loss:0.11197653038425248\n",
      "train loss:0.1034267755675971\n",
      "train loss:0.09623152453106072\n",
      "train loss:0.1924058973885732\n",
      "train loss:0.01371311993069644\n",
      "train loss:0.07957444801040721\n",
      "train loss:0.07845093405048426\n",
      "train loss:0.04683006362794848\n",
      "train loss:0.07583798885580005\n",
      "train loss:0.11837528357668096\n",
      "train loss:0.1504546403493063\n",
      "train loss:0.031360735013588784\n",
      "train loss:0.0568064835087953\n",
      "train loss:0.04165360316018742\n",
      "train loss:0.0439928366493627\n",
      "train loss:0.10590883193408886\n",
      "train loss:0.06706235773440816\n",
      "train loss:0.09522495911138051\n",
      "train loss:0.06395183986715433\n",
      "train loss:0.0895419699282964\n",
      "train loss:0.0454846233626193\n",
      "train loss:0.13453352625939094\n",
      "train loss:0.08609701033659693\n",
      "train loss:0.09202530496704307\n",
      "train loss:0.07659999787704837\n",
      "train loss:0.0824157917020394\n",
      "train loss:0.060621897733239505\n",
      "train loss:0.11298969625299227\n",
      "train loss:0.07917503966271389\n",
      "train loss:0.0856400986361755\n",
      "train loss:0.05583799863570427\n",
      "train loss:0.11381551285131117\n",
      "train loss:0.0772660364142958\n",
      "train loss:0.10918382777983723\n",
      "train loss:0.10633773025212352\n",
      "train loss:0.031147137259901373\n",
      "train loss:0.04541034668458175\n",
      "train loss:0.13102527582972817\n",
      "train loss:0.04647106536421615\n",
      "train loss:0.046321083861478256\n",
      "train loss:0.04606698718308998\n",
      "train loss:0.025434266117161014\n",
      "train loss:0.087075235995209\n",
      "train loss:0.0841356603161127\n",
      "train loss:0.06637839439605525\n",
      "train loss:0.04408816634511051\n",
      "train loss:0.04342166992456093\n",
      "train loss:0.08278202663639252\n",
      "train loss:0.07112052861363184\n",
      "train loss:0.03954467752640262\n",
      "train loss:0.07302630338422772\n",
      "train loss:0.05966229969327147\n",
      "train loss:0.11304163018038015\n",
      "train loss:0.07009083332550498\n",
      "train loss:0.06341122121108361\n",
      "train loss:0.11275512723440205\n",
      "train loss:0.051740246286463364\n",
      "train loss:0.03667958694703249\n",
      "train loss:0.1430704320720068\n",
      "train loss:0.0336259392924848\n",
      "train loss:0.0215421007849398\n",
      "train loss:0.07381056400684369\n",
      "train loss:0.026094665552390945\n",
      "train loss:0.07952583359994649\n",
      "train loss:0.10127151098113173\n",
      "train loss:0.10628515141081765\n",
      "train loss:0.0928463036300041\n",
      "train loss:0.054569612504588305\n",
      "train loss:0.08408105325446132\n",
      "train loss:0.029581475266468274\n",
      "train loss:0.09417142031962561\n",
      "train loss:0.053240193559332315\n",
      "train loss:0.12589481548677142\n",
      "train loss:0.1587732989198214\n",
      "train loss:0.04640384467117996\n",
      "train loss:0.049177525547740075\n",
      "train loss:0.04806940640207963\n",
      "train loss:0.11601431199352717\n",
      "train loss:0.1017972526661679\n",
      "train loss:0.05367186587552376\n",
      "train loss:0.03673887272471085\n",
      "train loss:0.03565953512751633\n",
      "train loss:0.09884854933917014\n",
      "train loss:0.03245680969754818\n",
      "train loss:0.050110864454043495\n",
      "train loss:0.05434977270548837\n",
      "train loss:0.018905808359700908\n",
      "train loss:0.03497179501365884\n",
      "train loss:0.16319373904142673\n",
      "train loss:0.0519554660840794\n",
      "train loss:0.09882345035021406\n",
      "train loss:0.061775872029745625\n",
      "train loss:0.055196664044416595\n",
      "train loss:0.05750425766740437\n",
      "train loss:0.08970178914588185\n",
      "train loss:0.06908953460528129\n",
      "train loss:0.09930105210441274\n",
      "train loss:0.14769795183717807\n",
      "train loss:0.08728223709282638\n",
      "train loss:0.06420085447830429\n",
      "train loss:0.06085358199719163\n",
      "train loss:0.02721443804381413\n",
      "train loss:0.052457446146094926\n",
      "train loss:0.19024577584746175\n",
      "train loss:0.16579924039945343\n",
      "train loss:0.14241385223826644\n",
      "train loss:0.03193942829744244\n",
      "train loss:0.030186988452575534\n",
      "train loss:0.07850510831348428\n",
      "train loss:0.08422331025706299\n",
      "train loss:0.05906908995223886\n",
      "train loss:0.0515208730149108\n",
      "train loss:0.08752480155805711\n",
      "train loss:0.07059943692626827\n",
      "train loss:0.08177421029246981\n",
      "train loss:0.08662496882486742\n",
      "train loss:0.05795122254463156\n",
      "train loss:0.028289320919096434\n",
      "train loss:0.061952840971852094\n",
      "train loss:0.0867508857327167\n",
      "train loss:0.030529996103630327\n",
      "train loss:0.09242395437998438\n",
      "train loss:0.1008502397534946\n",
      "train loss:0.023365140071040593\n",
      "train loss:0.02990050053206899\n",
      "train loss:0.06508082036952727\n",
      "train loss:0.046613245460023475\n",
      "train loss:0.04960006339017612\n",
      "train loss:0.05041900310903616\n",
      "train loss:0.0423779866764405\n",
      "train loss:0.049744699512267586\n",
      "train loss:0.04785769427372781\n",
      "train loss:0.07488419793785386\n",
      "train loss:0.030917656640224125\n",
      "train loss:0.03370929538840667\n",
      "train loss:0.057617944387074856\n",
      "train loss:0.06972937148581916\n",
      "train loss:0.04680745883329611\n",
      "train loss:0.04603854586691617\n",
      "train loss:0.10035729939878235\n",
      "train loss:0.1085979791989413\n",
      "train loss:0.040929884579749595\n",
      "train loss:0.0732020058305913\n",
      "train loss:0.17494192142764564\n",
      "train loss:0.06440688551434257\n",
      "train loss:0.05255375159015565\n",
      "train loss:0.14453957719001495\n",
      "train loss:0.06564841491705287\n",
      "train loss:0.044559252221932966\n",
      "train loss:0.041036939322335056\n",
      "train loss:0.04134628458827806\n",
      "train loss:0.08823435867420658\n",
      "train loss:0.05100637580742122\n",
      "train loss:0.049347553607081006\n",
      "train loss:0.10823018750981622\n",
      "train loss:0.05685203375277955\n",
      "train loss:0.05840941502085399\n",
      "train loss:0.07498163050751752\n",
      "train loss:0.025026192834580324\n",
      "train loss:0.017252705126318126\n",
      "train loss:0.05269187703717132\n",
      "train loss:0.025024943618453387\n",
      "train loss:0.03199467950681527\n",
      "train loss:0.14556714655747036\n",
      "train loss:0.16471210575925313\n",
      "train loss:0.04397441094129935\n",
      "train loss:0.048187624231741985\n",
      "train loss:0.030836511801455687\n",
      "train loss:0.08640476466804445\n",
      "train loss:0.08592712351242232\n",
      "train loss:0.09105160994370837\n",
      "train loss:0.04633066444072112\n",
      "train loss:0.030170444473327365\n",
      "train loss:0.06551260162227092\n",
      "train loss:0.02715478745556161\n",
      "train loss:0.03660086859486173\n",
      "train loss:0.0507664905313794\n",
      "train loss:0.09646494222013732\n",
      "train loss:0.03294645559250958\n",
      "train loss:0.07451595800871737\n",
      "train loss:0.0388735234197482\n",
      "train loss:0.08022784643863103\n",
      "train loss:0.07974409042087084\n",
      "train loss:0.12416963054638976\n",
      "train loss:0.1020015538347686\n",
      "train loss:0.029914466235051198\n",
      "train loss:0.09851952345572845\n",
      "train loss:0.10933092719607362\n",
      "train loss:0.058179844624248085\n",
      "train loss:0.0859469414555693\n",
      "train loss:0.0775209412441461\n",
      "train loss:0.08710694814730532\n",
      "train loss:0.07628321520490014\n",
      "train loss:0.06912592405443037\n",
      "train loss:0.032199573460459714\n",
      "train loss:0.02136118923644318\n",
      "train loss:0.09103340951023207\n",
      "train loss:0.02671485658032957\n",
      "train loss:0.06720474880003763\n",
      "train loss:0.038243653797069316\n",
      "train loss:0.12453330542607853\n",
      "train loss:0.03697295269342451\n",
      "train loss:0.1395055341853965\n",
      "train loss:0.027548682255716127\n",
      "train loss:0.12566863315113472\n",
      "train loss:0.06245009295661623\n",
      "train loss:0.054141621297391265\n",
      "train loss:0.051986853887722353\n",
      "train loss:0.031699447900918616\n",
      "train loss:0.04315715285634877\n",
      "train loss:0.10137814235810003\n",
      "train loss:0.05674869537032648\n",
      "train loss:0.022329631144764682\n",
      "train loss:0.025915252907421565\n",
      "train loss:0.06960098100926662\n",
      "train loss:0.04948324930170365\n",
      "train loss:0.061622805128408634\n",
      "train loss:0.05756688761574802\n",
      "train loss:0.041188019120190954\n",
      "train loss:0.05050402180189652\n",
      "train loss:0.1574830039915166\n",
      "train loss:0.0763056856771853\n",
      "train loss:0.08838628834982046\n",
      "train loss:0.12100725149504063\n",
      "train loss:0.06477435375543725\n",
      "train loss:0.10463422926341158\n",
      "train loss:0.0982006026467859\n",
      "train loss:0.038845979369854004\n",
      "train loss:0.1599899156638393\n",
      "train loss:0.09743259945111662\n",
      "train loss:0.06998526494236482\n",
      "train loss:0.18449231263053914\n",
      "train loss:0.08223029128524807\n",
      "train loss:0.0771468276033747\n",
      "train loss:0.14166476062067168\n",
      "train loss:0.04721334489321753\n",
      "train loss:0.067381787731656\n",
      "train loss:0.06615090117313575\n",
      "train loss:0.14937781201280523\n",
      "train loss:0.09097384842460234\n",
      "=== epoch:13, train acc:0.972, test acc:0.965 ===, time:  232.44605803489685\n",
      "train loss:0.09717684644362652\n",
      "train loss:0.038585930225464034\n",
      "train loss:0.0755046051009361\n",
      "train loss:0.04604827588096235\n",
      "train loss:0.05682786645349895\n",
      "train loss:0.16365086885557686\n",
      "train loss:0.10850804717958501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.09544355182857073\n",
      "train loss:0.024119760527783755\n",
      "train loss:0.06297376093062232\n",
      "train loss:0.04198599439935867\n",
      "train loss:0.09292739311452576\n",
      "train loss:0.09625024154419265\n",
      "train loss:0.039756774249861106\n",
      "train loss:0.1495760270605172\n",
      "train loss:0.07171057623024962\n",
      "train loss:0.06521306070176895\n",
      "train loss:0.07727171555530031\n",
      "train loss:0.06454797206271795\n",
      "train loss:0.14847860211977712\n",
      "train loss:0.061624545921576804\n",
      "train loss:0.01616645032496901\n",
      "train loss:0.08279861477912098\n",
      "train loss:0.07089960604943467\n",
      "train loss:0.10170857875737688\n",
      "train loss:0.015356366785875243\n",
      "train loss:0.12904562026707148\n",
      "train loss:0.0555973836452007\n",
      "train loss:0.04765930011243662\n",
      "train loss:0.04667095863169743\n",
      "train loss:0.13728156909284497\n",
      "train loss:0.06395438787060793\n",
      "train loss:0.07336470835186058\n",
      "train loss:0.12902659449408238\n",
      "train loss:0.04791218553180471\n",
      "train loss:0.016041346837630713\n",
      "train loss:0.07444674839506694\n",
      "train loss:0.08041390481840857\n",
      "train loss:0.015776762417243878\n",
      "train loss:0.06738855111609501\n",
      "train loss:0.1432951534132565\n",
      "train loss:0.09225232059586777\n",
      "train loss:0.05468568837491969\n",
      "train loss:0.021008204229717692\n",
      "train loss:0.07954260007582514\n",
      "train loss:0.023679258734049254\n",
      "train loss:0.016533516591737574\n",
      "train loss:0.06464738398505693\n",
      "train loss:0.14193143085318607\n",
      "train loss:0.09769270478624749\n",
      "train loss:0.04608428453280299\n",
      "train loss:0.040401675454699276\n",
      "train loss:0.0568910006037714\n",
      "train loss:0.058376540535702855\n",
      "train loss:0.15038109951265086\n",
      "train loss:0.04105115578896323\n",
      "train loss:0.08701761946891341\n",
      "train loss:0.04916416340797836\n",
      "train loss:0.024502043677715107\n",
      "train loss:0.07953829201851069\n",
      "train loss:0.07630035090420591\n",
      "train loss:0.027595195587993563\n",
      "train loss:0.07773038837586155\n",
      "train loss:0.1272172779935525\n",
      "train loss:0.02840757386431221\n",
      "train loss:0.03542209162552967\n",
      "train loss:0.10728392162166625\n",
      "train loss:0.08320973935914854\n",
      "train loss:0.04079538625818886\n",
      "train loss:0.08411315240475553\n",
      "train loss:0.04883590250467598\n",
      "train loss:0.030033379732422393\n",
      "train loss:0.06380072719615963\n",
      "train loss:0.07078958985370815\n",
      "train loss:0.08414830518829981\n",
      "train loss:0.07233149080466621\n",
      "train loss:0.10254025254372191\n",
      "train loss:0.10982849356195704\n",
      "train loss:0.0545664319343985\n",
      "train loss:0.04334626019027249\n",
      "train loss:0.10932017646959517\n",
      "train loss:0.045036487193602516\n",
      "train loss:0.046584712906412556\n",
      "train loss:0.02239008561004937\n",
      "train loss:0.08043466489868355\n",
      "train loss:0.031000371941118297\n",
      "train loss:0.06682887835906269\n",
      "train loss:0.0365041923462798\n",
      "train loss:0.0572056128470279\n",
      "train loss:0.1544370529327216\n",
      "train loss:0.05225058781887359\n",
      "train loss:0.09196031809744579\n",
      "train loss:0.08364625331485279\n",
      "train loss:0.029613613412671217\n",
      "train loss:0.08368450420347436\n",
      "train loss:0.04913586778008518\n",
      "train loss:0.04546202039916378\n",
      "train loss:0.07335292796174951\n",
      "train loss:0.09251157427112539\n",
      "train loss:0.07795632927345744\n",
      "train loss:0.05529878943070404\n",
      "train loss:0.14483363531803006\n",
      "train loss:0.0347969009810189\n",
      "train loss:0.061411236341634784\n",
      "train loss:0.028378618096555022\n",
      "train loss:0.07520068675748431\n",
      "train loss:0.08966923036272434\n",
      "train loss:0.051526777836176985\n",
      "train loss:0.03210472002671858\n",
      "train loss:0.03335798496894345\n",
      "train loss:0.040223709073618955\n",
      "train loss:0.10082048040408477\n",
      "train loss:0.08805008797924913\n",
      "train loss:0.03732047957105296\n",
      "train loss:0.039034856497218426\n",
      "train loss:0.07405387849935681\n",
      "train loss:0.08263323866191928\n",
      "train loss:0.10912029376352908\n",
      "train loss:0.17576911017771246\n",
      "train loss:0.07543267975198789\n",
      "train loss:0.07544407035523797\n",
      "train loss:0.06610836661686995\n",
      "train loss:0.015405218775131277\n",
      "train loss:0.05884617441173834\n",
      "train loss:0.06616293612849278\n",
      "train loss:0.11038546812806743\n",
      "train loss:0.0371371710168055\n",
      "train loss:0.12492030725575967\n",
      "train loss:0.08549574218619113\n",
      "train loss:0.03679130191541182\n",
      "train loss:0.07317907936947944\n",
      "train loss:0.036318113355690095\n",
      "train loss:0.20659282036437912\n",
      "train loss:0.07976615764823011\n",
      "train loss:0.029853076704302674\n",
      "train loss:0.05579544405954136\n",
      "train loss:0.024439079994134288\n",
      "train loss:0.07521251850388527\n",
      "train loss:0.03987128467841584\n",
      "train loss:0.020724680655868667\n",
      "train loss:0.11644203902562054\n",
      "train loss:0.09859044903352167\n",
      "train loss:0.036838929887505464\n",
      "train loss:0.053286548348779064\n",
      "train loss:0.10587296501703569\n",
      "train loss:0.06248160772820079\n",
      "train loss:0.10070516250297615\n",
      "train loss:0.04661760219134904\n",
      "train loss:0.08066911936319282\n",
      "train loss:0.10181156290737428\n",
      "train loss:0.207916934144802\n",
      "train loss:0.08551701751998214\n",
      "train loss:0.02287379969664336\n",
      "train loss:0.07389816510302949\n",
      "train loss:0.03783983522382454\n",
      "train loss:0.028149555884723513\n",
      "train loss:0.18416389871566513\n",
      "train loss:0.04543330156913138\n",
      "train loss:0.04225560416449151\n",
      "train loss:0.04072060610193882\n",
      "train loss:0.02048729063907497\n",
      "train loss:0.03936823736124421\n",
      "train loss:0.0934012238433279\n",
      "train loss:0.07029966854215502\n",
      "train loss:0.06207316112010581\n",
      "train loss:0.04029820570232519\n",
      "train loss:0.08296426955669223\n",
      "train loss:0.13176758288207543\n",
      "train loss:0.025352514822797215\n",
      "train loss:0.04437527334033185\n",
      "train loss:0.05052350117449402\n",
      "train loss:0.15148010587118768\n",
      "train loss:0.06447410003262372\n",
      "train loss:0.06911734787938291\n",
      "train loss:0.04945449263065898\n",
      "train loss:0.02928926773406819\n",
      "train loss:0.06812289282359398\n",
      "train loss:0.08233311075123333\n",
      "train loss:0.11842881577761126\n",
      "train loss:0.06372531230632572\n",
      "train loss:0.07104512398570076\n",
      "train loss:0.03811150454645571\n",
      "train loss:0.13413972863237153\n",
      "train loss:0.028598559999048537\n",
      "train loss:0.0990666430967905\n",
      "train loss:0.08513125607560727\n",
      "train loss:0.07405871066403537\n",
      "train loss:0.036602424917940996\n",
      "train loss:0.04458588889996833\n",
      "train loss:0.059483890436567766\n",
      "train loss:0.10234529580307938\n",
      "train loss:0.050029392393265766\n",
      "train loss:0.025733903279912537\n",
      "train loss:0.13304456047487456\n",
      "train loss:0.06874022020962087\n",
      "train loss:0.07337269152391279\n",
      "train loss:0.08331830735931554\n",
      "train loss:0.02245416208468254\n",
      "train loss:0.03835818444374446\n",
      "train loss:0.01599973354475899\n",
      "train loss:0.06927508894726567\n",
      "train loss:0.029457767742284088\n",
      "train loss:0.06868754110507\n",
      "train loss:0.06820159977093748\n",
      "train loss:0.03499467033843753\n",
      "train loss:0.03244752310442894\n",
      "train loss:0.08556179947261651\n",
      "train loss:0.094570837976775\n",
      "train loss:0.07537647683684381\n",
      "train loss:0.03585678602699862\n",
      "train loss:0.11903076448148793\n",
      "train loss:0.10438215635210848\n",
      "train loss:0.06610233245531974\n",
      "train loss:0.12341773594565969\n",
      "train loss:0.07122137270688224\n",
      "train loss:0.05883797606517409\n",
      "train loss:0.03839312155064422\n",
      "train loss:0.011954664674112572\n",
      "train loss:0.03412305814987579\n",
      "train loss:0.11011458967502556\n",
      "train loss:0.12004270286552203\n",
      "train loss:0.0755065362185277\n",
      "train loss:0.10002360705849667\n",
      "train loss:0.030087610089968776\n",
      "train loss:0.05839004316575572\n",
      "train loss:0.04051345217253175\n",
      "train loss:0.04816996702625771\n",
      "train loss:0.03787185078550821\n",
      "train loss:0.05866146506400347\n",
      "train loss:0.07078745405377108\n",
      "train loss:0.16748464152262074\n",
      "train loss:0.050690969268289934\n",
      "train loss:0.09897520283211327\n",
      "train loss:0.04599730090491444\n",
      "train loss:0.12979648122849508\n",
      "train loss:0.0958219563017312\n",
      "train loss:0.03327209590708564\n",
      "train loss:0.06258595615336977\n",
      "train loss:0.10086721481586944\n",
      "train loss:0.038600090487543925\n",
      "train loss:0.12969846920120479\n",
      "train loss:0.11322095221648842\n",
      "train loss:0.0930316726680332\n",
      "train loss:0.1072807433398318\n",
      "train loss:0.057352772947137726\n",
      "train loss:0.05248485621702139\n",
      "train loss:0.07375538908189962\n",
      "train loss:0.07432368785149172\n",
      "train loss:0.017248206596921663\n",
      "train loss:0.10634160642909152\n",
      "train loss:0.021915091842179452\n",
      "train loss:0.10301198327145084\n",
      "train loss:0.03939098860652721\n",
      "train loss:0.04191367908206663\n",
      "train loss:0.037822284918416105\n",
      "train loss:0.09540752840747135\n",
      "train loss:0.07363686756713109\n",
      "train loss:0.08795312090174147\n",
      "train loss:0.032404598193266174\n",
      "train loss:0.10070985446523974\n",
      "train loss:0.11459683146469202\n",
      "train loss:0.06919236389773921\n",
      "train loss:0.12161735498277272\n",
      "train loss:0.06380184921880516\n",
      "train loss:0.11319328897291273\n",
      "train loss:0.06760532348743781\n",
      "train loss:0.07983718183794418\n",
      "train loss:0.0911323652956779\n",
      "train loss:0.06323315775109209\n",
      "train loss:0.06811922013366875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0856898861669556\n",
      "train loss:0.04381670559703819\n",
      "train loss:0.03712247782230583\n",
      "train loss:0.2240833541007947\n",
      "train loss:0.042659227465574726\n",
      "train loss:0.03516210172046545\n",
      "train loss:0.043141272058995275\n",
      "train loss:0.08195546562632057\n",
      "train loss:0.016150933064136744\n",
      "train loss:0.07623854151416193\n",
      "train loss:0.09796575064673199\n",
      "train loss:0.06145174899147502\n",
      "train loss:0.08783394376667221\n",
      "train loss:0.03139540720330943\n",
      "train loss:0.06562767402142378\n",
      "train loss:0.13361956317365528\n",
      "train loss:0.05128647713005571\n",
      "train loss:0.09866945819281289\n",
      "train loss:0.10116671046148945\n",
      "train loss:0.04727477223911244\n",
      "train loss:0.039323215336112105\n",
      "train loss:0.021662946617527767\n",
      "train loss:0.031057128187767066\n",
      "train loss:0.0350458285143567\n",
      "train loss:0.17175779104957567\n",
      "train loss:0.06640895940564254\n",
      "train loss:0.07068847712442898\n",
      "train loss:0.03152505869777875\n",
      "train loss:0.08015488466848014\n",
      "train loss:0.10443777322893495\n",
      "train loss:0.0439138836717478\n",
      "train loss:0.036106307000045613\n",
      "train loss:0.07490015365207187\n",
      "train loss:0.06858377785844012\n",
      "train loss:0.024586850793875265\n",
      "train loss:0.04223564096009591\n",
      "train loss:0.0357118826174673\n",
      "train loss:0.02270464261872794\n",
      "train loss:0.028910182504079097\n",
      "train loss:0.27070517218233064\n",
      "train loss:0.027512670917239978\n",
      "train loss:0.04414144518263377\n",
      "train loss:0.05238419480457858\n",
      "train loss:0.05068575913502744\n",
      "train loss:0.14959274175209047\n",
      "train loss:0.05086985861904373\n",
      "train loss:0.046655276605695135\n",
      "train loss:0.024585617053627197\n",
      "train loss:0.04827206166492955\n",
      "train loss:0.0704514268245621\n",
      "train loss:0.09125390714230702\n",
      "train loss:0.10990348568570216\n",
      "train loss:0.04267924214809209\n",
      "train loss:0.04463113937525151\n",
      "train loss:0.04206068283439472\n",
      "train loss:0.03641908232179018\n",
      "train loss:0.07006956819884035\n",
      "train loss:0.10987237261547653\n",
      "train loss:0.039923565845324346\n",
      "train loss:0.040946536637223\n",
      "train loss:0.04018372983994576\n",
      "train loss:0.026517890291371627\n",
      "train loss:0.04527153816495852\n",
      "train loss:0.04668279138055589\n",
      "train loss:0.023157035758877145\n",
      "train loss:0.05537944528609131\n",
      "train loss:0.016745464479966214\n",
      "train loss:0.11560862057600668\n",
      "train loss:0.13661442533921261\n",
      "train loss:0.08654402316875043\n",
      "train loss:0.061177613887899523\n",
      "train loss:0.06607115980551623\n",
      "train loss:0.06305729071006645\n",
      "train loss:0.11872365354608012\n",
      "train loss:0.07124586552538088\n",
      "train loss:0.05735143877817811\n",
      "train loss:0.06648285750126974\n",
      "train loss:0.028054625826984293\n",
      "train loss:0.061582829089865954\n",
      "train loss:0.06582624028007822\n",
      "train loss:0.08548482398447335\n",
      "train loss:0.08604906542699753\n",
      "train loss:0.0617452876582513\n",
      "train loss:0.07346891649316951\n",
      "train loss:0.09920131847815065\n",
      "train loss:0.08366221565946079\n",
      "train loss:0.06749827879956202\n",
      "train loss:0.046892284045355656\n",
      "train loss:0.15751900332777743\n",
      "train loss:0.04369865226549014\n",
      "train loss:0.05075078742319224\n",
      "train loss:0.07465440426745207\n",
      "train loss:0.03891658765822276\n",
      "train loss:0.060444579629697695\n",
      "train loss:0.0686749775344503\n",
      "train loss:0.06868662396216935\n",
      "train loss:0.11345817415904319\n",
      "train loss:0.137057908758004\n",
      "train loss:0.08348917198628249\n",
      "train loss:0.07338300735607052\n",
      "train loss:0.05204285232059974\n",
      "train loss:0.09506198400924172\n",
      "train loss:0.022087841117391163\n",
      "train loss:0.057840183858011845\n",
      "train loss:0.03721309439604588\n",
      "train loss:0.0903457996011098\n",
      "train loss:0.08334731288184878\n",
      "train loss:0.10400959695236807\n",
      "train loss:0.03477968777269917\n",
      "train loss:0.06069084785753383\n",
      "train loss:0.10057890881415028\n",
      "train loss:0.06331721294385535\n",
      "train loss:0.080774533545651\n",
      "train loss:0.08779974335137171\n",
      "train loss:0.035437276448965604\n",
      "train loss:0.06841668220003298\n",
      "train loss:0.03443707083963937\n",
      "train loss:0.057373835162466774\n",
      "train loss:0.061577414270889176\n",
      "train loss:0.07153908386523308\n",
      "train loss:0.05727631340059532\n",
      "train loss:0.09433449861666399\n",
      "train loss:0.023548612024575363\n",
      "train loss:0.053940364732175394\n",
      "train loss:0.08809470705191966\n",
      "train loss:0.04170419196597663\n",
      "train loss:0.02201828393053724\n",
      "train loss:0.08402153368443241\n",
      "train loss:0.04662116488646396\n",
      "train loss:0.07861663302352576\n",
      "train loss:0.055769088948984996\n",
      "train loss:0.08738187123750896\n",
      "train loss:0.08942441645399189\n",
      "train loss:0.03913624591299321\n",
      "train loss:0.17046711794462277\n",
      "train loss:0.08476995604112021\n",
      "train loss:0.06871570179036178\n",
      "train loss:0.10387786982924772\n",
      "train loss:0.0859037647157322\n",
      "train loss:0.057426832892065426\n",
      "train loss:0.09683996204087374\n",
      "train loss:0.03421667849694767\n",
      "train loss:0.09514804057048513\n",
      "train loss:0.07520181340099004\n",
      "train loss:0.10337108837520334\n",
      "train loss:0.07256710494803409\n",
      "train loss:0.11798680113346588\n",
      "train loss:0.04005364418610908\n",
      "train loss:0.10452938736466663\n",
      "train loss:0.049301151361632795\n",
      "train loss:0.05097206385164205\n",
      "train loss:0.08411079086944749\n",
      "train loss:0.03723607206732351\n",
      "train loss:0.020904955274913\n",
      "train loss:0.07863720850457095\n",
      "train loss:0.05727931575252176\n",
      "train loss:0.10485750745342644\n",
      "train loss:0.09792571207823157\n",
      "train loss:0.17361874923501347\n",
      "train loss:0.034236960765823214\n",
      "train loss:0.04272362968913006\n",
      "train loss:0.10533475335201986\n",
      "train loss:0.1021577622093616\n",
      "train loss:0.06313698773193863\n",
      "train loss:0.09763663222453912\n",
      "train loss:0.14616284757819448\n",
      "train loss:0.047097829810483764\n",
      "train loss:0.03630890099753315\n",
      "train loss:0.1868224047710265\n",
      "train loss:0.05219158909464422\n",
      "train loss:0.05889438672710865\n",
      "train loss:0.0434692171661484\n",
      "train loss:0.14460235733666177\n",
      "train loss:0.08426447919138515\n",
      "train loss:0.09706739713612349\n",
      "train loss:0.061776458663334755\n",
      "train loss:0.01609972473785265\n",
      "train loss:0.04388109475128639\n",
      "train loss:0.025280733997081327\n",
      "train loss:0.12305696562572621\n",
      "train loss:0.12232151505511929\n",
      "train loss:0.02744141029889971\n",
      "train loss:0.06620373514617559\n",
      "train loss:0.05554038764962887\n",
      "train loss:0.053523447015582\n",
      "train loss:0.07683241672711465\n",
      "train loss:0.15308372632281117\n",
      "train loss:0.09923645917756946\n",
      "train loss:0.13765986493890742\n",
      "train loss:0.15961464723037583\n",
      "train loss:0.05171722001020652\n",
      "train loss:0.056084251303302864\n",
      "train loss:0.04505582158063609\n",
      "train loss:0.024523604438476645\n",
      "train loss:0.05299147261974421\n",
      "train loss:0.13735608446859726\n",
      "train loss:0.058415279669311454\n",
      "train loss:0.06454426540569208\n",
      "train loss:0.10893065959214336\n",
      "train loss:0.037063771475374534\n",
      "train loss:0.10187160784638234\n",
      "train loss:0.08792759437523898\n",
      "train loss:0.021536329961133\n",
      "train loss:0.04472660618039821\n",
      "train loss:0.04421556821214653\n",
      "train loss:0.0395977124609633\n",
      "train loss:0.041302083976562806\n",
      "train loss:0.044179715615784536\n",
      "train loss:0.02805140934083229\n",
      "train loss:0.0912422578450643\n",
      "train loss:0.06265831663553206\n",
      "train loss:0.1720617477953164\n",
      "train loss:0.056622702188133714\n",
      "train loss:0.07369682454348926\n",
      "train loss:0.1046597767391169\n",
      "train loss:0.0617630773643667\n",
      "train loss:0.19131474040772958\n",
      "train loss:0.11612913831167107\n",
      "train loss:0.0817036060452973\n",
      "train loss:0.03125286552312607\n",
      "train loss:0.03927873940637658\n",
      "train loss:0.07679542337540149\n",
      "train loss:0.04476693295150046\n",
      "train loss:0.08854318667569577\n",
      "train loss:0.1309951845563609\n",
      "train loss:0.07121492731243095\n",
      "train loss:0.07026294431061868\n",
      "train loss:0.11979621859541284\n",
      "train loss:0.0611070667344451\n",
      "train loss:0.08783010481451786\n",
      "train loss:0.06981932655219354\n",
      "train loss:0.03318896758259854\n",
      "train loss:0.090861076071524\n",
      "train loss:0.15833252757643346\n",
      "train loss:0.030540675658497572\n",
      "train loss:0.10745145673075082\n",
      "train loss:0.0849491480925352\n",
      "train loss:0.10797510420557259\n",
      "train loss:0.05918460575292319\n",
      "train loss:0.05081167126651199\n",
      "train loss:0.06348069272187655\n",
      "train loss:0.0951316889217493\n",
      "train loss:0.2489401137418461\n",
      "train loss:0.07293296998479072\n",
      "train loss:0.06086708869565488\n",
      "train loss:0.04488227957484123\n",
      "train loss:0.04734732153929646\n",
      "train loss:0.08191009255532986\n",
      "train loss:0.06212685472831624\n",
      "train loss:0.03079300935515762\n",
      "train loss:0.10903050250566236\n",
      "train loss:0.05702084019848457\n",
      "train loss:0.07964338474721004\n",
      "train loss:0.028782055222480358\n",
      "train loss:0.07633522038206472\n",
      "train loss:0.04393987160067692\n",
      "train loss:0.13908381791985833\n",
      "train loss:0.0701936499314041\n",
      "train loss:0.08547446145294359\n",
      "train loss:0.057872642060804065\n",
      "train loss:0.055904134749144914\n",
      "train loss:0.06709174442091681\n",
      "train loss:0.04359067736475878\n",
      "train loss:0.08431220087313619\n",
      "train loss:0.1293049768076564\n",
      "train loss:0.07036020705510601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.044314198747444064\n",
      "train loss:0.08590070565051869\n",
      "train loss:0.09238089876255595\n",
      "train loss:0.12381794522987288\n",
      "train loss:0.053272006347392\n",
      "train loss:0.14812260264869992\n",
      "train loss:0.1545770156082556\n",
      "train loss:0.07303471313918904\n",
      "train loss:0.07639870974120648\n",
      "train loss:0.03225611035249477\n",
      "train loss:0.053625667440694975\n",
      "train loss:0.1901991203083013\n",
      "train loss:0.05892460719265699\n",
      "train loss:0.10680781864361996\n",
      "train loss:0.07000055492399061\n",
      "train loss:0.08066439229313488\n",
      "train loss:0.046614036989603036\n",
      "train loss:0.09353816248613675\n",
      "train loss:0.06663379890380818\n",
      "train loss:0.09257168755336792\n",
      "train loss:0.08806960666890319\n",
      "train loss:0.07239392433620777\n",
      "train loss:0.02974963245404154\n",
      "train loss:0.03353083608543023\n",
      "train loss:0.06773132269047646\n",
      "train loss:0.06122765115811224\n",
      "train loss:0.1101682090462013\n",
      "train loss:0.06764569821257817\n",
      "train loss:0.03208735195035861\n",
      "train loss:0.050468855028440604\n",
      "train loss:0.05405625336213299\n",
      "train loss:0.08168117961020017\n",
      "train loss:0.10516230542238901\n",
      "train loss:0.04200164124068128\n",
      "train loss:0.04407483549271883\n",
      "train loss:0.07562748430912185\n",
      "train loss:0.033159299046517605\n",
      "train loss:0.058165753835664115\n",
      "train loss:0.029081553685058662\n",
      "train loss:0.06674306937835413\n",
      "train loss:0.04503052369484454\n",
      "train loss:0.08658556171787989\n",
      "train loss:0.057406243247042334\n",
      "train loss:0.05711914715773961\n",
      "train loss:0.019511087183235517\n",
      "train loss:0.030306214403042042\n",
      "train loss:0.08395283687548204\n",
      "train loss:0.07818227890831024\n",
      "train loss:0.06096176172842453\n",
      "train loss:0.061990043490772556\n",
      "train loss:0.0642096248036448\n",
      "train loss:0.027156691952357048\n",
      "train loss:0.0526937351867778\n",
      "train loss:0.07529083239993492\n",
      "train loss:0.06664643408751622\n",
      "train loss:0.030827937809436046\n",
      "train loss:0.10629611629867317\n",
      "train loss:0.047121550780028755\n",
      "train loss:0.06795344148966936\n",
      "train loss:0.09098948399798994\n",
      "train loss:0.036506395138743035\n",
      "train loss:0.06771403735556113\n",
      "train loss:0.06321059418602827\n",
      "train loss:0.15272673974483522\n",
      "=== epoch:14, train acc:0.976, test acc:0.968 ===, time:  253.01561164855957\n",
      "train loss:0.09153238167185801\n",
      "train loss:0.033260105050650794\n",
      "train loss:0.052344497951016346\n",
      "train loss:0.02541077885208698\n",
      "train loss:0.021936287545646506\n",
      "train loss:0.12470252011039343\n",
      "train loss:0.058982843981231395\n",
      "train loss:0.049650154478109915\n",
      "train loss:0.05275245488924748\n",
      "train loss:0.07926144332444159\n",
      "train loss:0.06225073862539542\n",
      "train loss:0.13770172373711942\n",
      "train loss:0.06734839657937366\n",
      "train loss:0.05416662085208326\n",
      "train loss:0.041143394107815805\n",
      "train loss:0.090931578867507\n",
      "train loss:0.06395758537601881\n",
      "train loss:0.034329877761675516\n",
      "train loss:0.04773632133156136\n",
      "train loss:0.07471885802661228\n",
      "train loss:0.0502656737052381\n",
      "train loss:0.08039227022697792\n",
      "train loss:0.1279511602712866\n",
      "train loss:0.04270834170029707\n",
      "train loss:0.03746473621281545\n",
      "train loss:0.059372762795260076\n",
      "train loss:0.042851708645310904\n",
      "train loss:0.08886060208202518\n",
      "train loss:0.04642476724378506\n",
      "train loss:0.04597540326300678\n",
      "train loss:0.07751759132239601\n",
      "train loss:0.036020092370560385\n",
      "train loss:0.16853779476268918\n",
      "train loss:0.14543525065669555\n",
      "train loss:0.13046310743428483\n",
      "train loss:0.05428768237592329\n",
      "train loss:0.13499711563779201\n",
      "train loss:0.08115336351470596\n",
      "train loss:0.10848032097342516\n",
      "train loss:0.09713550517231882\n",
      "train loss:0.0673618991994015\n",
      "train loss:0.0449871891672694\n",
      "train loss:0.04810249220991661\n",
      "train loss:0.08504404266464181\n",
      "train loss:0.036458866546146475\n",
      "train loss:0.07371426382975549\n",
      "train loss:0.024626277599832228\n",
      "train loss:0.04515088727821918\n",
      "train loss:0.014905460742481124\n",
      "train loss:0.03999227343021355\n",
      "train loss:0.07118686251432885\n",
      "train loss:0.036276239504863715\n",
      "train loss:0.07452247511962913\n",
      "train loss:0.007820310020231848\n",
      "train loss:0.05869250762157571\n",
      "train loss:0.05444885862965593\n",
      "train loss:0.10420380801169396\n",
      "train loss:0.05236420492532406\n",
      "train loss:0.028450566893060313\n",
      "train loss:0.0500681590795963\n",
      "train loss:0.08717188294969967\n",
      "train loss:0.19942715671501893\n",
      "train loss:0.057707396702377095\n",
      "train loss:0.07103715738845624\n",
      "train loss:0.03540009740783538\n",
      "train loss:0.047761928621128505\n",
      "train loss:0.030986077184134497\n",
      "train loss:0.072345467641985\n",
      "train loss:0.015092566195409305\n",
      "train loss:0.0942087205919406\n",
      "train loss:0.06869721249864909\n",
      "train loss:0.07992319016266758\n",
      "train loss:0.06248508283571743\n",
      "train loss:0.06842572617797463\n",
      "train loss:0.11349633589502339\n",
      "train loss:0.10867762889487606\n",
      "train loss:0.11177443310297386\n",
      "train loss:0.12378144144190735\n",
      "train loss:0.04682244818153641\n",
      "train loss:0.058552336548527935\n",
      "train loss:0.11081198251742984\n",
      "train loss:0.08554032430273041\n",
      "train loss:0.030828318245134868\n",
      "train loss:0.14309582462093268\n",
      "train loss:0.13872449622043684\n",
      "train loss:0.06598575916448282\n",
      "train loss:0.04687824460971427\n",
      "train loss:0.14378698353671213\n",
      "train loss:0.09375683261051143\n",
      "train loss:0.03895965291014389\n",
      "train loss:0.025177149196193356\n",
      "train loss:0.115366079696089\n",
      "train loss:0.015741606656107847\n",
      "train loss:0.03686368186215719\n",
      "train loss:0.11269985383502634\n",
      "train loss:0.09134883593304323\n",
      "train loss:0.07852376724651124\n",
      "train loss:0.014205469883601283\n",
      "train loss:0.047037027588435504\n",
      "train loss:0.13140149119006325\n",
      "train loss:0.11413021094865908\n",
      "train loss:0.03147416106871194\n",
      "train loss:0.05992732212462441\n",
      "train loss:0.05727514428756766\n",
      "train loss:0.07228489418853187\n",
      "train loss:0.06448914293668401\n",
      "train loss:0.09371384696878364\n",
      "train loss:0.01682581058962709\n",
      "train loss:0.02916725169408702\n",
      "train loss:0.043685966061867705\n",
      "train loss:0.04360267710743724\n",
      "train loss:0.08095622180169663\n",
      "train loss:0.10190365037455378\n",
      "train loss:0.051729250215452494\n",
      "train loss:0.143941602401636\n",
      "train loss:0.10771503918248225\n",
      "train loss:0.04259080005193933\n",
      "train loss:0.08529469730465192\n",
      "train loss:0.03780612474345353\n",
      "train loss:0.027564932083953417\n",
      "train loss:0.046121980185137454\n",
      "train loss:0.04713318853242596\n",
      "train loss:0.07011530109211812\n",
      "train loss:0.08363929976894789\n",
      "train loss:0.0250820241053831\n",
      "train loss:0.0486097154582412\n",
      "train loss:0.049378843443939724\n",
      "train loss:0.08466423055205284\n",
      "train loss:0.07722663937407491\n",
      "train loss:0.028444346954590048\n",
      "train loss:0.04602009457095363\n",
      "train loss:0.029732489110052062\n",
      "train loss:0.07578636803958827\n",
      "train loss:0.043126868276949164\n",
      "train loss:0.07408306771937646\n",
      "train loss:0.049008140094045374\n",
      "train loss:0.026233275909045128\n",
      "train loss:0.07682538596190062\n",
      "train loss:0.08256861258667007\n",
      "train loss:0.08311794586173507\n",
      "train loss:0.05371209245959641\n",
      "train loss:0.0485475163042607\n",
      "train loss:0.05272145934716741\n",
      "train loss:0.016308535866708218\n",
      "train loss:0.04966569356651223\n",
      "train loss:0.06425316426880903\n",
      "train loss:0.1532894915368677\n",
      "train loss:0.0893148913670381\n",
      "train loss:0.03893639687333536\n",
      "train loss:0.07764657900192035\n",
      "train loss:0.06902801089624198\n",
      "train loss:0.03467876439312326\n",
      "train loss:0.06693430993309059\n",
      "train loss:0.06117843062522376\n",
      "train loss:0.07071482772592394\n",
      "train loss:0.08786033527223436\n",
      "train loss:0.06026096217969873\n",
      "train loss:0.14203225538239103\n",
      "train loss:0.06926329095244181\n",
      "train loss:0.0590403808569373\n",
      "train loss:0.049569618058587166\n",
      "train loss:0.06830893986919744\n",
      "train loss:0.033955746293508976\n",
      "train loss:0.06288687271272432\n",
      "train loss:0.035657143629814356\n",
      "train loss:0.1298555803136042\n",
      "train loss:0.07863268966550462\n",
      "train loss:0.061106069728254504\n",
      "train loss:0.01860499487370172\n",
      "train loss:0.05537095418825823\n",
      "train loss:0.09782419561431524\n",
      "train loss:0.03312988268755645\n",
      "train loss:0.03143014481795611\n",
      "train loss:0.12073098552735634\n",
      "train loss:0.04136420652538181\n",
      "train loss:0.03274376052990055\n",
      "train loss:0.06786614695071633\n",
      "train loss:0.05681785136266982\n",
      "train loss:0.042189354891056824\n",
      "train loss:0.12287731016014801\n",
      "train loss:0.041910238915254625\n",
      "train loss:0.07267076040595129\n",
      "train loss:0.026064980791106057\n",
      "train loss:0.04511297710901206\n",
      "train loss:0.03667951439909849\n",
      "train loss:0.11749828010809443\n",
      "train loss:0.04756562163975114\n",
      "train loss:0.033335229965494095\n",
      "train loss:0.07703975175302315\n",
      "train loss:0.07966659856918054\n",
      "train loss:0.18271958712114358\n",
      "train loss:0.09518422302569479\n",
      "train loss:0.11003000744040067\n",
      "train loss:0.038829327266148565\n",
      "train loss:0.04571081898478999\n",
      "train loss:0.029655217743887224\n",
      "train loss:0.07020849992474604\n",
      "train loss:0.10030394143998528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08034041802100378\n",
      "train loss:0.02903728584925951\n",
      "train loss:0.059657241745390846\n",
      "train loss:0.19644602637644112\n",
      "train loss:0.029094809904727136\n",
      "train loss:0.16859127271552424\n",
      "train loss:0.06458220210645144\n",
      "train loss:0.13864323321708372\n",
      "train loss:0.042381182646978016\n",
      "train loss:0.027815021793313046\n",
      "train loss:0.06822984795188812\n",
      "train loss:0.06082865678402127\n",
      "train loss:0.049402580069490803\n",
      "train loss:0.08265886857726126\n",
      "train loss:0.06647505169478882\n",
      "train loss:0.057120140752771366\n",
      "train loss:0.12984474356342546\n",
      "train loss:0.03523847714304658\n",
      "train loss:0.14556145941377385\n",
      "train loss:0.05415475358473624\n",
      "train loss:0.1151074147954271\n",
      "train loss:0.05009104838035181\n",
      "train loss:0.14842970535461816\n",
      "train loss:0.07679476347864206\n",
      "train loss:0.06527807982038404\n",
      "train loss:0.016041021173254837\n",
      "train loss:0.11009598152301452\n",
      "train loss:0.1330202782567901\n",
      "train loss:0.0938954145444536\n",
      "train loss:0.018655334447849246\n",
      "train loss:0.04650409710790766\n",
      "train loss:0.10845739754342304\n",
      "train loss:0.11009833376462225\n",
      "train loss:0.03812207100629379\n",
      "train loss:0.03864948642011298\n",
      "train loss:0.0751010580262957\n",
      "train loss:0.0789707912253851\n",
      "train loss:0.029058937320038725\n",
      "train loss:0.019571877973110295\n",
      "train loss:0.00942955584089203\n",
      "train loss:0.03870827612142289\n",
      "train loss:0.049522067360879725\n",
      "train loss:0.0706259365636039\n",
      "train loss:0.017289865592473336\n",
      "train loss:0.04022359431132539\n",
      "train loss:0.05718240579612913\n",
      "train loss:0.0480685467148205\n",
      "train loss:0.12841734477697447\n",
      "train loss:0.04552649529837033\n",
      "train loss:0.09393876081046941\n",
      "train loss:0.0766604955516849\n",
      "train loss:0.09071649567433893\n",
      "train loss:0.050813504359602885\n",
      "train loss:0.04525736670562371\n",
      "train loss:0.11374736687617634\n",
      "train loss:0.0407183118987398\n",
      "train loss:0.05117354232823982\n",
      "train loss:0.05540134116931374\n",
      "train loss:0.05634541099612665\n",
      "train loss:0.08968637229740763\n",
      "train loss:0.03932205039108233\n",
      "train loss:0.09266187114329902\n",
      "train loss:0.11751370016103564\n",
      "train loss:0.049930993518021556\n",
      "train loss:0.059166852387687055\n",
      "train loss:0.03755725214484371\n",
      "train loss:0.05539866347772067\n",
      "train loss:0.06126658268601341\n",
      "train loss:0.061904757569344396\n",
      "train loss:0.023404768535074786\n",
      "train loss:0.031279259187396054\n",
      "train loss:0.047069972267301925\n",
      "train loss:0.04226409739465208\n",
      "train loss:0.0388293459830871\n",
      "train loss:0.08267601779469144\n",
      "train loss:0.04543292978334821\n",
      "train loss:0.06497858751803935\n",
      "train loss:0.03794593319627745\n",
      "train loss:0.05468710081569546\n",
      "train loss:0.06968368053737886\n",
      "train loss:0.07737015394519905\n",
      "train loss:0.030703965757128717\n",
      "train loss:0.026054151076156905\n",
      "train loss:0.0370120925423337\n",
      "train loss:0.06361399664357624\n",
      "train loss:0.040939212501069584\n",
      "train loss:0.030285950895793067\n",
      "train loss:0.03456832359960608\n",
      "train loss:0.0674087786192184\n",
      "train loss:0.13289642880718014\n",
      "train loss:0.08973028486263988\n",
      "train loss:0.029799280595483587\n",
      "train loss:0.02041311110841195\n",
      "train loss:0.03434507846961055\n",
      "train loss:0.08476468703231944\n",
      "train loss:0.05867335905703697\n",
      "train loss:0.0704305727977525\n",
      "train loss:0.03587540045808547\n",
      "train loss:0.03347940226524342\n",
      "train loss:0.15243444131651057\n",
      "train loss:0.024145209704463638\n",
      "train loss:0.10057407271647857\n",
      "train loss:0.018771351154222696\n",
      "train loss:0.04526860168624202\n",
      "train loss:0.030328496284437057\n",
      "train loss:0.05188971404911447\n",
      "train loss:0.07034675486651397\n",
      "train loss:0.03212385829751991\n",
      "train loss:0.04167889173532371\n",
      "train loss:0.06226368009390934\n",
      "train loss:0.037338665321667124\n",
      "train loss:0.09568838032769442\n",
      "train loss:0.03178401784689627\n",
      "train loss:0.05466508829416844\n",
      "train loss:0.03984567560792091\n",
      "train loss:0.07466952142985406\n",
      "train loss:0.1951531270053778\n",
      "train loss:0.053918892071603206\n",
      "train loss:0.02536338094216079\n",
      "train loss:0.128245299387816\n",
      "train loss:0.02399281192867767\n",
      "train loss:0.0615596300099578\n",
      "train loss:0.02835899500386679\n",
      "train loss:0.025634224229762866\n",
      "train loss:0.07096611373900273\n",
      "train loss:0.03517507220523495\n",
      "train loss:0.12107314782182393\n",
      "train loss:0.06669262111339634\n",
      "train loss:0.0923026327439138\n",
      "train loss:0.06044644545214208\n",
      "train loss:0.014246071072095516\n",
      "train loss:0.06837904411693847\n",
      "train loss:0.04312818220400539\n",
      "train loss:0.028017937066080092\n",
      "train loss:0.02866878802222659\n",
      "train loss:0.07474480518052895\n",
      "train loss:0.04003067880865856\n",
      "train loss:0.03543812214280314\n",
      "train loss:0.0973389660432444\n",
      "train loss:0.06008597069220265\n",
      "train loss:0.12170184857750263\n",
      "train loss:0.06853994364719238\n",
      "train loss:0.11864212784961221\n",
      "train loss:0.024229167966685294\n",
      "train loss:0.05038518705067794\n",
      "train loss:0.04111033370507446\n",
      "train loss:0.056475932763555114\n",
      "train loss:0.041010235473890884\n",
      "train loss:0.07451999400606406\n",
      "train loss:0.052651250374767804\n",
      "train loss:0.01758378866927168\n",
      "train loss:0.022018468136713452\n",
      "train loss:0.07504057124434026\n",
      "train loss:0.06765259598772609\n",
      "train loss:0.047624246366812874\n",
      "train loss:0.03333117104281695\n",
      "train loss:0.036828231366020404\n",
      "train loss:0.03244324944018997\n",
      "train loss:0.03644336143032553\n",
      "train loss:0.07501389531975088\n",
      "train loss:0.14174456933457802\n",
      "train loss:0.0903734234901532\n",
      "train loss:0.021232623759710804\n",
      "train loss:0.06912008735092848\n",
      "train loss:0.043328934480044046\n",
      "train loss:0.021539137984677062\n",
      "train loss:0.12141919955695948\n",
      "train loss:0.07108170938350299\n",
      "train loss:0.03850312406537781\n",
      "train loss:0.0738047788247344\n",
      "train loss:0.12830355323958703\n",
      "train loss:0.056340915913559136\n",
      "train loss:0.035474470101212456\n",
      "train loss:0.03221297526435907\n",
      "train loss:0.10478902437255838\n",
      "train loss:0.13856502056993153\n",
      "train loss:0.057520998627310214\n",
      "train loss:0.023442008478361632\n",
      "train loss:0.01013032696474847\n",
      "train loss:0.06483196462859157\n",
      "train loss:0.1492462855781361\n",
      "train loss:0.05688900874394502\n",
      "train loss:0.050626765608609875\n",
      "train loss:0.023217560435066762\n",
      "train loss:0.032781599907411606\n",
      "train loss:0.03083362511108299\n",
      "train loss:0.07812571530451068\n",
      "train loss:0.03724387422203584\n",
      "train loss:0.0535364077521773\n",
      "train loss:0.015161945520800447\n",
      "train loss:0.023873229326010804\n",
      "train loss:0.046996035829914275\n",
      "train loss:0.05083285368697358\n",
      "train loss:0.10655331642062467\n",
      "train loss:0.044101480049227704\n",
      "train loss:0.06416340752617772\n",
      "train loss:0.0682112358763946\n",
      "train loss:0.1683851409184323\n",
      "train loss:0.035165574755571166\n",
      "train loss:0.07598675675546669\n",
      "train loss:0.07273604331252695\n",
      "train loss:0.0585406884338072\n",
      "train loss:0.039815826790531084\n",
      "train loss:0.19720015130436216\n",
      "train loss:0.06055690771159292\n",
      "train loss:0.05328195242891848\n",
      "train loss:0.06443296578142012\n",
      "train loss:0.10238171061016653\n",
      "train loss:0.029580741223489457\n",
      "train loss:0.08293052411236752\n",
      "train loss:0.057167443760565095\n",
      "train loss:0.04911297299517041\n",
      "train loss:0.0525826469738806\n",
      "train loss:0.09040449452446682\n",
      "train loss:0.018780867763425274\n",
      "train loss:0.07775594261891464\n",
      "train loss:0.040542821941226805\n",
      "train loss:0.03295945914332207\n",
      "train loss:0.06326968064664408\n",
      "train loss:0.09431753090800844\n",
      "train loss:0.06385820852320179\n",
      "train loss:0.1697016634955886\n",
      "train loss:0.02809096245125645\n",
      "train loss:0.027737448037378473\n",
      "train loss:0.05298345867261306\n",
      "train loss:0.03307954899520461\n",
      "train loss:0.06260487381173556\n",
      "train loss:0.041195688190383564\n",
      "train loss:0.05347890074763962\n",
      "train loss:0.11730047414767675\n",
      "train loss:0.024528198133350308\n",
      "train loss:0.05395034750612571\n",
      "train loss:0.029600172539786022\n",
      "train loss:0.07725172066970638\n",
      "train loss:0.05117680374339275\n",
      "train loss:0.04598837499837292\n",
      "train loss:0.055164988214747156\n",
      "train loss:0.09350700744140754\n",
      "train loss:0.053836041407275895\n",
      "train loss:0.05612187771938631\n",
      "train loss:0.01882130570712681\n",
      "train loss:0.059901857482728624\n",
      "train loss:0.0904724223973942\n",
      "train loss:0.08290359048032052\n",
      "train loss:0.03027675383472538\n",
      "train loss:0.02502331746838611\n",
      "train loss:0.03120333144823074\n",
      "train loss:0.03561892541358774\n",
      "train loss:0.0373200333209621\n",
      "train loss:0.06489097003202544\n",
      "train loss:0.025182044039643255\n",
      "train loss:0.06453797255199739\n",
      "train loss:0.13007337877341768\n",
      "train loss:0.06850171379100814\n",
      "train loss:0.05062937597904558\n",
      "train loss:0.0663889837743036\n",
      "train loss:0.028510399205116478\n",
      "train loss:0.05372451702028817\n",
      "train loss:0.008704147915063506\n",
      "train loss:0.10937885688461353\n",
      "train loss:0.04755388054261526\n",
      "train loss:0.042964906321705326\n",
      "train loss:0.051890234360850405\n",
      "train loss:0.030220660022019383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.016335424689513496\n",
      "train loss:0.05119443346593499\n",
      "train loss:0.04423885977311442\n",
      "train loss:0.04092987096357801\n",
      "train loss:0.05282887149025885\n",
      "train loss:0.09947181940878622\n",
      "train loss:0.05633281211416202\n",
      "train loss:0.050749375578230574\n",
      "train loss:0.04644871795910698\n",
      "train loss:0.11620464047713722\n",
      "train loss:0.03142152233862635\n",
      "train loss:0.12726815138478087\n",
      "train loss:0.04742206169513327\n",
      "train loss:0.024780658379178887\n",
      "train loss:0.10477527659007953\n",
      "train loss:0.06677974948898498\n",
      "train loss:0.14625352635170738\n",
      "train loss:0.12775837205983082\n",
      "train loss:0.03915766909730709\n",
      "train loss:0.03024223497044255\n",
      "train loss:0.04291391888102237\n",
      "train loss:0.10969636688173334\n",
      "train loss:0.03295813229781628\n",
      "train loss:0.04395579961498991\n",
      "train loss:0.19108279492380686\n",
      "train loss:0.058791244607212835\n",
      "train loss:0.03132443388663544\n",
      "train loss:0.08681263230068854\n",
      "train loss:0.05616890257895579\n",
      "train loss:0.02301675121595449\n",
      "train loss:0.03048081614491585\n",
      "train loss:0.04220902722712708\n",
      "train loss:0.06724073300970917\n",
      "train loss:0.061151122143018925\n",
      "train loss:0.029426927359139057\n",
      "train loss:0.050433285890560106\n",
      "train loss:0.14669527117916834\n",
      "train loss:0.05619254211928432\n",
      "train loss:0.035685391166138315\n",
      "train loss:0.06703779048996199\n",
      "train loss:0.05559597115491794\n",
      "train loss:0.09964840525929984\n",
      "train loss:0.06678584296316466\n",
      "train loss:0.09632812965226294\n",
      "train loss:0.05594356242811806\n",
      "train loss:0.1517657500291323\n",
      "train loss:0.02163796034080954\n",
      "train loss:0.11133860581480111\n",
      "train loss:0.04763968065043196\n",
      "train loss:0.019753089713444732\n",
      "train loss:0.06846600936359909\n",
      "train loss:0.06727712848627374\n",
      "train loss:0.05508367448581382\n",
      "train loss:0.04133989221147052\n",
      "train loss:0.21236475925211948\n",
      "train loss:0.052923375431194304\n",
      "train loss:0.04836676528796666\n",
      "train loss:0.15556015696969097\n",
      "train loss:0.14177179014794644\n",
      "train loss:0.08113379964621444\n",
      "train loss:0.0330167570023252\n",
      "train loss:0.14833572889934904\n",
      "train loss:0.02862884870760722\n",
      "train loss:0.06836577037269098\n",
      "train loss:0.03346593218398398\n",
      "train loss:0.08084751369261602\n",
      "train loss:0.0176708340958765\n",
      "train loss:0.06089780908135922\n",
      "train loss:0.04321700932165173\n",
      "train loss:0.06293828990548454\n",
      "train loss:0.07283907750341533\n",
      "train loss:0.041546672589993776\n",
      "train loss:0.06887532608496144\n",
      "train loss:0.133264664748129\n",
      "train loss:0.036003025441482095\n",
      "train loss:0.007801479252664254\n",
      "train loss:0.04270023720022508\n",
      "train loss:0.04226169375485756\n",
      "train loss:0.047718074958779694\n",
      "train loss:0.07625732158967363\n",
      "train loss:0.06309622491383399\n",
      "train loss:0.11141527445238532\n",
      "train loss:0.04838379460448249\n",
      "train loss:0.08544817544326021\n",
      "train loss:0.07357440539323716\n",
      "train loss:0.07481038529944628\n",
      "train loss:0.054311527069030016\n",
      "train loss:0.2509871254987058\n",
      "train loss:0.03818442705660043\n",
      "train loss:0.09667574574159209\n",
      "train loss:0.14023426317278823\n",
      "train loss:0.05665909089039471\n",
      "train loss:0.054291577501146875\n",
      "train loss:0.1435686219144894\n",
      "train loss:0.029958224910733088\n",
      "train loss:0.0733741894573634\n",
      "train loss:0.10972022724901663\n",
      "train loss:0.05334003730479453\n",
      "train loss:0.046738217027628946\n",
      "train loss:0.027498324899355775\n",
      "train loss:0.07632432708433949\n",
      "train loss:0.03427885313041849\n",
      "train loss:0.06824980809553402\n",
      "train loss:0.07066071140437981\n",
      "train loss:0.02540472196625903\n",
      "train loss:0.032265897536460926\n",
      "train loss:0.10989363830086354\n",
      "train loss:0.0615490310521746\n",
      "train loss:0.08777047516769303\n",
      "train loss:0.05348797086552168\n",
      "train loss:0.07788839476279652\n",
      "train loss:0.054091910794353645\n",
      "train loss:0.055668017315722976\n",
      "train loss:0.07898254412142591\n",
      "train loss:0.04265313438447934\n",
      "train loss:0.10703451491965182\n",
      "train loss:0.0571277240878178\n",
      "train loss:0.06395457892500869\n",
      "train loss:0.025529458005258358\n",
      "train loss:0.05427161708271272\n",
      "train loss:0.15055354902604623\n",
      "train loss:0.02067214937234016\n",
      "train loss:0.012334461242144821\n",
      "train loss:0.07433146352263593\n",
      "train loss:0.057335226996982146\n",
      "train loss:0.030658545725551278\n",
      "train loss:0.03181000458701932\n",
      "train loss:0.04279671718689758\n",
      "train loss:0.010327082353115406\n",
      "train loss:0.026759330723909045\n",
      "train loss:0.03691308839005031\n",
      "train loss:0.0482192239582485\n",
      "train loss:0.09760593546710891\n",
      "train loss:0.0890821166938702\n",
      "train loss:0.05171370116755458\n",
      "train loss:0.03967814902419837\n",
      "train loss:0.0810808747754941\n",
      "train loss:0.017696994908956865\n",
      "=== epoch:15, train acc:0.977, test acc:0.965 ===, time:  274.3758225440979\n",
      "train loss:0.04069816657921408\n",
      "train loss:0.02680327856411066\n",
      "train loss:0.060515288741474806\n",
      "train loss:0.03557583274504312\n",
      "train loss:0.03464737103757482\n",
      "train loss:0.04875575015115238\n",
      "train loss:0.06022068998237642\n",
      "train loss:0.04258760641774313\n",
      "train loss:0.04800769065123571\n",
      "train loss:0.08521126003309748\n",
      "train loss:0.09752603060561174\n",
      "train loss:0.01638615333840354\n",
      "train loss:0.07075639229564765\n",
      "train loss:0.019638211963611697\n",
      "train loss:0.023989563470763718\n",
      "train loss:0.07463505648078059\n",
      "train loss:0.03769486036720849\n",
      "train loss:0.045478459917655735\n",
      "train loss:0.15487616652684644\n",
      "train loss:0.07336747835205487\n",
      "train loss:0.029615727698373163\n",
      "train loss:0.060713437446678314\n",
      "train loss:0.015099380191590454\n",
      "train loss:0.058329854441473164\n",
      "train loss:0.056172993427539904\n",
      "train loss:0.03780350504657048\n",
      "train loss:0.07321595535738232\n",
      "train loss:0.09302757471326278\n",
      "train loss:0.049187708323036566\n",
      "train loss:0.029701452954993178\n",
      "train loss:0.04738645336017567\n",
      "train loss:0.08527838898348483\n",
      "train loss:0.09802708221280908\n",
      "train loss:0.09271489129078025\n",
      "train loss:0.0335386991240084\n",
      "train loss:0.02945470481466491\n",
      "train loss:0.029253323498430128\n",
      "train loss:0.12910685922679466\n",
      "train loss:0.04749630510546909\n",
      "train loss:0.005304036952002653\n",
      "train loss:0.03752461242024756\n",
      "train loss:0.10006070316332911\n",
      "train loss:0.03704468561303719\n",
      "train loss:0.06614211192061492\n",
      "train loss:0.0487777311013618\n",
      "train loss:0.03164155379565083\n",
      "train loss:0.06204288848922019\n",
      "train loss:0.057344245117340445\n",
      "train loss:0.03481062502194552\n",
      "train loss:0.025723376183068573\n",
      "train loss:0.04413588366788361\n",
      "train loss:0.12040611300171193\n",
      "train loss:0.053691767902143105\n",
      "train loss:0.07189943314930451\n",
      "train loss:0.026608717868892243\n",
      "train loss:0.09180973641135978\n",
      "train loss:0.08072088703467306\n",
      "train loss:0.01857602293430578\n",
      "train loss:0.01675751865399102\n",
      "train loss:0.12827391297344654\n",
      "train loss:0.09314222552452385\n",
      "train loss:0.07248056057924272\n",
      "train loss:0.027313236900406226\n",
      "train loss:0.01660120154141378\n",
      "train loss:0.06953598514453413\n",
      "train loss:0.09259424832999176\n",
      "train loss:0.08991478830166473\n",
      "train loss:0.041759271087770104\n",
      "train loss:0.052883089309336315\n",
      "train loss:0.03445210986771147\n",
      "train loss:0.0974168254626645\n",
      "train loss:0.05200290059084217\n",
      "train loss:0.030345591967435394\n",
      "train loss:0.05056315580605398\n",
      "train loss:0.03254954432497943\n",
      "train loss:0.025643050797844246\n",
      "train loss:0.043843256923984456\n",
      "train loss:0.07307112334446524\n",
      "train loss:0.02050709748252847\n",
      "train loss:0.07709740725396377\n",
      "train loss:0.03859853107998153\n",
      "train loss:0.03650743523742127\n",
      "train loss:0.023399766395487118\n",
      "train loss:0.1318590195146993\n",
      "train loss:0.06187659192749624\n",
      "train loss:0.023066852865172394\n",
      "train loss:0.02406250262797305\n",
      "train loss:0.09718856665793237\n",
      "train loss:0.047095976908777495\n",
      "train loss:0.06252864181062702\n",
      "train loss:0.047859801382356\n",
      "train loss:0.07606716563110515\n",
      "train loss:0.048207934350413366\n",
      "train loss:0.07569347833883051\n",
      "train loss:0.02749275768807634\n",
      "train loss:0.02235949431772695\n",
      "train loss:0.035215024808983794\n",
      "train loss:0.10440221174094994\n",
      "train loss:0.0809269935916061\n",
      "train loss:0.047384455122188945\n",
      "train loss:0.09658609226970842\n",
      "train loss:0.066100021800478\n",
      "train loss:0.01931991639565221\n",
      "train loss:0.03515468364021759\n",
      "train loss:0.11116263510221333\n",
      "train loss:0.025314163110261752\n",
      "train loss:0.06671856204315485\n",
      "train loss:0.0272903438644057\n",
      "train loss:0.08424921591304414\n",
      "train loss:0.07997445619279474\n",
      "train loss:0.050826502483777014\n",
      "train loss:0.08015694171657994\n",
      "train loss:0.030210770474143063\n",
      "train loss:0.0924319858513016\n",
      "train loss:0.041851302125914994\n",
      "train loss:0.057319979644790714\n",
      "train loss:0.05862655441073669\n",
      "train loss:0.054183664304296754\n",
      "train loss:0.07645800489759759\n",
      "train loss:0.02002235736023093\n",
      "train loss:0.11402873383076319\n",
      "train loss:0.026550336910403954\n",
      "train loss:0.10689708437042383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03630917977384749\n",
      "train loss:0.062447318580360324\n",
      "train loss:0.04128945198550748\n",
      "train loss:0.030432593532902823\n",
      "train loss:0.06346787176230004\n",
      "train loss:0.04573956090070423\n",
      "train loss:0.12913504851697913\n",
      "train loss:0.062193610791021994\n",
      "train loss:0.02546026874104602\n",
      "train loss:0.03618677262477689\n",
      "train loss:0.026467287588316908\n",
      "train loss:0.041689191220078546\n",
      "train loss:0.06783127132696024\n",
      "train loss:0.05983593989878584\n",
      "train loss:0.04493629984545713\n",
      "train loss:0.035987867164420345\n",
      "train loss:0.08075157001624486\n",
      "train loss:0.02891055497892321\n",
      "train loss:0.035705092747460115\n",
      "train loss:0.03379661365488284\n",
      "train loss:0.10394799203766288\n",
      "train loss:0.03925915131705505\n",
      "train loss:0.08072191619985222\n",
      "train loss:0.04457121716203205\n",
      "train loss:0.10655878461178618\n",
      "train loss:0.08832055864245786\n",
      "train loss:0.03068375906822983\n",
      "train loss:0.0576372768571047\n",
      "train loss:0.10905800147499066\n",
      "train loss:0.07123313323543261\n",
      "train loss:0.09857612535455262\n",
      "train loss:0.028645299887476692\n",
      "train loss:0.06491106648732302\n",
      "train loss:0.021671354638217774\n",
      "train loss:0.022993778214246335\n",
      "train loss:0.0318940417534378\n",
      "train loss:0.05993229240282865\n",
      "train loss:0.027910427543010995\n",
      "train loss:0.044142541661213244\n",
      "train loss:0.07160101347248259\n",
      "train loss:0.06188491377997906\n",
      "train loss:0.05649113582947672\n",
      "train loss:0.02533327144230329\n",
      "train loss:0.046061309566773324\n",
      "train loss:0.04125826986931598\n",
      "train loss:0.04668601198144423\n",
      "train loss:0.04570425590106109\n",
      "train loss:0.03175546844841998\n",
      "train loss:0.06666496109561061\n",
      "train loss:0.051335380899388466\n",
      "train loss:0.09631124096616762\n",
      "train loss:0.04565296648476598\n",
      "train loss:0.014489621584121872\n",
      "train loss:0.03671325351569761\n",
      "train loss:0.043939264332068594\n",
      "train loss:0.11544156601943456\n",
      "train loss:0.03448275213459831\n",
      "train loss:0.02373203205238259\n",
      "train loss:0.04160587514385962\n",
      "train loss:0.1081619449705481\n",
      "train loss:0.047586287334264225\n",
      "train loss:0.10640352758801372\n",
      "train loss:0.11666899538339148\n",
      "train loss:0.08228976788679068\n",
      "train loss:0.014331631826717211\n",
      "train loss:0.07264533080628993\n",
      "train loss:0.04465071154179226\n",
      "train loss:0.04057564995761775\n",
      "train loss:0.08267687386790488\n",
      "train loss:0.023518106836296012\n",
      "train loss:0.024072355407815757\n",
      "train loss:0.059482807037458396\n",
      "train loss:0.14032848151484115\n",
      "train loss:0.13060667551752847\n",
      "train loss:0.04094813397972438\n",
      "train loss:0.05558967011311114\n",
      "train loss:0.01888930959883283\n",
      "train loss:0.04953910940380193\n",
      "train loss:0.11119053072768122\n",
      "train loss:0.05169267904623724\n",
      "train loss:0.07019136687542\n",
      "train loss:0.031814387221680174\n",
      "train loss:0.13760862918023706\n",
      "train loss:0.19855315678763816\n",
      "train loss:0.0556772791239134\n",
      "train loss:0.04869751915844537\n",
      "train loss:0.044512763605688115\n",
      "train loss:0.03341416366802656\n",
      "train loss:0.061184560853404645\n",
      "train loss:0.06594762197522662\n",
      "train loss:0.061495146044171826\n",
      "train loss:0.08230414135803953\n",
      "train loss:0.041832388596856285\n",
      "train loss:0.1068586385740869\n",
      "train loss:0.04623676371728692\n",
      "train loss:0.054506089493042545\n",
      "train loss:0.10626069053005596\n",
      "train loss:0.029029800726048473\n",
      "train loss:0.02793064168144296\n",
      "train loss:0.015175563799934897\n",
      "train loss:0.04388177224119127\n",
      "train loss:0.022325096766001393\n",
      "train loss:0.12766407446970396\n",
      "train loss:0.06778617823890862\n",
      "train loss:0.03644266014007649\n",
      "train loss:0.04081459394741824\n",
      "train loss:0.02135339047792482\n",
      "train loss:0.1299686290703526\n",
      "train loss:0.06586505818209702\n",
      "train loss:0.0548489613196623\n",
      "train loss:0.07915342227156771\n",
      "train loss:0.07781246496424186\n",
      "train loss:0.04565002408841849\n",
      "train loss:0.14809851801730262\n",
      "train loss:0.04484439572197016\n",
      "train loss:0.08174316693068606\n",
      "train loss:0.022911969493357272\n",
      "train loss:0.059547144857284844\n",
      "train loss:0.024892039339265634\n",
      "train loss:0.0428705091669701\n",
      "train loss:0.02639382200796393\n",
      "train loss:0.13073446669546654\n",
      "train loss:0.03716236626006088\n",
      "train loss:0.09315223810260952\n",
      "train loss:0.043590290832592936\n",
      "train loss:0.03098903492714343\n",
      "train loss:0.05892362630841293\n",
      "train loss:0.017795455589620198\n",
      "train loss:0.028808051644319918\n",
      "train loss:0.01713091384132302\n",
      "train loss:0.08084023594354217\n",
      "train loss:0.02153322818581884\n",
      "train loss:0.018646224990709528\n",
      "train loss:0.04953812809001212\n",
      "train loss:0.07074972533958766\n",
      "train loss:0.10878847372513681\n",
      "train loss:0.04699536629526717\n",
      "train loss:0.05283146822789618\n",
      "train loss:0.05855033502795938\n",
      "train loss:0.02906869882833984\n",
      "train loss:0.028842428391493747\n",
      "train loss:0.05439932796250728\n",
      "train loss:0.057629758330704293\n",
      "train loss:0.07013803543008303\n",
      "train loss:0.053574688877874\n",
      "train loss:0.06632906602223765\n",
      "train loss:0.12062221830373797\n",
      "train loss:0.03140420660558463\n",
      "train loss:0.022132168652362033\n",
      "train loss:0.0792228913855774\n",
      "train loss:0.06827528993870562\n",
      "train loss:0.030918181621653003\n",
      "train loss:0.05285416891721188\n",
      "train loss:0.04511661189860759\n",
      "train loss:0.09823684224086371\n",
      "train loss:0.012321829598164961\n",
      "train loss:0.056037257046254715\n",
      "train loss:0.05441135033104368\n",
      "train loss:0.03668494510172694\n",
      "train loss:0.07846623345073184\n",
      "train loss:0.04331934359391048\n",
      "train loss:0.13085922453945054\n",
      "train loss:0.0867677308635\n",
      "train loss:0.11741993791613002\n",
      "train loss:0.1431703721661174\n",
      "train loss:0.0703265857405262\n",
      "train loss:0.1613753007985713\n",
      "train loss:0.04720320595133769\n",
      "train loss:0.04856630382247696\n",
      "train loss:0.023650811514020407\n",
      "train loss:0.03979723201774031\n",
      "train loss:0.040068278608399475\n",
      "train loss:0.021152385463642235\n",
      "train loss:0.07049057968986171\n",
      "train loss:0.01854086666391367\n",
      "train loss:0.02350801408656641\n",
      "train loss:0.0869408559949284\n",
      "train loss:0.046749711577882096\n",
      "train loss:0.20982679682413546\n",
      "train loss:0.04822586880821445\n",
      "train loss:0.11128719590865868\n",
      "train loss:0.06461962260659267\n",
      "train loss:0.022793579156817092\n",
      "train loss:0.08785574261423389\n",
      "train loss:0.05054067702976237\n",
      "train loss:0.06285734382481797\n",
      "train loss:0.08555759812485561\n",
      "train loss:0.1502169852807648\n",
      "train loss:0.03969382926590129\n",
      "train loss:0.0283244572324994\n",
      "train loss:0.0880017977726776\n",
      "train loss:0.050445194450530695\n",
      "train loss:0.035335670037921284\n",
      "train loss:0.13376182994436076\n",
      "train loss:0.05135412615475307\n",
      "train loss:0.03856456211898698\n",
      "train loss:0.05024958008918844\n",
      "train loss:0.0398619002944009\n",
      "train loss:0.10967093043425524\n",
      "train loss:0.09608059120483334\n",
      "train loss:0.052136966585057634\n",
      "train loss:0.1308077331348936\n",
      "train loss:0.02059200572112098\n",
      "train loss:0.047299908295185114\n",
      "train loss:0.020209388870955816\n",
      "train loss:0.02843239364824776\n",
      "train loss:0.0453440131107892\n",
      "train loss:0.04555649783709209\n",
      "train loss:0.05521057820988427\n",
      "train loss:0.04469009585318722\n",
      "train loss:0.048499923776170434\n",
      "train loss:0.017827638833315698\n",
      "train loss:0.006227948593155211\n",
      "train loss:0.023092229757789434\n",
      "train loss:0.03251623694159098\n",
      "train loss:0.06124454472027126\n",
      "train loss:0.051819534594343714\n",
      "train loss:0.022935008823124735\n",
      "train loss:0.12335630994056865\n",
      "train loss:0.0587528156497073\n",
      "train loss:0.06387099071443929\n",
      "train loss:0.07448627886550917\n",
      "train loss:0.04672889067507945\n",
      "train loss:0.0468422735221421\n",
      "train loss:0.03488119941505887\n",
      "train loss:0.05017218009732154\n",
      "train loss:0.08129171915966746\n",
      "train loss:0.0275418823608244\n",
      "train loss:0.08101623461890119\n",
      "train loss:0.013386118929006787\n",
      "train loss:0.07098848966458048\n",
      "train loss:0.032647266106000106\n",
      "train loss:0.06414662224288166\n",
      "train loss:0.07244722091846797\n",
      "train loss:0.13087831273556785\n",
      "train loss:0.08421864633262334\n",
      "train loss:0.10483603011440186\n",
      "train loss:0.07484480364473749\n",
      "train loss:0.0326473935415348\n",
      "train loss:0.03966478669581292\n",
      "train loss:0.08435384090005665\n",
      "train loss:0.05838351831720636\n",
      "train loss:0.07736091531853244\n",
      "train loss:0.031095643192342745\n",
      "train loss:0.06717687431774752\n",
      "train loss:0.014470142863696925\n",
      "train loss:0.026596018073962533\n",
      "train loss:0.07989883438094621\n",
      "train loss:0.04749676384041618\n",
      "train loss:0.07289518717120606\n",
      "train loss:0.04671049718301673\n",
      "train loss:0.12528055973153254\n",
      "train loss:0.04717106082868232\n",
      "train loss:0.09572405503911473\n",
      "train loss:0.057884916931911945\n",
      "train loss:0.017129979111311356\n",
      "train loss:0.11549922756175807\n",
      "train loss:0.057409906647558254\n",
      "train loss:0.06164605334353901\n",
      "train loss:0.04975196228517714\n",
      "train loss:0.10191062854713598\n",
      "train loss:0.02311897763373933\n",
      "train loss:0.04065787769721763\n",
      "train loss:0.06940989400156411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.060832386675689694\n",
      "train loss:0.03457117006616905\n",
      "train loss:0.015919443468605313\n",
      "train loss:0.13956213492702746\n",
      "train loss:0.05669061077014212\n",
      "train loss:0.04471390103854195\n",
      "train loss:0.049467909938919835\n",
      "train loss:0.04768555652015784\n",
      "train loss:0.11076245188691905\n",
      "train loss:0.07645896788415357\n",
      "train loss:0.07091982419634835\n",
      "train loss:0.043508205807280584\n",
      "train loss:0.04619453494920306\n",
      "train loss:0.02967760029085614\n",
      "train loss:0.040850473278429326\n",
      "train loss:0.08510052023419833\n",
      "train loss:0.060900909294786226\n",
      "train loss:0.0281176221796993\n",
      "train loss:0.05353228038088342\n",
      "train loss:0.02586627876965801\n",
      "train loss:0.07892117865527426\n",
      "train loss:0.08106637577408421\n",
      "train loss:0.07537443199785407\n",
      "train loss:0.06616529259228639\n",
      "train loss:0.05944113856248398\n",
      "train loss:0.03515071527350937\n",
      "train loss:0.0328518683283608\n",
      "train loss:0.0371888303169608\n",
      "train loss:0.18522993106363433\n",
      "train loss:0.051795450223606244\n",
      "train loss:0.07860604692681457\n",
      "train loss:0.034467351028198846\n",
      "train loss:0.045783883945649986\n",
      "train loss:0.05311870367313001\n",
      "train loss:0.0684805076022278\n",
      "train loss:0.02066976401992675\n",
      "train loss:0.13315977607294005\n",
      "train loss:0.03482092075404494\n",
      "train loss:0.008281131499031789\n",
      "train loss:0.051353812393134274\n",
      "train loss:0.04060793746467502\n",
      "train loss:0.07160764448803306\n",
      "train loss:0.026885090354123103\n",
      "train loss:0.06426254696023474\n",
      "train loss:0.04424626944277636\n",
      "train loss:0.04806400445628573\n",
      "train loss:0.03205421525040081\n",
      "train loss:0.028202115724466112\n",
      "train loss:0.025383720020938232\n",
      "train loss:0.02821372829857313\n",
      "train loss:0.16117905383716363\n",
      "train loss:0.04850876945104583\n",
      "train loss:0.03835134245873639\n",
      "train loss:0.06818508435303629\n",
      "train loss:0.09097252921373294\n",
      "train loss:0.022517512821237727\n",
      "train loss:0.0428658235545154\n",
      "train loss:0.07705819421561695\n",
      "train loss:0.03009824216148354\n",
      "train loss:0.030448520140553357\n",
      "train loss:0.018892600261955474\n",
      "train loss:0.08791959270829974\n",
      "train loss:0.05371195795199571\n",
      "train loss:0.06391171060310737\n",
      "train loss:0.054274127865552704\n",
      "train loss:0.03810168946702902\n",
      "train loss:0.09104910231870081\n",
      "train loss:0.03394464040889347\n",
      "train loss:0.019073106510125656\n",
      "train loss:0.04572362583495705\n",
      "train loss:0.0734612874606324\n",
      "train loss:0.023887400248548428\n",
      "train loss:0.11968903754926546\n",
      "train loss:0.021527746341651433\n",
      "train loss:0.027794524112498692\n",
      "train loss:0.1316495989284566\n",
      "train loss:0.08480535539127851\n",
      "train loss:0.0871752897882806\n",
      "train loss:0.05291576402234735\n",
      "train loss:0.0707734428644638\n",
      "train loss:0.021986465832450838\n",
      "train loss:0.08427890361018354\n",
      "train loss:0.025093619440588875\n",
      "train loss:0.10143793916304526\n",
      "train loss:0.01959666301706795\n",
      "train loss:0.05550029670811291\n",
      "train loss:0.04549818297698938\n",
      "train loss:0.07130575027616318\n",
      "train loss:0.03286575717553911\n",
      "train loss:0.04293641319591383\n",
      "train loss:0.03940736551081904\n",
      "train loss:0.024834827250303847\n",
      "train loss:0.07962344290118611\n",
      "train loss:0.03480341821197212\n",
      "train loss:0.12179305947680255\n",
      "train loss:0.05915102010583124\n",
      "train loss:0.06377410486456993\n",
      "train loss:0.04324819024869844\n",
      "train loss:0.03188568462645838\n",
      "train loss:0.03730548901181929\n",
      "train loss:0.09051004779594785\n",
      "train loss:0.13849263423032224\n",
      "train loss:0.07672152817256964\n",
      "train loss:0.028834381473868152\n",
      "train loss:0.12110043131586577\n",
      "train loss:0.028637198214231687\n",
      "train loss:0.031095212219256502\n",
      "train loss:0.14173776439372665\n",
      "train loss:0.10012289286929622\n",
      "train loss:0.11180378262191025\n",
      "train loss:0.04365445232047762\n",
      "train loss:0.04541550501481376\n",
      "train loss:0.042520648528179536\n",
      "train loss:0.06326762393763369\n",
      "train loss:0.06617185586798979\n",
      "train loss:0.1018053583074591\n",
      "train loss:0.07425593573873213\n",
      "train loss:0.08981485017244578\n",
      "train loss:0.03733506465976611\n",
      "train loss:0.08081690845378836\n",
      "train loss:0.07789078296481854\n",
      "train loss:0.03493759514651633\n",
      "train loss:0.03111925640109324\n",
      "train loss:0.051448201433194854\n",
      "train loss:0.022767148225583386\n",
      "train loss:0.06123637761705977\n",
      "train loss:0.07725854413216593\n",
      "train loss:0.024696729024440554\n",
      "train loss:0.08356067347702144\n",
      "train loss:0.0746547976927149\n",
      "train loss:0.022687331050206913\n",
      "train loss:0.02417420403303477\n",
      "train loss:0.022299899052123193\n",
      "train loss:0.027363369791303164\n",
      "train loss:0.017147346099343208\n",
      "train loss:0.09310120485872753\n",
      "train loss:0.02073570052982336\n",
      "train loss:0.03891011322961746\n",
      "train loss:0.09954293031990044\n",
      "train loss:0.17240186991149895\n",
      "train loss:0.027362778686324356\n",
      "train loss:0.019125740432244707\n",
      "train loss:0.03142029578271769\n",
      "train loss:0.021063974712246646\n",
      "train loss:0.05487453220913243\n",
      "train loss:0.03167293053284136\n",
      "train loss:0.05828206396466095\n",
      "train loss:0.01762891634195429\n",
      "train loss:0.037102777858575825\n",
      "train loss:0.04100327497647271\n",
      "train loss:0.08764386273563331\n",
      "train loss:0.0424909777987037\n",
      "train loss:0.05351059806498409\n",
      "train loss:0.10374969527030825\n",
      "train loss:0.10148222096413452\n",
      "train loss:0.03064386137453825\n",
      "train loss:0.04271453684554218\n",
      "train loss:0.08390822195560071\n",
      "train loss:0.07620835294990869\n",
      "train loss:0.024864340434845554\n",
      "train loss:0.02547980940370767\n",
      "train loss:0.12794883991251005\n",
      "train loss:0.13107511210667788\n",
      "train loss:0.07488988491707257\n",
      "train loss:0.07502350869005353\n",
      "train loss:0.024362332200681455\n",
      "train loss:0.025262937149111642\n",
      "train loss:0.04832455240025329\n",
      "train loss:0.04861031229861857\n",
      "train loss:0.03802276416222637\n",
      "train loss:0.0751037248093274\n",
      "train loss:0.02069730641422853\n",
      "train loss:0.07435073995918923\n",
      "train loss:0.08741027883834987\n",
      "train loss:0.029215204233841306\n",
      "train loss:0.03999337727096903\n",
      "train loss:0.06127608406725705\n",
      "train loss:0.06184486796693951\n",
      "train loss:0.11123338524412171\n",
      "train loss:0.03341562392280507\n",
      "train loss:0.05954524404193202\n",
      "train loss:0.10486627650103754\n",
      "train loss:0.044268512534487145\n",
      "train loss:0.027210769468226457\n",
      "train loss:0.059809295636927676\n",
      "train loss:0.11799232219180816\n",
      "train loss:0.06455187374695684\n",
      "train loss:0.05492268314556875\n",
      "train loss:0.007531527624327674\n",
      "train loss:0.05194103782873439\n",
      "train loss:0.05517315461913072\n",
      "train loss:0.039206566841683554\n",
      "train loss:0.03343081000987489\n",
      "train loss:0.02342261733195399\n",
      "train loss:0.0619364358050733\n",
      "train loss:0.15300988661710554\n",
      "train loss:0.0688141102872697\n",
      "train loss:0.04510186431492953\n",
      "train loss:0.04338759507404303\n",
      "train loss:0.01516753661399292\n",
      "train loss:0.03660244972851983\n",
      "train loss:0.05850301569172855\n",
      "train loss:0.04310394280292588\n",
      "train loss:0.06761234507711722\n",
      "train loss:0.026115986584558267\n",
      "train loss:0.049567759759035095\n",
      "train loss:0.042860275425920996\n",
      "train loss:0.07465848765773715\n",
      "train loss:0.02021219347242875\n",
      "train loss:0.04190526928014164\n",
      "train loss:0.026398715764151665\n",
      "train loss:0.03486629666319991\n",
      "train loss:0.07507634426179369\n",
      "=== epoch:16, train acc:0.975, test acc:0.964 ===, time:  295.33218598365784\n",
      "train loss:0.027091214195263107\n",
      "train loss:0.09766451359624316\n",
      "train loss:0.06948252081684565\n",
      "train loss:0.04264015422079008\n",
      "train loss:0.05602318842142186\n",
      "train loss:0.04255147115143921\n",
      "train loss:0.07217424524479182\n",
      "train loss:0.05076339389114118\n",
      "train loss:0.04492118630481557\n",
      "train loss:0.10987254332945624\n",
      "train loss:0.06628027840560727\n",
      "train loss:0.03562703422234797\n",
      "train loss:0.08890696526703706\n",
      "train loss:0.10865136969446869\n",
      "train loss:0.0989299486868444\n",
      "train loss:0.08028579164333592\n",
      "train loss:0.02159857765831982\n",
      "train loss:0.022730355320231325\n",
      "train loss:0.028808790699324058\n",
      "train loss:0.13651712323016463\n",
      "train loss:0.0746829830276397\n",
      "train loss:0.04099430846998118\n",
      "train loss:0.07834288714334373\n",
      "train loss:0.11041887816044386\n",
      "train loss:0.027725875047093736\n",
      "train loss:0.06308583114270698\n",
      "train loss:0.06282648594224317\n",
      "train loss:0.017925739136894082\n",
      "train loss:0.020346068324571146\n",
      "train loss:0.061033773469074015\n",
      "train loss:0.08847337206452949\n",
      "train loss:0.03948608534176784\n",
      "train loss:0.024378535657935865\n",
      "train loss:0.056172075929585875\n",
      "train loss:0.05087709352133613\n",
      "train loss:0.00946674541550196\n",
      "train loss:0.10319341848996558\n",
      "train loss:0.05728323135240438\n",
      "train loss:0.07276656398959468\n",
      "train loss:0.02737549496885806\n",
      "train loss:0.06779983670065165\n",
      "train loss:0.044693424268021434\n",
      "train loss:0.044539879432485795\n",
      "train loss:0.053724104076390986\n",
      "train loss:0.09325868847848374\n",
      "train loss:0.02463903902872392\n",
      "train loss:0.013311926648653582\n",
      "train loss:0.038641032556489215\n",
      "train loss:0.05144789419137519\n",
      "train loss:0.05059950002295901\n",
      "train loss:0.03129202636057418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0415502570260856\n",
      "train loss:0.03795638334770407\n",
      "train loss:0.042822013538655695\n",
      "train loss:0.05683709383350045\n",
      "train loss:0.020225760374545505\n",
      "train loss:0.044049742029852776\n",
      "train loss:0.04558124746359174\n",
      "train loss:0.04325471606861418\n",
      "train loss:0.13281206391929953\n",
      "train loss:0.10041894209470824\n",
      "train loss:0.018487493638208875\n",
      "train loss:0.009106750459701846\n",
      "train loss:0.09348455584078501\n",
      "train loss:0.09015208148134306\n",
      "train loss:0.03635887509897938\n",
      "train loss:0.0837116654440437\n",
      "train loss:0.05654257012372988\n",
      "train loss:0.09675774946163088\n",
      "train loss:0.04818006598069565\n",
      "train loss:0.0675973846857351\n",
      "train loss:0.0937333688159672\n",
      "train loss:0.015780845113990204\n",
      "train loss:0.011662804792599353\n",
      "train loss:0.06467292169613229\n",
      "train loss:0.07860742342144977\n",
      "train loss:0.06662715916775416\n",
      "train loss:0.007997706454015225\n",
      "train loss:0.04090871055727166\n",
      "train loss:0.060690248935277406\n",
      "train loss:0.03159538148105918\n",
      "train loss:0.07681518364303169\n",
      "train loss:0.04983441552055589\n",
      "train loss:0.05833956764338523\n",
      "train loss:0.14448809588915534\n",
      "train loss:0.029375988218185795\n",
      "train loss:0.03386132175417488\n",
      "train loss:0.06612045513017926\n",
      "train loss:0.025365059395933923\n",
      "train loss:0.03379171075754399\n",
      "train loss:0.0442841921319287\n",
      "train loss:0.03844479377292332\n",
      "train loss:0.04341779581681946\n",
      "train loss:0.06023522653249005\n",
      "train loss:0.01990236666910943\n",
      "train loss:0.052113854632833405\n",
      "train loss:0.020655453060841048\n",
      "train loss:0.07087607455477284\n",
      "train loss:0.04926761557846216\n",
      "train loss:0.053355159867810024\n",
      "train loss:0.09421216669034715\n",
      "train loss:0.05812344198127653\n",
      "train loss:0.09782786295837073\n",
      "train loss:0.05102558977647763\n",
      "train loss:0.10758558400600098\n",
      "train loss:0.058758053254317794\n",
      "train loss:0.030200961959841805\n",
      "train loss:0.09463656969988926\n",
      "train loss:0.03938615146150409\n",
      "train loss:0.03710319420602919\n",
      "train loss:0.10718859972994838\n",
      "train loss:0.048704447829942106\n",
      "train loss:0.040375290537651105\n",
      "train loss:0.06320445130019048\n",
      "train loss:0.07981352003710424\n",
      "train loss:0.035996351859572034\n",
      "train loss:0.013825235885902242\n",
      "train loss:0.0908699471061116\n",
      "train loss:0.03692723648906114\n",
      "train loss:0.040125835847597636\n",
      "train loss:0.015153270822290076\n",
      "train loss:0.09969885685909118\n",
      "train loss:0.02619771492957139\n",
      "train loss:0.1210157818765788\n",
      "train loss:0.044792964324703366\n",
      "train loss:0.008490226454888873\n",
      "train loss:0.10624943523912353\n",
      "train loss:0.14642426283632232\n",
      "train loss:0.04728822071766995\n",
      "train loss:0.08923645245496192\n",
      "train loss:0.018097580783846007\n",
      "train loss:0.05105717398118477\n",
      "train loss:0.08140709414526885\n",
      "train loss:0.07239140377079259\n",
      "train loss:0.025890350623012814\n",
      "train loss:0.16041302241912742\n",
      "train loss:0.11301632850143911\n",
      "train loss:0.04805455655484682\n",
      "train loss:0.01147932525089126\n",
      "train loss:0.022144872892518493\n",
      "train loss:0.048069018470899776\n",
      "train loss:0.02340948441729317\n",
      "train loss:0.10123367444113214\n",
      "train loss:0.1288900087848144\n",
      "train loss:0.04676897632387613\n",
      "train loss:0.1716760490860326\n",
      "train loss:0.021452574918870263\n",
      "train loss:0.028493842802575598\n",
      "train loss:0.05694103319632152\n",
      "train loss:0.11060585457729001\n",
      "train loss:0.04280905091182238\n",
      "train loss:0.19313501890086165\n",
      "train loss:0.019932411352482752\n",
      "train loss:0.03640435941160713\n",
      "train loss:0.05107020646353526\n",
      "train loss:0.1014759732460212\n",
      "train loss:0.02641200450347017\n",
      "train loss:0.06461387735203297\n",
      "train loss:0.029840119317842348\n",
      "train loss:0.04225061851976225\n",
      "train loss:0.07905442654312854\n",
      "train loss:0.029756094722915342\n",
      "train loss:0.034385937155313934\n",
      "train loss:0.05734533828885931\n",
      "train loss:0.08540018749649829\n",
      "train loss:0.06465606566356658\n",
      "train loss:0.08370904260019099\n",
      "train loss:0.07117942905105262\n",
      "train loss:0.022500774949157778\n",
      "train loss:0.03793595525552485\n",
      "train loss:0.062461096858830174\n",
      "train loss:0.026531550914747227\n",
      "train loss:0.02550514654282002\n",
      "train loss:0.04209558384286288\n",
      "train loss:0.031925097147240136\n",
      "train loss:0.05187794715408362\n",
      "train loss:0.026588830001667056\n",
      "train loss:0.03964657124690269\n",
      "train loss:0.1666100236657892\n",
      "train loss:0.06750898200235006\n",
      "train loss:0.06497878683717766\n",
      "train loss:0.04920692254136216\n",
      "train loss:0.0636706282771616\n",
      "train loss:0.02140594974225999\n",
      "train loss:0.03663783281844006\n",
      "train loss:0.11483135174512314\n",
      "train loss:0.033153782288463225\n",
      "train loss:0.05990254558301225\n",
      "train loss:0.056021847534452336\n",
      "train loss:0.0613162556276827\n",
      "train loss:0.02909359274567099\n",
      "train loss:0.030068568283524402\n",
      "train loss:0.05830246758059974\n",
      "train loss:0.026634214923392095\n",
      "train loss:0.07869559909451934\n",
      "train loss:0.029646338695286652\n",
      "train loss:0.020679145137910727\n",
      "train loss:0.12464987298653311\n",
      "train loss:0.035328685299051775\n",
      "train loss:0.03675855529971515\n",
      "train loss:0.04932902710430456\n",
      "train loss:0.017142495764458886\n",
      "train loss:0.048023819240723284\n",
      "train loss:0.03615298891795677\n",
      "train loss:0.02374685147147394\n",
      "train loss:0.0318905136939677\n",
      "train loss:0.08081861053497001\n",
      "train loss:0.01354222414086299\n",
      "train loss:0.0659016506889143\n",
      "train loss:0.027160711424570744\n",
      "train loss:0.06593387922517922\n",
      "train loss:0.06471280734114962\n",
      "train loss:0.03592342641545913\n",
      "train loss:0.06400113256591035\n",
      "train loss:0.10013387231043534\n",
      "train loss:0.03560906151757731\n",
      "train loss:0.057503763725330496\n",
      "train loss:0.032944228943103365\n",
      "train loss:0.016667289364529672\n",
      "train loss:0.05589909279998731\n",
      "train loss:0.03204618704251828\n",
      "train loss:0.08609488704416596\n",
      "train loss:0.06119117152181862\n",
      "train loss:0.05977076380274084\n",
      "train loss:0.04702797510270174\n",
      "train loss:0.03396812441539713\n",
      "train loss:0.0799434051008984\n",
      "train loss:0.03230522834574695\n",
      "train loss:0.019354938604232513\n",
      "train loss:0.045068274906700186\n",
      "train loss:0.017672150470165585\n",
      "train loss:0.1368380277302127\n",
      "train loss:0.07299994289083822\n",
      "train loss:0.028986889349115738\n",
      "train loss:0.03743892798382921\n",
      "train loss:0.1223152005338205\n",
      "train loss:0.08973798347030043\n",
      "train loss:0.016081307434474657\n",
      "train loss:0.051636465601130575\n",
      "train loss:0.04372836301008623\n",
      "train loss:0.08293133360375166\n",
      "train loss:0.053843321919326705\n",
      "train loss:0.029015541363093623\n",
      "train loss:0.049665603434149955\n",
      "train loss:0.04053996508890093\n",
      "train loss:0.04604045132322728\n",
      "train loss:0.08901863467081807\n",
      "train loss:0.032669020474589076\n",
      "train loss:0.057556559426662074\n",
      "train loss:0.077219964827227\n",
      "train loss:0.04108792198926317\n",
      "train loss:0.008197179083550343\n",
      "train loss:0.03226478716036384\n",
      "train loss:0.06108643908356615\n",
      "train loss:0.030461212688806256\n",
      "train loss:0.02360743038817704\n",
      "train loss:0.07493846402170813\n",
      "train loss:0.03790577599237803\n",
      "train loss:0.11413741317793127\n",
      "train loss:0.04316242727778263\n",
      "train loss:0.01674531030916566\n",
      "train loss:0.046174007386207874\n",
      "train loss:0.04817941961163278\n",
      "train loss:0.05532473869754265\n",
      "train loss:0.05890793138068189\n",
      "train loss:0.08192228061707901\n",
      "train loss:0.07087107548761112\n",
      "train loss:0.03631298393226925\n",
      "train loss:0.017474889583103878\n",
      "train loss:0.024143435499364846\n",
      "train loss:0.03633215000377909\n",
      "train loss:0.025834277137096642\n",
      "train loss:0.021446190441364876\n",
      "train loss:0.043414701826049625\n",
      "train loss:0.026332687424851682\n",
      "train loss:0.07623868017797107\n",
      "train loss:0.11161444009130791\n",
      "train loss:0.0623709627282445\n",
      "train loss:0.11518506960783424\n",
      "train loss:0.02663983373178231\n",
      "train loss:0.08834521741646748\n",
      "train loss:0.011716811136268912\n",
      "train loss:0.012893396258531602\n",
      "train loss:0.039964116060471205\n",
      "train loss:0.04082739050467477\n",
      "train loss:0.023218033044549592\n",
      "train loss:0.030730327858389365\n",
      "train loss:0.045769766390693245\n",
      "train loss:0.0665465952563292\n",
      "train loss:0.046134602081508734\n",
      "train loss:0.09734004785227734\n",
      "train loss:0.02550561705369653\n",
      "train loss:0.035674483966698485\n",
      "train loss:0.049413177869171036\n",
      "train loss:0.1053099315328399\n",
      "train loss:0.021571217244316664\n",
      "train loss:0.09424200679526477\n",
      "train loss:0.01939129165510207\n",
      "train loss:0.028180466952833782\n",
      "train loss:0.10171406790677599\n",
      "train loss:0.07136514620835296\n",
      "train loss:0.058632189817125556\n",
      "train loss:0.03302126856987233\n",
      "train loss:0.03204865759409719\n",
      "train loss:0.04496574256300975\n",
      "train loss:0.08959084217680764\n",
      "train loss:0.024696713970826446\n",
      "train loss:0.03392155618204988\n",
      "train loss:0.04739503092203355\n",
      "train loss:0.04210810739269833\n",
      "train loss:0.036413480446254885\n",
      "train loss:0.04669657441208502\n",
      "train loss:0.010277309985623184\n",
      "train loss:0.017032883221490613\n",
      "train loss:0.041230104385522735\n",
      "train loss:0.11755830900098457\n",
      "train loss:0.030962279427673763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.040734695904571995\n",
      "train loss:0.05100828871004535\n",
      "train loss:0.05052948846243165\n",
      "train loss:0.062012688486809416\n",
      "train loss:0.05513663030504146\n",
      "train loss:0.02852679659874313\n",
      "train loss:0.04142755296152496\n",
      "train loss:0.02665027293589635\n",
      "train loss:0.04730220022662289\n",
      "train loss:0.11649688431545789\n",
      "train loss:0.12678188067244864\n",
      "train loss:0.04397264220730742\n",
      "train loss:0.07285899362925323\n",
      "train loss:0.06984279626672063\n",
      "train loss:0.0815339944714983\n",
      "train loss:0.03462726031276933\n",
      "train loss:0.0492487519866174\n",
      "train loss:0.09661718318182438\n",
      "train loss:0.11688625945862782\n",
      "train loss:0.011591307538118061\n",
      "train loss:0.04994537188838537\n",
      "train loss:0.06299518350325069\n",
      "train loss:0.038758317158172934\n",
      "train loss:0.09267958414115302\n",
      "train loss:0.06367076051444297\n",
      "train loss:0.025655259695803137\n",
      "train loss:0.05731626507936166\n",
      "train loss:0.0601442027630416\n",
      "train loss:0.08051903348271748\n",
      "train loss:0.04920476731950872\n",
      "train loss:0.060647779745077936\n",
      "train loss:0.04140734167648575\n",
      "train loss:0.03842196328430271\n",
      "train loss:0.057216121947666204\n",
      "train loss:0.06664227455267038\n",
      "train loss:0.016880308777238652\n",
      "train loss:0.08039503238769682\n",
      "train loss:0.08136478378776246\n",
      "train loss:0.14506478293518704\n",
      "train loss:0.1197766023111572\n",
      "train loss:0.06894785019582643\n",
      "train loss:0.03249116499231704\n",
      "train loss:0.03468663985190312\n",
      "train loss:0.007248671992459621\n",
      "train loss:0.08169979846221131\n",
      "train loss:0.06565929250859254\n",
      "train loss:0.024488589156181476\n",
      "train loss:0.06054249869220531\n",
      "train loss:0.037769578092205484\n",
      "train loss:0.09466877513193218\n",
      "train loss:0.050510347298737664\n",
      "train loss:0.04336380145219061\n",
      "train loss:0.07828498561286633\n",
      "train loss:0.021252507748359496\n",
      "train loss:0.05999408857675676\n",
      "train loss:0.10050841964037582\n",
      "train loss:0.004526572119957333\n",
      "train loss:0.020663894836263064\n",
      "train loss:0.02555230929320468\n",
      "train loss:0.032498700579763694\n",
      "train loss:0.027316710857797508\n",
      "train loss:0.028023711787263945\n",
      "train loss:0.06794869705041134\n",
      "train loss:0.013484395499700803\n",
      "train loss:0.043344440077089\n",
      "train loss:0.055163437924041554\n",
      "train loss:0.030205999476029227\n",
      "train loss:0.10387230010731839\n",
      "train loss:0.05570867551753542\n",
      "train loss:0.04141462352043627\n",
      "train loss:0.04114401464758328\n",
      "train loss:0.02596638323510553\n",
      "train loss:0.07650328862896161\n",
      "train loss:0.04762064103179343\n",
      "train loss:0.04451699803883411\n",
      "train loss:0.08508370286594076\n",
      "train loss:0.12015440317757\n",
      "train loss:0.0308391524936974\n",
      "train loss:0.06049729958963598\n",
      "train loss:0.03303736677264195\n",
      "train loss:0.05335148588615766\n",
      "train loss:0.08063495714217117\n",
      "train loss:0.12088572233453773\n",
      "train loss:0.04732000760340679\n",
      "train loss:0.012401646197549791\n",
      "train loss:0.028247585827667288\n",
      "train loss:0.02209964273814504\n",
      "train loss:0.05981297737884584\n",
      "train loss:0.05801609862991319\n",
      "train loss:0.016494452326980318\n",
      "train loss:0.026950469763787673\n",
      "train loss:0.02443009812914955\n",
      "train loss:0.041395867933158075\n",
      "train loss:0.07204122263323255\n",
      "train loss:0.0413312322296441\n",
      "train loss:0.0263143292033866\n",
      "train loss:0.14700175971606935\n",
      "train loss:0.14957487242291476\n",
      "train loss:0.02112603287441301\n",
      "train loss:0.1296830575633426\n",
      "train loss:0.08355114675536295\n",
      "train loss:0.04447795499021329\n",
      "train loss:0.03224638476381851\n",
      "train loss:0.06607988022593368\n",
      "train loss:0.04356297088409759\n",
      "train loss:0.09282946518752982\n",
      "train loss:0.055665170657653945\n",
      "train loss:0.03111601667916387\n",
      "train loss:0.12352467884915526\n",
      "train loss:0.04246069545478152\n",
      "train loss:0.04828585870380166\n",
      "train loss:0.018056153740531905\n",
      "train loss:0.07643166603581814\n",
      "train loss:0.11344559599316092\n",
      "train loss:0.05731595527947223\n",
      "train loss:0.009639743911367427\n",
      "train loss:0.019951594675110068\n",
      "train loss:0.031177140548564356\n",
      "train loss:0.02387932245177247\n",
      "train loss:0.07371868444620938\n",
      "train loss:0.021652631068062225\n",
      "train loss:0.03380995737944048\n",
      "train loss:0.09503730062412549\n",
      "train loss:0.027293927434314205\n",
      "train loss:0.11942695648607816\n",
      "train loss:0.04322602063158074\n",
      "train loss:0.014187699416983139\n",
      "train loss:0.05879459489797754\n",
      "train loss:0.07236048775779874\n",
      "train loss:0.04312250417189706\n",
      "train loss:0.06947687259203734\n",
      "train loss:0.08350529422367126\n",
      "train loss:0.03976074562431229\n",
      "train loss:0.03374915704250494\n",
      "train loss:0.03498858226676935\n",
      "train loss:0.13422110652276723\n",
      "train loss:0.04850325597965321\n",
      "train loss:0.06773568782689587\n",
      "train loss:0.11174461531279789\n",
      "train loss:0.07450266351906706\n",
      "train loss:0.05793925020694989\n",
      "train loss:0.07962154819522295\n",
      "train loss:0.05324535599094413\n",
      "train loss:0.06365312017317262\n",
      "train loss:0.08356352336388313\n",
      "train loss:0.036577599948306026\n",
      "train loss:0.02132051229914494\n",
      "train loss:0.021197913364678304\n",
      "train loss:0.058550800292429164\n",
      "train loss:0.07357637385949471\n",
      "train loss:0.02470835180277618\n",
      "train loss:0.024058702974466217\n",
      "train loss:0.07673455682891518\n",
      "train loss:0.05521683428812665\n",
      "train loss:0.054822653878500924\n",
      "train loss:0.03692449256231242\n",
      "train loss:0.04240177559616937\n",
      "train loss:0.055499394259734845\n",
      "train loss:0.0396282892160156\n",
      "train loss:0.07739233010535468\n",
      "train loss:0.1218489257912523\n",
      "train loss:0.020671705005434412\n",
      "train loss:0.05731160267414369\n",
      "train loss:0.09371258320974922\n",
      "train loss:0.048378352151608316\n",
      "train loss:0.018643730877016734\n",
      "train loss:0.07884283274378685\n",
      "train loss:0.034533839798034906\n",
      "train loss:0.04764115663863481\n",
      "train loss:0.07604036199245016\n",
      "train loss:0.03640669583456337\n",
      "train loss:0.04031082760781234\n",
      "train loss:0.035040404786326376\n",
      "train loss:0.13971641196525322\n",
      "train loss:0.05623066510326168\n",
      "train loss:0.0461649300008583\n",
      "train loss:0.01997160763176737\n",
      "train loss:0.041842423776258936\n",
      "train loss:0.03897684327931102\n",
      "train loss:0.09985304831038615\n",
      "train loss:0.03659589515960294\n",
      "train loss:0.04699737038725264\n",
      "train loss:0.015366977000596058\n",
      "train loss:0.03031083734905372\n",
      "train loss:0.057258167363325826\n",
      "train loss:0.03690548302180003\n",
      "train loss:0.035463833526963355\n",
      "train loss:0.05638571425266052\n",
      "train loss:0.03692312936382833\n",
      "train loss:0.05811426189082436\n",
      "train loss:0.05198693455146658\n",
      "train loss:0.035442922202360824\n",
      "train loss:0.05644266520273134\n",
      "train loss:0.030554190471560657\n",
      "train loss:0.07003201391042899\n",
      "train loss:0.01713788860387437\n",
      "train loss:0.03337979720177892\n",
      "train loss:0.09009400467211369\n",
      "train loss:0.09853374170940743\n",
      "train loss:0.0916082216537108\n",
      "train loss:0.1322647049396917\n",
      "train loss:0.05075804383724489\n",
      "train loss:0.05001837912952304\n",
      "train loss:0.05610454203803578\n",
      "train loss:0.03931710333244642\n",
      "train loss:0.11245245728100914\n",
      "train loss:0.024230846891368327\n",
      "train loss:0.04559331505613265\n",
      "train loss:0.07280124855031964\n",
      "train loss:0.04074779697749168\n",
      "train loss:0.020573353235306686\n",
      "train loss:0.0777006264290237\n",
      "train loss:0.06907355774258367\n",
      "train loss:0.06041008814077641\n",
      "train loss:0.012892800454279978\n",
      "train loss:0.09435036582804326\n",
      "train loss:0.04702250378493144\n",
      "train loss:0.07899131495605953\n",
      "train loss:0.01518331098017456\n",
      "train loss:0.0912733053929286\n",
      "train loss:0.031073919280315908\n",
      "train loss:0.026941546034999278\n",
      "train loss:0.030455291779606607\n",
      "train loss:0.05949288982162751\n",
      "train loss:0.07387275632832474\n",
      "train loss:0.04989591259995789\n",
      "train loss:0.10811693808361124\n",
      "train loss:0.03667732868473976\n",
      "train loss:0.06675353715526415\n",
      "train loss:0.08425066322689757\n",
      "train loss:0.030324136701096488\n",
      "train loss:0.07706179119368292\n",
      "train loss:0.04682355955445269\n",
      "train loss:0.02975286250171809\n",
      "train loss:0.07799943209430876\n",
      "train loss:0.040352282946492846\n",
      "train loss:0.03468767579961532\n",
      "train loss:0.13731627334876204\n",
      "train loss:0.16596733372870007\n",
      "train loss:0.04332751304312886\n",
      "train loss:0.06558843939261856\n",
      "train loss:0.08300013967327474\n",
      "train loss:0.04800683513362992\n",
      "train loss:0.08575351459499661\n",
      "train loss:0.0710023426438485\n",
      "train loss:0.015963207893994535\n",
      "train loss:0.054661182359085465\n",
      "train loss:0.023116181723313714\n",
      "train loss:0.07866472525627585\n",
      "train loss:0.03240157026055377\n",
      "train loss:0.06279735474751971\n",
      "train loss:0.08178543277918726\n",
      "train loss:0.032921213532960854\n",
      "train loss:0.04474580209567264\n",
      "train loss:0.0041965375760359\n",
      "train loss:0.019180817661189255\n",
      "train loss:0.024687859637839656\n",
      "train loss:0.0362467203325475\n",
      "train loss:0.04080098370523648\n",
      "train loss:0.014568797979432408\n",
      "train loss:0.06657148177980018\n",
      "train loss:0.05085284256906966\n",
      "train loss:0.03139146712084027\n",
      "train loss:0.037982745000963235\n",
      "train loss:0.02261314409380235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06959832058896218\n",
      "train loss:0.08546943567265876\n",
      "train loss:0.014287318360114059\n",
      "train loss:0.03838441741142586\n",
      "train loss:0.09476996412834883\n",
      "train loss:0.030365132534959857\n",
      "train loss:0.015549963199683207\n",
      "train loss:0.019220440357190106\n",
      "train loss:0.028989024417550552\n",
      "train loss:0.10916209334918482\n",
      "train loss:0.06909591162384071\n",
      "train loss:0.04408437241697878\n",
      "train loss:0.125102475721189\n",
      "train loss:0.08056653401115671\n",
      "train loss:0.05101293655312299\n",
      "train loss:0.042449564781924035\n",
      "train loss:0.032962754960759774\n",
      "train loss:0.08960424042490278\n",
      "=== epoch:17, train acc:0.979, test acc:0.966 ===, time:  315.9534571170807\n",
      "train loss:0.030601530337108596\n",
      "train loss:0.05365224109816112\n",
      "train loss:0.06830290431663538\n",
      "train loss:0.11757972415229288\n",
      "train loss:0.015321664928966687\n",
      "train loss:0.021310571661937328\n",
      "train loss:0.08865003922647544\n",
      "train loss:0.1185214582463768\n",
      "train loss:0.04014623359824526\n",
      "train loss:0.047659343509574896\n",
      "train loss:0.08077750292162562\n",
      "train loss:0.017273010094590507\n",
      "train loss:0.07462485739431134\n",
      "train loss:0.049189429914405086\n",
      "train loss:0.08496506397861517\n",
      "train loss:0.030647229346789092\n",
      "train loss:0.06611637316318278\n",
      "train loss:0.044402739971587196\n",
      "train loss:0.009335497356303828\n",
      "train loss:0.027173066976820454\n",
      "train loss:0.030422902542673567\n",
      "train loss:0.07136007977718391\n",
      "train loss:0.03824311079250013\n",
      "train loss:0.06271941226836723\n",
      "train loss:0.03762716480740201\n",
      "train loss:0.04378881256963479\n",
      "train loss:0.0882786974350574\n",
      "train loss:0.04222348823120765\n",
      "train loss:0.07528271128160519\n",
      "train loss:0.14286148433481505\n",
      "train loss:0.03593112594640269\n",
      "train loss:0.0567554656133383\n",
      "train loss:0.04169361716495661\n",
      "train loss:0.052797504923059006\n",
      "train loss:0.05520921108032655\n",
      "train loss:0.011768558677161398\n",
      "train loss:0.04252013812447712\n",
      "train loss:0.04661585971453148\n",
      "train loss:0.04372097212533828\n",
      "train loss:0.04865217434536136\n",
      "train loss:0.028042946673746516\n",
      "train loss:0.1090851508374636\n",
      "train loss:0.012266796013493422\n",
      "train loss:0.04582694286173766\n",
      "train loss:0.03292984535032607\n",
      "train loss:0.07224485953469127\n",
      "train loss:0.010882126292389716\n",
      "train loss:0.025407572320453452\n",
      "train loss:0.07811653789373928\n",
      "train loss:0.05816214649563782\n",
      "train loss:0.03897927904593205\n",
      "train loss:0.06293362891771953\n",
      "train loss:0.06399921950400138\n",
      "train loss:0.03306183779256758\n",
      "train loss:0.0332868884789893\n",
      "train loss:0.04036463781546117\n",
      "train loss:0.033883398851482706\n",
      "train loss:0.040112380699216604\n",
      "train loss:0.01531422865044873\n",
      "train loss:0.015352213934316197\n",
      "train loss:0.0676457614555217\n",
      "train loss:0.014208925924790903\n",
      "train loss:0.043028717435141924\n",
      "train loss:0.1166510257645559\n",
      "train loss:0.04804914219235333\n",
      "train loss:0.16300427952736535\n",
      "train loss:0.02374351753596923\n",
      "train loss:0.03598205501376103\n",
      "train loss:0.011093721648724431\n",
      "train loss:0.025249996440748573\n",
      "train loss:0.008857292184463367\n",
      "train loss:0.030298288776798507\n",
      "train loss:0.06612278479871433\n",
      "train loss:0.03723638394358588\n",
      "train loss:0.01968281440179591\n",
      "train loss:0.03817452998454509\n",
      "train loss:0.056462664592829184\n",
      "train loss:0.13365341659476293\n",
      "train loss:0.07408973036454207\n",
      "train loss:0.04270574613909375\n",
      "train loss:0.055459869571899585\n",
      "train loss:0.039641580613967255\n",
      "train loss:0.04277025460127493\n",
      "train loss:0.01328593719866943\n",
      "train loss:0.07001026866206572\n",
      "train loss:0.0381737206440174\n",
      "train loss:0.07166085633269105\n",
      "train loss:0.04750686859981862\n",
      "train loss:0.06466778037447492\n",
      "train loss:0.03136449261276415\n",
      "train loss:0.03424641443766641\n",
      "train loss:0.05082216689663599\n",
      "train loss:0.03415557728122614\n",
      "train loss:0.03139798500199772\n",
      "train loss:0.017396040473176454\n",
      "train loss:0.020569996415885944\n",
      "train loss:0.10351288924001707\n",
      "train loss:0.10424106443585819\n",
      "train loss:0.18698488033771155\n",
      "train loss:0.05956401584459083\n",
      "train loss:0.0034401085923377608\n",
      "train loss:0.08704631730993287\n",
      "train loss:0.07035118965366918\n",
      "train loss:0.02285561768156566\n",
      "train loss:0.12229062206185688\n",
      "train loss:0.12170996075655878\n",
      "train loss:0.034303788843126695\n",
      "train loss:0.0347419490911149\n",
      "train loss:0.051649364056501786\n",
      "train loss:0.0248286382433882\n",
      "train loss:0.05760579349195412\n",
      "train loss:0.040217707666344714\n",
      "train loss:0.08040053709394973\n",
      "train loss:0.02389041584329783\n",
      "train loss:0.016631229924964165\n",
      "train loss:0.12722680342837422\n",
      "train loss:0.04217409066642303\n",
      "train loss:0.045454322870575006\n",
      "train loss:0.03909390675845499\n",
      "train loss:0.06769950207994062\n",
      "train loss:0.06794848433313101\n",
      "train loss:0.03882801853995755\n",
      "train loss:0.032864758880249666\n",
      "train loss:0.09619097508652441\n",
      "train loss:0.02668721915498886\n",
      "train loss:0.03703087136453467\n",
      "train loss:0.027199026908392387\n",
      "train loss:0.017307564967288188\n",
      "train loss:0.07682102608693975\n",
      "train loss:0.16413461633775475\n",
      "train loss:0.04727021255795196\n",
      "train loss:0.07572081682693148\n",
      "train loss:0.046276657204967424\n",
      "train loss:0.024183029219377095\n",
      "train loss:0.062185770712952254\n",
      "train loss:0.064012238196317\n",
      "train loss:0.037822795198857895\n",
      "train loss:0.061639401056127696\n",
      "train loss:0.04057858707932352\n",
      "train loss:0.036899258487651715\n",
      "train loss:0.0787864437329527\n",
      "train loss:0.02477171056739832\n",
      "train loss:0.13003398127424462\n",
      "train loss:0.01945673278069286\n",
      "train loss:0.016572715707346083\n",
      "train loss:0.02169895777512683\n",
      "train loss:0.021610132410553002\n",
      "train loss:0.0399970223715662\n",
      "train loss:0.059713474057755865\n",
      "train loss:0.06974274600585806\n",
      "train loss:0.034852273455379085\n",
      "train loss:0.03343769277022139\n",
      "train loss:0.02837659644633231\n",
      "train loss:0.10186829582381841\n",
      "train loss:0.09973627007671151\n",
      "train loss:0.0389125156020358\n",
      "train loss:0.029121955577091692\n",
      "train loss:0.049805248962291895\n",
      "train loss:0.07577158599772964\n",
      "train loss:0.033792640547263116\n",
      "train loss:0.03511554951555335\n",
      "train loss:0.0560658036742689\n",
      "train loss:0.02910260690994751\n",
      "train loss:0.04711340033617893\n",
      "train loss:0.07291704334266465\n",
      "train loss:0.13250687278577528\n",
      "train loss:0.07522207209106707\n",
      "train loss:0.0264283459311041\n",
      "train loss:0.09699063245572115\n",
      "train loss:0.013392735496763945\n",
      "train loss:0.05881460198892607\n",
      "train loss:0.04370185487015552\n",
      "train loss:0.022794622625227145\n",
      "train loss:0.035013298837423656\n",
      "train loss:0.013260415979554258\n",
      "train loss:0.09393173462063185\n",
      "train loss:0.07450641617124193\n",
      "train loss:0.015727420702183928\n",
      "train loss:0.03390842102512756\n",
      "train loss:0.030034021485042597\n",
      "train loss:0.0679290820719366\n",
      "train loss:0.05198331596592526\n",
      "train loss:0.03745393779816918\n",
      "train loss:0.016672794167204397\n",
      "train loss:0.05771103519526397\n",
      "train loss:0.0848312258516993\n",
      "train loss:0.06704585210016219\n",
      "train loss:0.067134463212892\n",
      "train loss:0.02428442293108915\n",
      "train loss:0.08944248555900437\n",
      "train loss:0.0612050833554191\n",
      "train loss:0.13716216259910458\n",
      "train loss:0.039869578887723196\n",
      "train loss:0.07787429109757243\n",
      "train loss:0.13452481960817583\n",
      "train loss:0.06848521716379344\n",
      "train loss:0.005496635616121736\n",
      "train loss:0.021492049833947136\n",
      "train loss:0.08210516381888935\n",
      "train loss:0.08608120216078519\n",
      "train loss:0.07595630092843488\n",
      "train loss:0.06096182990698613\n",
      "train loss:0.018443415289424857\n",
      "train loss:0.07650532913689191\n",
      "train loss:0.04028223021163198\n",
      "train loss:0.06370195942443384\n",
      "train loss:0.02522015666873597\n",
      "train loss:0.007207261979120016\n",
      "train loss:0.059925518624739944\n",
      "train loss:0.031616718967147475\n",
      "train loss:0.03479976640519577\n",
      "train loss:0.06309441097518165\n",
      "train loss:0.049053127758227344\n",
      "train loss:0.06216557735673975\n",
      "train loss:0.07943236243392211\n",
      "train loss:0.022341165011315514\n",
      "train loss:0.018198955012176905\n",
      "train loss:0.08426778062370952\n",
      "train loss:0.07249674385551881\n",
      "train loss:0.011081075780771579\n",
      "train loss:0.011670067083654366\n",
      "train loss:0.08903371052201409\n",
      "train loss:0.028995459299537202\n",
      "train loss:0.056334958410591066\n",
      "train loss:0.09792057652127503\n",
      "train loss:0.022382903297214533\n",
      "train loss:0.01640121375587438\n",
      "train loss:0.03698413864568281\n",
      "train loss:0.08568108158627175\n",
      "train loss:0.028208962595542973\n",
      "train loss:0.03179657804159999\n",
      "train loss:0.05441246376725516\n",
      "train loss:0.13153775790370198\n",
      "train loss:0.03288456747786972\n",
      "train loss:0.10521351078363456\n",
      "train loss:0.05506038294001599\n",
      "train loss:0.12935158608063768\n",
      "train loss:0.02948536076582335\n",
      "train loss:0.01376096751070535\n",
      "train loss:0.06984524328652032\n",
      "train loss:0.0432600455905246\n",
      "train loss:0.021162701266475684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11442534561991889\n",
      "train loss:0.040324392196238686\n",
      "train loss:0.04334443961886294\n",
      "train loss:0.03145051141919628\n",
      "train loss:0.061011370464911854\n",
      "train loss:0.030027366656481966\n",
      "train loss:0.06854392793741597\n",
      "train loss:0.03926048024741533\n",
      "train loss:0.06823089268064923\n",
      "train loss:0.06536590083446138\n",
      "train loss:0.048216152152339216\n",
      "train loss:0.030538070947329122\n",
      "train loss:0.02917582116631732\n",
      "train loss:0.030181516130905927\n",
      "train loss:0.07912628652082254\n",
      "train loss:0.010874154753740933\n",
      "train loss:0.03525205615280614\n",
      "train loss:0.036528403155816375\n",
      "train loss:0.051274032839132795\n",
      "train loss:0.15635879969210598\n",
      "train loss:0.045274923154960886\n",
      "train loss:0.03363500647378293\n",
      "train loss:0.03696454883357929\n",
      "train loss:0.027812302810756882\n",
      "train loss:0.0913113202540086\n",
      "train loss:0.029620870654289148\n",
      "train loss:0.02714321141906852\n",
      "train loss:0.030716800954538194\n",
      "train loss:0.08924792371991788\n",
      "train loss:0.09024040566959254\n",
      "train loss:0.04506691350003878\n",
      "train loss:0.05498737540189623\n",
      "train loss:0.06636571141787587\n",
      "train loss:0.029213719388698784\n",
      "train loss:0.02572951187453603\n",
      "train loss:0.028059251684494566\n",
      "train loss:0.02398848679563149\n",
      "train loss:0.04314139544405188\n",
      "train loss:0.024213034990183558\n",
      "train loss:0.06166694012890006\n",
      "train loss:0.0494403936932582\n",
      "train loss:0.015071764396407951\n",
      "train loss:0.010510569806873775\n",
      "train loss:0.06296708041281524\n",
      "train loss:0.08427050640656017\n",
      "train loss:0.07827132721730991\n",
      "train loss:0.012583926752469752\n",
      "train loss:0.01733716082574727\n",
      "train loss:0.07827673307130247\n",
      "train loss:0.02105309801423939\n",
      "train loss:0.036699290317398096\n",
      "train loss:0.10314201064718963\n",
      "train loss:0.09553350908801962\n",
      "train loss:0.032580273048956804\n",
      "train loss:0.15694973078817023\n",
      "train loss:0.022205264395244274\n",
      "train loss:0.028528025638839903\n",
      "train loss:0.05333106432802432\n",
      "train loss:0.04918912997277508\n",
      "train loss:0.03394249730307039\n",
      "train loss:0.08993905591322898\n",
      "train loss:0.03358356067199166\n",
      "train loss:0.03004660006013498\n",
      "train loss:0.033685844394091495\n",
      "train loss:0.0846073784034228\n",
      "train loss:0.025111330111867315\n",
      "train loss:0.04256313487449205\n",
      "train loss:0.036632775854749784\n",
      "train loss:0.04024708552093641\n",
      "train loss:0.09176420528270535\n",
      "train loss:0.030043927847858778\n",
      "train loss:0.04792655125260488\n",
      "train loss:0.012296206500023435\n",
      "train loss:0.006062222992017612\n",
      "train loss:0.012550308632369667\n",
      "train loss:0.030267201293824493\n",
      "train loss:0.04407832821940506\n",
      "train loss:0.047527396576337685\n",
      "train loss:0.029232991725731364\n",
      "train loss:0.02553789216448933\n",
      "train loss:0.030336738262062644\n",
      "train loss:0.02794616577552583\n",
      "train loss:0.07117037627122808\n",
      "train loss:0.033779174998339004\n",
      "train loss:0.02831883062181243\n",
      "train loss:0.007271225248321803\n",
      "train loss:0.01265866440396508\n",
      "train loss:0.035900679017054\n",
      "train loss:0.06616069387687909\n",
      "train loss:0.10612181127445997\n",
      "train loss:0.0170788196184515\n",
      "train loss:0.02282415371440116\n",
      "train loss:0.05321661411347189\n",
      "train loss:0.09525480537786207\n",
      "train loss:0.04057918338934646\n",
      "train loss:0.045712650638402325\n",
      "train loss:0.020876258802732937\n",
      "train loss:0.04071953283958394\n",
      "train loss:0.04744178615157248\n",
      "train loss:0.007462085032996232\n",
      "train loss:0.07360081140628487\n",
      "train loss:0.014453338601873766\n",
      "train loss:0.039658084340326534\n",
      "train loss:0.030589981693227082\n",
      "train loss:0.014341001305308305\n",
      "train loss:0.08192549578460642\n",
      "train loss:0.03846598210720276\n",
      "train loss:0.07896142895548162\n",
      "train loss:0.04544582893373999\n",
      "train loss:0.031785708468272736\n",
      "train loss:0.025252741635901157\n",
      "train loss:0.026417755464172292\n",
      "train loss:0.017070499166196688\n",
      "train loss:0.057526527092281704\n",
      "train loss:0.019881981594161716\n",
      "train loss:0.03701613720511806\n",
      "train loss:0.028032726389012726\n",
      "train loss:0.03829384132019206\n",
      "train loss:0.03356579034272866\n",
      "train loss:0.032728654453692156\n",
      "train loss:0.005960459940425727\n",
      "train loss:0.01742312051941063\n",
      "train loss:0.021145831500476955\n",
      "train loss:0.1332747102007394\n",
      "train loss:0.06955459572568584\n",
      "train loss:0.05244543639009809\n",
      "train loss:0.08052980486417621\n",
      "train loss:0.12263738301394433\n",
      "train loss:0.03239368132872558\n",
      "train loss:0.054795153263930356\n",
      "train loss:0.06485707419243238\n",
      "train loss:0.02176037891149087\n",
      "train loss:0.06617947470207984\n",
      "train loss:0.025370306557369673\n",
      "train loss:0.14301479155089605\n",
      "train loss:0.13858196155378655\n",
      "train loss:0.03174368126629987\n",
      "train loss:0.05093941822564876\n",
      "train loss:0.029785133554721885\n",
      "train loss:0.0686660165083706\n",
      "train loss:0.03329050150584975\n",
      "train loss:0.053892427654200256\n",
      "train loss:0.054488072795197365\n",
      "train loss:0.042294632172999676\n",
      "train loss:0.06937337358930241\n",
      "train loss:0.038243390252564444\n",
      "train loss:0.056342899634613\n",
      "train loss:0.023786597086570476\n",
      "train loss:0.021575651862198696\n",
      "train loss:0.10541106625224524\n",
      "train loss:0.07037343689247517\n",
      "train loss:0.04437296493071705\n",
      "train loss:0.07296624507440655\n",
      "train loss:0.03607909660399572\n",
      "train loss:0.034667510628425345\n",
      "train loss:0.03878501985358565\n",
      "train loss:0.05172808978908135\n",
      "train loss:0.04280770515537637\n",
      "train loss:0.026587975405564658\n",
      "train loss:0.0318746161572128\n",
      "train loss:0.02179113268210968\n",
      "train loss:0.09949758576047767\n",
      "train loss:0.03623252510281737\n",
      "train loss:0.037679836613894936\n",
      "train loss:0.03733369151023578\n",
      "train loss:0.04689570076688951\n",
      "train loss:0.053341471175765244\n",
      "train loss:0.08174656494341642\n",
      "train loss:0.0788857911760985\n",
      "train loss:0.022380326848232768\n",
      "train loss:0.03385725624573797\n",
      "train loss:0.019596597098479905\n",
      "train loss:0.11281028716452489\n",
      "train loss:0.04537142648232239\n",
      "train loss:0.05119038041407435\n",
      "train loss:0.04834942288456976\n",
      "train loss:0.038988061565877724\n",
      "train loss:0.03303323392958501\n",
      "train loss:0.11283434132175159\n",
      "train loss:0.022082221339205444\n",
      "train loss:0.10012129143795302\n",
      "train loss:0.007820206910944828\n",
      "train loss:0.04481504648104799\n",
      "train loss:0.03467391736408346\n",
      "train loss:0.034149154702711015\n",
      "train loss:0.049371831496619355\n",
      "train loss:0.04374961275220572\n",
      "train loss:0.049673769471106806\n",
      "train loss:0.02458482744466727\n",
      "train loss:0.04705757359586529\n",
      "train loss:0.02163713824585502\n",
      "train loss:0.010555422179838403\n",
      "train loss:0.022452990359905556\n",
      "train loss:0.07594615880243502\n",
      "train loss:0.04374805871906947\n",
      "train loss:0.06741381286316052\n",
      "train loss:0.02488166326640543\n",
      "train loss:0.022043514137919752\n",
      "train loss:0.059277415259775944\n",
      "train loss:0.03930567726893879\n",
      "train loss:0.02705748945590503\n",
      "train loss:0.07519554703873546\n",
      "train loss:0.09334353193982901\n",
      "train loss:0.015002252840399627\n",
      "train loss:0.06104792262155977\n",
      "train loss:0.08118656913643461\n",
      "train loss:0.05270300053708899\n",
      "train loss:0.04000133284356794\n",
      "train loss:0.06363290836103963\n",
      "train loss:0.004446299899648377\n",
      "train loss:0.04526755122824437\n",
      "train loss:0.14613831646838585\n",
      "train loss:0.018092695309049923\n",
      "train loss:0.029619188350981\n",
      "train loss:0.02091265567262584\n",
      "train loss:0.02259834880550822\n",
      "train loss:0.05211172501438121\n",
      "train loss:0.07051469492860613\n",
      "train loss:0.019498484600477314\n",
      "train loss:0.05226878632176035\n",
      "train loss:0.13180542576041288\n",
      "train loss:0.01694750008494168\n",
      "train loss:0.08729521181910506\n",
      "train loss:0.06081986936308076\n",
      "train loss:0.02632875130618143\n",
      "train loss:0.07231752666073893\n",
      "train loss:0.018251597442736432\n",
      "train loss:0.07834054239522152\n",
      "train loss:0.007377300649894464\n",
      "train loss:0.026172884585213576\n",
      "train loss:0.03891288207979568\n",
      "train loss:0.01831006843529469\n",
      "train loss:0.04459783984442061\n",
      "train loss:0.010883038028798414\n",
      "train loss:0.16535903023261148\n",
      "train loss:0.030412286949253145\n",
      "train loss:0.06458636439654314\n",
      "train loss:0.03695416497763575\n",
      "train loss:0.061327685539613264\n",
      "train loss:0.032343257585375935\n",
      "train loss:0.03285487120246366\n",
      "train loss:0.03554292185161687\n",
      "train loss:0.0667812256620628\n",
      "train loss:0.03719533714228023\n",
      "train loss:0.028258407337582957\n",
      "train loss:0.02740257821414872\n",
      "train loss:0.06918622001550825\n",
      "train loss:0.041844087279418754\n",
      "train loss:0.03212404011595613\n",
      "train loss:0.06517976963767395\n",
      "train loss:0.04131878243428979\n",
      "train loss:0.05130992400937875\n",
      "train loss:0.026415403214683525\n",
      "train loss:0.0868345866310414\n",
      "train loss:0.04753453393252136\n",
      "train loss:0.04415593352550633\n",
      "train loss:0.02100651388247571\n",
      "train loss:0.04287609436303903\n",
      "train loss:0.16775021948474758\n",
      "train loss:0.07673593700186661\n",
      "train loss:0.06848096751047406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.017622422267902213\n",
      "train loss:0.04061869248957211\n",
      "train loss:0.0749935927399023\n",
      "train loss:0.031072373964141607\n",
      "train loss:0.08523193973412059\n",
      "train loss:0.04714689725858812\n",
      "train loss:0.06447537109705782\n",
      "train loss:0.015496223798995264\n",
      "train loss:0.01979017505973563\n",
      "train loss:0.03396543473922149\n",
      "train loss:0.009587559098892525\n",
      "train loss:0.09365495978139465\n",
      "train loss:0.013375728239282568\n",
      "train loss:0.04702164842797213\n",
      "train loss:0.025546959574345596\n",
      "train loss:0.010196315183467855\n",
      "train loss:0.013177807714838525\n",
      "train loss:0.06332455725790044\n",
      "train loss:0.08273308491720222\n",
      "train loss:0.036513181570662\n",
      "train loss:0.026658470645327198\n",
      "train loss:0.11280496113226197\n",
      "train loss:0.014365671094958754\n",
      "train loss:0.07728853228811076\n",
      "train loss:0.07365070876661116\n",
      "train loss:0.023738677367461967\n",
      "train loss:0.05329482301294146\n",
      "train loss:0.01983866259641744\n",
      "train loss:0.03605841395583655\n",
      "train loss:0.02840395279084348\n",
      "train loss:0.02324143513899206\n",
      "train loss:0.05245045545228123\n",
      "train loss:0.02065055568435177\n",
      "train loss:0.016077014595653603\n",
      "train loss:0.06663489427045223\n",
      "train loss:0.02806917291097954\n",
      "train loss:0.05096923685328651\n",
      "train loss:0.017762744024878742\n",
      "train loss:0.016099408660414496\n",
      "train loss:0.05161102561042708\n",
      "train loss:0.05212259390066103\n",
      "train loss:0.018264737390821184\n",
      "train loss:0.08900845732405369\n",
      "train loss:0.039066850604100624\n",
      "train loss:0.05841576637485\n",
      "train loss:0.03420566512428831\n",
      "train loss:0.07183292020797931\n",
      "train loss:0.02766138674751574\n",
      "train loss:0.09786337177383791\n",
      "train loss:0.049278610935291074\n",
      "train loss:0.01992845159770663\n",
      "train loss:0.046442682141166855\n",
      "train loss:0.06599185057776744\n",
      "train loss:0.015649520116536232\n",
      "train loss:0.020794692094066907\n",
      "train loss:0.065319712654331\n",
      "train loss:0.03465200374799027\n",
      "train loss:0.048902536829847\n",
      "train loss:0.013528476636239952\n",
      "train loss:0.016346024295069084\n",
      "train loss:0.042904565148928354\n",
      "train loss:0.06742099341343204\n",
      "train loss:0.0340648333491729\n",
      "train loss:0.04063667894275883\n",
      "train loss:0.03158260313716872\n",
      "train loss:0.07272623064265721\n",
      "train loss:0.07766255903486606\n",
      "train loss:0.10667857425805087\n",
      "train loss:0.04059263455692596\n",
      "train loss:0.04071819332921369\n",
      "train loss:0.1472818029426014\n",
      "train loss:0.10690441065518826\n",
      "train loss:0.0982344116925009\n",
      "train loss:0.10940997331992168\n",
      "train loss:0.02208709359427371\n",
      "train loss:0.02565686836509296\n",
      "train loss:0.04506999659323903\n",
      "train loss:0.05771071346394681\n",
      "train loss:0.042749146198942406\n",
      "train loss:0.05410111208110458\n",
      "train loss:0.06179153901460836\n",
      "train loss:0.03603169063273585\n",
      "train loss:0.02591108508298762\n",
      "train loss:0.0396113097115326\n",
      "train loss:0.034585879577145436\n",
      "train loss:0.04200669856857177\n",
      "train loss:0.03162340109001954\n",
      "train loss:0.023420067601645608\n",
      "train loss:0.027413789999341763\n",
      "train loss:0.05443233354709193\n",
      "train loss:0.12034540831126822\n",
      "train loss:0.02394755808926844\n",
      "train loss:0.057253470685903564\n",
      "train loss:0.020160285770956146\n",
      "train loss:0.03816318502608335\n",
      "train loss:0.1533291638599385\n",
      "train loss:0.049776397225971755\n",
      "=== epoch:18, train acc:0.979, test acc:0.968 ===, time:  336.3786401748657\n",
      "train loss:0.025304779859614383\n",
      "train loss:0.030630875841815227\n",
      "train loss:0.029978618611739238\n",
      "train loss:0.028782816428623098\n",
      "train loss:0.030803681142713417\n",
      "train loss:0.0461034378886038\n",
      "train loss:0.08559536884003621\n",
      "train loss:0.024360590366216975\n",
      "train loss:0.008215027203843183\n",
      "train loss:0.04145286587149574\n",
      "train loss:0.03653993409457555\n",
      "train loss:0.014200845901972702\n",
      "train loss:0.06475666386200764\n",
      "train loss:0.06390158817358206\n",
      "train loss:0.030491878267253966\n",
      "train loss:0.025336290586431068\n",
      "train loss:0.03595593957997685\n",
      "train loss:0.06525763528801287\n",
      "train loss:0.062233005705122475\n",
      "train loss:0.03655478290250952\n",
      "train loss:0.027704341893070646\n",
      "train loss:0.024095245272301655\n",
      "train loss:0.05073003429199735\n",
      "train loss:0.06581155826552171\n",
      "train loss:0.03969135439127402\n",
      "train loss:0.012535149226482946\n",
      "train loss:0.031287833660209444\n",
      "train loss:0.04367919169123133\n",
      "train loss:0.0549215902895448\n",
      "train loss:0.08947637000874183\n",
      "train loss:0.014352769666119227\n",
      "train loss:0.06935627241941866\n",
      "train loss:0.12436342809321982\n",
      "train loss:0.060538542953294\n",
      "train loss:0.03669385692857139\n",
      "train loss:0.18397811610830225\n",
      "train loss:0.021508547380964246\n",
      "train loss:0.029249015184891636\n",
      "train loss:0.028482382197347503\n",
      "train loss:0.09838628678335505\n",
      "train loss:0.01745135916503691\n",
      "train loss:0.0702748416087961\n",
      "train loss:0.033102719071750705\n",
      "train loss:0.09588218139339301\n",
      "train loss:0.040417647056652815\n",
      "train loss:0.045691247973487926\n",
      "train loss:0.05051460275256371\n",
      "train loss:0.034607590986723474\n",
      "train loss:0.016868014135969275\n",
      "train loss:0.021952092464999698\n",
      "train loss:0.048438992010975145\n",
      "train loss:0.06440017009068101\n",
      "train loss:0.028409381944506425\n",
      "train loss:0.015532726133649779\n",
      "train loss:0.06253043843057825\n",
      "train loss:0.05770566039821316\n",
      "train loss:0.17392314076098472\n",
      "train loss:0.05681659928982066\n",
      "train loss:0.09215035615169351\n",
      "train loss:0.0947608209059529\n",
      "train loss:0.027564299627628616\n",
      "train loss:0.028685111848712155\n",
      "train loss:0.05214366839774551\n",
      "train loss:0.03550821917007503\n",
      "train loss:0.055751362507881284\n",
      "train loss:0.07610110721791247\n",
      "train loss:0.08866816642069575\n",
      "train loss:0.04601873732839974\n",
      "train loss:0.030266998956276017\n",
      "train loss:0.0621487245831976\n",
      "train loss:0.022772269688878133\n",
      "train loss:0.06331001336334366\n",
      "train loss:0.11985137610918123\n",
      "train loss:0.05548485797018711\n",
      "train loss:0.020675781142846548\n",
      "train loss:0.045169721968758875\n",
      "train loss:0.0281897844212291\n",
      "train loss:0.04824227166524078\n",
      "train loss:0.014677814775379444\n",
      "train loss:0.08485303357598717\n",
      "train loss:0.021396142827030794\n",
      "train loss:0.01805495195900496\n",
      "train loss:0.03934455913487267\n",
      "train loss:0.020388363290538534\n",
      "train loss:0.015714175477738086\n",
      "train loss:0.052063248893823806\n",
      "train loss:0.03739332723963428\n",
      "train loss:0.045728639464725065\n",
      "train loss:0.07258993354656113\n",
      "train loss:0.0503520113543686\n",
      "train loss:0.1350171045351119\n",
      "train loss:0.013995884579526554\n",
      "train loss:0.024236815681634667\n",
      "train loss:0.0572830746192598\n",
      "train loss:0.03011840687010064\n",
      "train loss:0.028138356412764236\n",
      "train loss:0.04476032410818564\n",
      "train loss:0.04096939588113869\n",
      "train loss:0.04572814940080692\n",
      "train loss:0.061174826018475556\n",
      "train loss:0.029532446463872083\n",
      "train loss:0.04150503084255124\n",
      "train loss:0.12687863971642932\n",
      "train loss:0.03690469116826942\n",
      "train loss:0.07113221244949053\n",
      "train loss:0.028557555889102443\n",
      "train loss:0.1275185583375061\n",
      "train loss:0.07156436779140496\n",
      "train loss:0.04920445416352888\n",
      "train loss:0.054143197543213485\n",
      "train loss:0.023094842325433615\n",
      "train loss:0.07013043247000975\n",
      "train loss:0.03562083508309746\n",
      "train loss:0.03147768456656907\n",
      "train loss:0.06013561255351529\n",
      "train loss:0.024847167466362428\n",
      "train loss:0.050930347651051006\n",
      "train loss:0.030040417404295864\n",
      "train loss:0.017499820117828788\n",
      "train loss:0.08684867647663394\n",
      "train loss:0.03638590807543732\n",
      "train loss:0.07721857633784035\n",
      "train loss:0.018179672402532127\n",
      "train loss:0.034490218414185224\n",
      "train loss:0.020820610468564406\n",
      "train loss:0.047200857521758156\n",
      "train loss:0.02417749611658153\n",
      "train loss:0.04999963218844115\n",
      "train loss:0.06720491756954641\n",
      "train loss:0.06244210233058853\n",
      "train loss:0.038994491633101196\n",
      "train loss:0.048286003114887247\n",
      "train loss:0.04448411836354782\n",
      "train loss:0.034631479037211754\n",
      "train loss:0.04428971429023917\n",
      "train loss:0.012726203278386692\n",
      "train loss:0.03992612707296492\n",
      "train loss:0.05428750322208527\n",
      "train loss:0.028307702420221355\n",
      "train loss:0.07730996228997113\n",
      "train loss:0.022897202098404998\n",
      "train loss:0.03302907734130065\n",
      "train loss:0.059574019463475264\n",
      "train loss:0.04567085988595344\n",
      "train loss:0.027498214621535587\n",
      "train loss:0.040290804574448905\n",
      "train loss:0.0217871099353917\n",
      "train loss:0.07930361771252778\n",
      "train loss:0.027608504442665303\n",
      "train loss:0.08978007638255564\n",
      "train loss:0.08982797342961125\n",
      "train loss:0.019015719661555762\n",
      "train loss:0.06971083951575686\n",
      "train loss:0.0621227619237233\n",
      "train loss:0.03585510430432335\n",
      "train loss:0.04012291503065177\n",
      "train loss:0.02768422659059426\n",
      "train loss:0.10400180929430011\n",
      "train loss:0.06407329906558729\n",
      "train loss:0.046607338898873536\n",
      "train loss:0.05681920515467605\n",
      "train loss:0.037210489498065664\n",
      "train loss:0.018946999030055676\n",
      "train loss:0.06499780809000343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.085291859571717\n",
      "train loss:0.08860398451456256\n",
      "train loss:0.02447884688731321\n",
      "train loss:0.05137253677818414\n",
      "train loss:0.05059245863391882\n",
      "train loss:0.029528108678746067\n",
      "train loss:0.014920955169415169\n",
      "train loss:0.023777570461467546\n",
      "train loss:0.051009377803464984\n",
      "train loss:0.03112277401608056\n",
      "train loss:0.06399886084831945\n",
      "train loss:0.06580712880076395\n",
      "train loss:0.022805948780838952\n",
      "train loss:0.05188364297436825\n",
      "train loss:0.027307953042338386\n",
      "train loss:0.019627522437022905\n",
      "train loss:0.05436496463967761\n",
      "train loss:0.020342976075570913\n",
      "train loss:0.09707852079864301\n",
      "train loss:0.0965328650601574\n",
      "train loss:0.026232963609879267\n",
      "train loss:0.025419245557210847\n",
      "train loss:0.06980955824741836\n",
      "train loss:0.03696141501445469\n",
      "train loss:0.09891252981352733\n",
      "train loss:0.03362593755541347\n",
      "train loss:0.025102917087038087\n",
      "train loss:0.011876595461579525\n",
      "train loss:0.07012929020731398\n",
      "train loss:0.02256242542323774\n",
      "train loss:0.009423575008986454\n",
      "train loss:0.0585466125765765\n",
      "train loss:0.03706215043888614\n",
      "train loss:0.07489044849025524\n",
      "train loss:0.05615233391179573\n",
      "train loss:0.0962852749504086\n",
      "train loss:0.08358595719452197\n",
      "train loss:0.013244509679423437\n",
      "train loss:0.08521129062152395\n",
      "train loss:0.016651626844651896\n",
      "train loss:0.08226235265195822\n",
      "train loss:0.05409921625725463\n",
      "train loss:0.1422945100426217\n",
      "train loss:0.04248357005454067\n",
      "train loss:0.01686334897865039\n",
      "train loss:0.05725681419604485\n",
      "train loss:0.019029715477473487\n",
      "train loss:0.045704593899538605\n",
      "train loss:0.047017348945333215\n",
      "train loss:0.048895108632006225\n",
      "train loss:0.10075720182369642\n",
      "train loss:0.03128224020095206\n",
      "train loss:0.038674058428378774\n",
      "train loss:0.08265905413190447\n",
      "train loss:0.01836887655893628\n",
      "train loss:0.04584623252519313\n",
      "train loss:0.10027474306882532\n",
      "train loss:0.035236859321220886\n",
      "train loss:0.03861946653405285\n",
      "train loss:0.06437407691819398\n",
      "train loss:0.013723074906441155\n",
      "train loss:0.07652874936292439\n",
      "train loss:0.005407805916220428\n",
      "train loss:0.09533449893474827\n",
      "train loss:0.0588078508693207\n",
      "train loss:0.017525311201160364\n",
      "train loss:0.09952487752335956\n",
      "train loss:0.033289946143914284\n",
      "train loss:0.03458379456894129\n",
      "train loss:0.08407681359826262\n",
      "train loss:0.03768622293837838\n",
      "train loss:0.08765231112812943\n",
      "train loss:0.04591249749093567\n",
      "train loss:0.05340965586369711\n",
      "train loss:0.030968627477293027\n",
      "train loss:0.023936051703475746\n",
      "train loss:0.13633668235198815\n",
      "train loss:0.08549303724932711\n",
      "train loss:0.09173744249512888\n",
      "train loss:0.13923197004160304\n",
      "train loss:0.04119520012830606\n",
      "train loss:0.036768832556683895\n",
      "train loss:0.10723744668471026\n",
      "train loss:0.023770652716986095\n",
      "train loss:0.03307646788363203\n",
      "train loss:0.03722120237934796\n",
      "train loss:0.05115992096654864\n",
      "train loss:0.04259592078362802\n",
      "train loss:0.0516716672638299\n",
      "train loss:0.06271532237752359\n",
      "train loss:0.03109342811916957\n",
      "train loss:0.04945660681092716\n",
      "train loss:0.020184934420834234\n",
      "train loss:0.01342944452232689\n",
      "train loss:0.06780976907743219\n",
      "train loss:0.061114224052974155\n",
      "train loss:0.08769384694868944\n",
      "train loss:0.0244540061978164\n",
      "train loss:0.044584943470091024\n",
      "train loss:0.058245177072579174\n",
      "train loss:0.06524613429647164\n",
      "train loss:0.0482303924932584\n",
      "train loss:0.031207067706574068\n",
      "train loss:0.06764484808442439\n",
      "train loss:0.1656961440778548\n",
      "train loss:0.046493313335710384\n",
      "train loss:0.03697224473711995\n",
      "train loss:0.104342789772954\n",
      "train loss:0.051324106474975366\n",
      "train loss:0.06288229164297697\n",
      "train loss:0.14106221170973654\n",
      "train loss:0.062262395949082\n",
      "train loss:0.07552059791640264\n",
      "train loss:0.03642192727081167\n",
      "train loss:0.021704583539492773\n",
      "train loss:0.035867308152274006\n",
      "train loss:0.045177196171504674\n",
      "train loss:0.07205702989058904\n",
      "train loss:0.06503621765864583\n",
      "train loss:0.07026988459940821\n",
      "train loss:0.049403599849731264\n",
      "train loss:0.08366336204500488\n",
      "train loss:0.03449697820676762\n",
      "train loss:0.06390902991827212\n",
      "train loss:0.06037210122581686\n",
      "train loss:0.0504384987581344\n",
      "train loss:0.09918000511076715\n",
      "train loss:0.055785218556805446\n",
      "train loss:0.01477297937035138\n",
      "train loss:0.044453102215178626\n",
      "train loss:0.04579587216549741\n",
      "train loss:0.08171708107251956\n",
      "train loss:0.051441771035541484\n",
      "train loss:0.01573034452977363\n",
      "train loss:0.01781694721715782\n",
      "train loss:0.0370935490813617\n",
      "train loss:0.01703709467354584\n",
      "train loss:0.06260350665870033\n",
      "train loss:0.05710739973816893\n",
      "train loss:0.021368430995091652\n",
      "train loss:0.057716400677568246\n",
      "train loss:0.053176371297139056\n",
      "train loss:0.022135372260329387\n",
      "train loss:0.1106557374485769\n",
      "train loss:0.030129351725366633\n",
      "train loss:0.018616078550481033\n",
      "train loss:0.0559046918414043\n",
      "train loss:0.017439564359172304\n",
      "train loss:0.05864858719614532\n",
      "train loss:0.04626996152203023\n",
      "train loss:0.06229781514524732\n",
      "train loss:0.048434378423712815\n",
      "train loss:0.01843597978214643\n",
      "train loss:0.0604199486215272\n",
      "train loss:0.11053421350412297\n",
      "train loss:0.021035652671398997\n",
      "train loss:0.07408986399077727\n",
      "train loss:0.04724567342493595\n",
      "train loss:0.03980336731241832\n",
      "train loss:0.09657512215519243\n",
      "train loss:0.09673538407161826\n",
      "train loss:0.07966754797717752\n",
      "train loss:0.057019973501892175\n",
      "train loss:0.03597059650708977\n",
      "train loss:0.02416906304025301\n",
      "train loss:0.024288806768987904\n",
      "train loss:0.024708421248904187\n",
      "train loss:0.05937263614918535\n",
      "train loss:0.0540641957496151\n",
      "train loss:0.0439559205830391\n",
      "train loss:0.04036000234284459\n",
      "train loss:0.013582343984997422\n",
      "train loss:0.09989339477617594\n",
      "train loss:0.09021592571338828\n",
      "train loss:0.030646078375136544\n",
      "train loss:0.020821708159935243\n",
      "train loss:0.011567957377025897\n",
      "train loss:0.05534046365891606\n",
      "train loss:0.0351706246148555\n",
      "train loss:0.07523086490324646\n",
      "train loss:0.025944824149532107\n",
      "train loss:0.01714718499842721\n",
      "train loss:0.01718129241259519\n",
      "train loss:0.016278030475289626\n",
      "train loss:0.060860258072484914\n",
      "train loss:0.026513511730877893\n",
      "train loss:0.1601273090288094\n",
      "train loss:0.06672013498802035\n",
      "train loss:0.030106232454453083\n",
      "train loss:0.05451882992897492\n",
      "train loss:0.043113943295075174\n",
      "train loss:0.03411357768669077\n",
      "train loss:0.05052061768495238\n",
      "train loss:0.06649983995060635\n",
      "train loss:0.054878863754354974\n",
      "train loss:0.028950049212897958\n",
      "train loss:0.053689136832207246\n",
      "train loss:0.032001712948950475\n",
      "train loss:0.011255951168774305\n",
      "train loss:0.0445351872758467\n",
      "train loss:0.04237116549308889\n",
      "train loss:0.04289807760284637\n",
      "train loss:0.030602569900860462\n",
      "train loss:0.05361117224585929\n",
      "train loss:0.014482290374565323\n",
      "train loss:0.029629074273813307\n",
      "train loss:0.014259008102022448\n",
      "train loss:0.02510717450301156\n",
      "train loss:0.04237483705490899\n",
      "train loss:0.022437934396226683\n",
      "train loss:0.04862671829977406\n",
      "train loss:0.058054019861490926\n",
      "train loss:0.05347396978902764\n",
      "train loss:0.07467600282444942\n",
      "train loss:0.03241936833800327\n",
      "train loss:0.04807785528832421\n",
      "train loss:0.02489276395362994\n",
      "train loss:0.08022284445896596\n",
      "train loss:0.09053928598109102\n",
      "train loss:0.11726922298383714\n",
      "train loss:0.028359118912148568\n",
      "train loss:0.04362682851828625\n",
      "train loss:0.13509951675271092\n",
      "train loss:0.04257908698256356\n",
      "train loss:0.04586836382694604\n",
      "train loss:0.013179855198392328\n",
      "train loss:0.05043494497619466\n",
      "train loss:0.038680965304474096\n",
      "train loss:0.016548028995718566\n",
      "train loss:0.06724430801518767\n",
      "train loss:0.04183904413380257\n",
      "train loss:0.020817935991785073\n",
      "train loss:0.011704592133560489\n",
      "train loss:0.04572759239957692\n",
      "train loss:0.058174130020499086\n",
      "train loss:0.025839413854653177\n",
      "train loss:0.03448093495364486\n",
      "train loss:0.017588838329737014\n",
      "train loss:0.020156152983132926\n",
      "train loss:0.028373123048069653\n",
      "train loss:0.11917678559731147\n",
      "train loss:0.040197679881126866\n",
      "train loss:0.025061612399699205\n",
      "train loss:0.035783899680913674\n",
      "train loss:0.05104707878755511\n",
      "train loss:0.01305534155725949\n",
      "train loss:0.026446097881435718\n",
      "train loss:0.0418760719688411\n",
      "train loss:0.04016548110025085\n",
      "train loss:0.0325706733207473\n",
      "train loss:0.05316456138651838\n",
      "train loss:0.07442601531476092\n",
      "train loss:0.05927697444389348\n",
      "train loss:0.028944871967968924\n",
      "train loss:0.0515020907954213\n",
      "train loss:0.03345580461864316\n",
      "train loss:0.0258706074123534\n",
      "train loss:0.11892864602942878\n",
      "train loss:0.008133870778505336\n",
      "train loss:0.0951898802535748\n",
      "train loss:0.07079631771870983\n",
      "train loss:0.04972197974642757\n",
      "train loss:0.06983040083331786\n",
      "train loss:0.11361630497189232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02993171883871924\n",
      "train loss:0.042216925097429386\n",
      "train loss:0.037290170412872935\n",
      "train loss:0.033036659810797585\n",
      "train loss:0.0776881670818122\n",
      "train loss:0.041682734936712776\n",
      "train loss:0.06501201679634211\n",
      "train loss:0.013669807368823814\n",
      "train loss:0.1019665082985772\n",
      "train loss:0.043258551663657864\n",
      "train loss:0.03803997647589206\n",
      "train loss:0.0674892293047442\n",
      "train loss:0.011701751341766053\n",
      "train loss:0.12169493473145877\n",
      "train loss:0.07894256485565904\n",
      "train loss:0.0780348780591279\n",
      "train loss:0.08861034597180226\n",
      "train loss:0.05164886611316225\n",
      "train loss:0.024181142593550944\n",
      "train loss:0.028849603350860363\n",
      "train loss:0.03688068711739245\n",
      "train loss:0.01581501956771678\n",
      "train loss:0.016981456344272085\n",
      "train loss:0.01597270541170721\n",
      "train loss:0.03197861152209043\n",
      "train loss:0.10580571650194794\n",
      "train loss:0.028466551058551715\n",
      "train loss:0.050067727608518124\n",
      "train loss:0.026958282959462582\n",
      "train loss:0.07880884024395451\n",
      "train loss:0.034790478869838756\n",
      "train loss:0.04235334724900947\n",
      "train loss:0.10581279586299913\n",
      "train loss:0.012951497398162072\n",
      "train loss:0.009295749589979148\n",
      "train loss:0.02873531869837937\n",
      "train loss:0.051960450289881575\n",
      "train loss:0.05642934148875277\n",
      "train loss:0.04826068276134596\n",
      "train loss:0.04422797449551023\n",
      "train loss:0.0541413239319047\n",
      "train loss:0.11433904566406641\n",
      "train loss:0.06686851378009646\n",
      "train loss:0.04274894224027486\n",
      "train loss:0.10178262381391963\n",
      "train loss:0.09619525828167083\n",
      "train loss:0.02560106314215119\n",
      "train loss:0.02749663487261843\n",
      "train loss:0.07551947365274538\n",
      "train loss:0.00614549452001611\n",
      "train loss:0.12263655531869963\n",
      "train loss:0.015558067131382523\n",
      "train loss:0.06557795858487662\n",
      "train loss:0.029827076972126734\n",
      "train loss:0.020561557928077442\n",
      "train loss:0.04195738357213382\n",
      "train loss:0.02967474449043929\n",
      "train loss:0.014957695837767383\n",
      "train loss:0.03930525592396774\n",
      "train loss:0.05336503381645346\n",
      "train loss:0.016567142822913605\n",
      "train loss:0.007089503330178424\n",
      "train loss:0.04765305478053922\n",
      "train loss:0.03569962567160782\n",
      "train loss:0.055763964810811376\n",
      "train loss:0.06069966408525443\n",
      "train loss:0.020991260143198645\n",
      "train loss:0.017798819848425254\n",
      "train loss:0.040278273504451\n",
      "train loss:0.03812897952696642\n",
      "train loss:0.051616011210552426\n",
      "train loss:0.12071302681586539\n",
      "train loss:0.011815593679761234\n",
      "train loss:0.060758477954616356\n",
      "train loss:0.018441657408895543\n",
      "train loss:0.03024437004959457\n",
      "train loss:0.024119387395834323\n",
      "train loss:0.06920710491207617\n",
      "train loss:0.10469310746251871\n",
      "train loss:0.06884587805010864\n",
      "train loss:0.05474484550243897\n",
      "train loss:0.011424548361002252\n",
      "train loss:0.016610663197141228\n",
      "train loss:0.037174783113242654\n",
      "train loss:0.027268851535744997\n",
      "train loss:0.05198419415154802\n",
      "train loss:0.051295132319285085\n",
      "train loss:0.03941561933346026\n",
      "train loss:0.04721111569090415\n",
      "train loss:0.09909005099892143\n",
      "train loss:0.03952981469444251\n",
      "train loss:0.017981378420465367\n",
      "train loss:0.07923911455635455\n",
      "train loss:0.020384427194432727\n",
      "train loss:0.025185176830197418\n",
      "train loss:0.05709047989625327\n",
      "train loss:0.029083456168458092\n",
      "train loss:0.014527661310774858\n",
      "train loss:0.033588200063300745\n",
      "train loss:0.02757034148340201\n",
      "train loss:0.05522559001400313\n",
      "train loss:0.036321749211694294\n",
      "train loss:0.07624033779131571\n",
      "train loss:0.013153413237851014\n",
      "train loss:0.03235998516632782\n",
      "train loss:0.10601068183283928\n",
      "train loss:0.05217031379072705\n",
      "train loss:0.0324206948432693\n",
      "train loss:0.03782482869804654\n",
      "train loss:0.05313026071057715\n",
      "train loss:0.05729319576641918\n",
      "train loss:0.05087534026557096\n",
      "train loss:0.014845393151341469\n",
      "train loss:0.030331411896231005\n",
      "train loss:0.07405957392366261\n",
      "train loss:0.03507719864621302\n",
      "train loss:0.026175799366386893\n",
      "train loss:0.030380742899176045\n",
      "train loss:0.1117175559565247\n",
      "train loss:0.04818106402966667\n",
      "train loss:0.01594790624196586\n",
      "train loss:0.051278903037859626\n",
      "train loss:0.023563331930336752\n",
      "train loss:0.05982222934861383\n",
      "train loss:0.054983708950104904\n",
      "train loss:0.04318082290274061\n",
      "train loss:0.01604241059410859\n",
      "train loss:0.046341960932410234\n",
      "train loss:0.02719692159012079\n",
      "train loss:0.10017893535122296\n",
      "train loss:0.015155983775400854\n",
      "train loss:0.03405851818367723\n",
      "train loss:0.025171207519120286\n",
      "train loss:0.01685730683478124\n",
      "train loss:0.01908022907111685\n",
      "train loss:0.04100912670897051\n",
      "train loss:0.13005727008148413\n",
      "train loss:0.0832572116523693\n",
      "train loss:0.03603332858695878\n",
      "train loss:0.022709851815064696\n",
      "train loss:0.14364798627193318\n",
      "train loss:0.05367949496513138\n",
      "train loss:0.06236647585601835\n",
      "train loss:0.07186167629495192\n",
      "train loss:0.019613277825267294\n",
      "train loss:0.05790879877532577\n",
      "train loss:0.03847052204861358\n",
      "train loss:0.14241976592697106\n",
      "train loss:0.06466141693513192\n",
      "train loss:0.0240484799143365\n",
      "train loss:0.06384827381465555\n",
      "train loss:0.009019558036476413\n",
      "train loss:0.010909815654295862\n",
      "train loss:0.07241679601752295\n",
      "train loss:0.04352791014491419\n",
      "train loss:0.043091002009009303\n",
      "train loss:0.09436225392162256\n",
      "train loss:0.06933429047010571\n",
      "train loss:0.02078636879337052\n",
      "train loss:0.01648392145180377\n",
      "train loss:0.0402437855528037\n",
      "train loss:0.04245457883297897\n",
      "train loss:0.03475197567840714\n",
      "train loss:0.011753280640499651\n",
      "train loss:0.0314171051932065\n",
      "train loss:0.01954000793805454\n",
      "train loss:0.03779606523477559\n",
      "train loss:0.007243591617612677\n",
      "train loss:0.027274075204611413\n",
      "train loss:0.060419637661949084\n",
      "train loss:0.028823068698513\n",
      "train loss:0.018672633928522853\n",
      "=== epoch:19, train acc:0.98, test acc:0.967 ===, time:  356.9306790828705\n",
      "train loss:0.010411488717042379\n",
      "train loss:0.00836157283010057\n",
      "train loss:0.07155909304791756\n",
      "train loss:0.07682503157057716\n",
      "train loss:0.02517861332562548\n",
      "train loss:0.010276765840049433\n",
      "train loss:0.035845652899724474\n",
      "train loss:0.01859763987763098\n",
      "train loss:0.0591541179087976\n",
      "train loss:0.05693165929625933\n",
      "train loss:0.015464660315098742\n",
      "train loss:0.1080600945323883\n",
      "train loss:0.022342989661452796\n",
      "train loss:0.04542068137631783\n",
      "train loss:0.029108284844983703\n",
      "train loss:0.06796537068139225\n",
      "train loss:0.03942532841986008\n",
      "train loss:0.09013147439864193\n",
      "train loss:0.060690323166553144\n",
      "train loss:0.026931142462985957\n",
      "train loss:0.023750687277719895\n",
      "train loss:0.029860922597878935\n",
      "train loss:0.026860305015629943\n",
      "train loss:0.022331686784602508\n",
      "train loss:0.019082535936830333\n",
      "train loss:0.015818560443060636\n",
      "train loss:0.0674831026527852\n",
      "train loss:0.03535876154367377\n",
      "train loss:0.03134612514669738\n",
      "train loss:0.14424542249269312\n",
      "train loss:0.03452784035661034\n",
      "train loss:0.01420031386709387\n",
      "train loss:0.07791001155317334\n",
      "train loss:0.018202408648743555\n",
      "train loss:0.03986720870915183\n",
      "train loss:0.11891231144397878\n",
      "train loss:0.040615930525847395\n",
      "train loss:0.019833445783558497\n",
      "train loss:0.03193875007856532\n",
      "train loss:0.050203756142458845\n",
      "train loss:0.03411161832684921\n",
      "train loss:0.04714276658193805\n",
      "train loss:0.01649579952929752\n",
      "train loss:0.026882701576455514\n",
      "train loss:0.025179730040792932\n",
      "train loss:0.06054978972684974\n",
      "train loss:0.02740300841497691\n",
      "train loss:0.060195562513336506\n",
      "train loss:0.03651110827255437\n",
      "train loss:0.03727318829851606\n",
      "train loss:0.04330559066322476\n",
      "train loss:0.06973776674218417\n",
      "train loss:0.07564493976446302\n",
      "train loss:0.07816622658254657\n",
      "train loss:0.10595980264081392\n",
      "train loss:0.018900611769316657\n",
      "train loss:0.028071318134085664\n",
      "train loss:0.03535041942835683\n",
      "train loss:0.042783566346435375\n",
      "train loss:0.06578923007196442\n",
      "train loss:0.05830839383627376\n",
      "train loss:0.06514173648908264\n",
      "train loss:0.005881620509818969\n",
      "train loss:0.017446270995585364\n",
      "train loss:0.025933905220041666\n",
      "train loss:0.04566634837326285\n",
      "train loss:0.13362302302961385\n",
      "train loss:0.024541369022614886\n",
      "train loss:0.030536690075471388\n",
      "train loss:0.04747227226955331\n",
      "train loss:0.07829661827185846\n",
      "train loss:0.039511613842791476\n",
      "train loss:0.024962844262928222\n",
      "train loss:0.041683279344289996\n",
      "train loss:0.1461729838746107\n",
      "train loss:0.03459714639080397\n",
      "train loss:0.08540147269081079\n",
      "train loss:0.041669033205341044\n",
      "train loss:0.02492453774917372\n",
      "train loss:0.13057558825279403\n",
      "train loss:0.11771589559871004\n",
      "train loss:0.017096105573813306\n",
      "train loss:0.017748774613871497\n",
      "train loss:0.07946959774145401\n",
      "train loss:0.012478747366245012\n",
      "train loss:0.08458152269767417\n",
      "train loss:0.03900724153915821\n",
      "train loss:0.06881475139510969\n",
      "train loss:0.09368248633481668\n",
      "train loss:0.032825403329534056\n",
      "train loss:0.03351346185413171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02780790623583489\n",
      "train loss:0.015472381930845864\n",
      "train loss:0.07356877747621296\n",
      "train loss:0.06789237759296557\n",
      "train loss:0.030994041724551214\n",
      "train loss:0.005965020965041761\n",
      "train loss:0.12249824568440093\n",
      "train loss:0.045920858183032015\n",
      "train loss:0.04175906888311399\n",
      "train loss:0.016710109043494036\n",
      "train loss:0.03794541396696342\n",
      "train loss:0.021630228710367162\n",
      "train loss:0.02372017631369472\n",
      "train loss:0.039202441428413025\n",
      "train loss:0.03130435039729191\n",
      "train loss:0.05951551051406034\n",
      "train loss:0.04205380985164919\n",
      "train loss:0.02008848375770874\n",
      "train loss:0.021392832091527435\n",
      "train loss:0.08436006949624451\n",
      "train loss:0.05067880957215496\n",
      "train loss:0.02205863254859187\n",
      "train loss:0.01980670163084621\n",
      "train loss:0.017577760043542986\n",
      "train loss:0.037921538661356856\n",
      "train loss:0.06727908626986817\n",
      "train loss:0.0429375087465148\n",
      "train loss:0.017907592404217788\n",
      "train loss:0.03746436676626816\n",
      "train loss:0.04052034381328075\n",
      "train loss:0.029792505912063266\n",
      "train loss:0.02200673892313275\n",
      "train loss:0.026893045019526596\n",
      "train loss:0.01612468531149536\n",
      "train loss:0.11076589073940099\n",
      "train loss:0.039855136039166295\n",
      "train loss:0.060156892992113284\n",
      "train loss:0.018823422266563243\n",
      "train loss:0.023309018065920277\n",
      "train loss:0.01979020432720606\n",
      "train loss:0.07988177893786266\n",
      "train loss:0.05311925953149025\n",
      "train loss:0.019560759914761125\n",
      "train loss:0.029053035450560153\n",
      "train loss:0.11804935291873227\n",
      "train loss:0.1140312364179052\n",
      "train loss:0.10872515213147527\n",
      "train loss:0.022786397594856\n",
      "train loss:0.02181827409835423\n",
      "train loss:0.03406792130358658\n",
      "train loss:0.030415152559381417\n",
      "train loss:0.031708536308280875\n",
      "train loss:0.05864669884381765\n",
      "train loss:0.034971575573099975\n",
      "train loss:0.05848279166883181\n",
      "train loss:0.07900568873177344\n",
      "train loss:0.04423761796486756\n",
      "train loss:0.07485617340437224\n",
      "train loss:0.04833377608423545\n",
      "train loss:0.024658000024579775\n",
      "train loss:0.04424922789721962\n",
      "train loss:0.02726477911784166\n",
      "train loss:0.05617030060327757\n",
      "train loss:0.05631049177816742\n",
      "train loss:0.038937477260929186\n",
      "train loss:0.046426984861092875\n",
      "train loss:0.05429728385560415\n",
      "train loss:0.02727049213942976\n",
      "train loss:0.13181263505366003\n",
      "train loss:0.05402858665001746\n",
      "train loss:0.06265207315714363\n",
      "train loss:0.04003878742300871\n",
      "train loss:0.033042107226012696\n",
      "train loss:0.03363965023291367\n",
      "train loss:0.04234063718379717\n",
      "train loss:0.04859703654705334\n",
      "train loss:0.0620008386183136\n",
      "train loss:0.0634748433773773\n",
      "train loss:0.13292078258540396\n",
      "train loss:0.019529876576759232\n",
      "train loss:0.029453695290857156\n",
      "train loss:0.05317210818298507\n",
      "train loss:0.034929701131894676\n",
      "train loss:0.0244181720251644\n",
      "train loss:0.027627434197468187\n",
      "train loss:0.017208250957724408\n",
      "train loss:0.1280882599959274\n",
      "train loss:0.016386779953194614\n",
      "train loss:0.10161684053406515\n",
      "train loss:0.04916179873880413\n",
      "train loss:0.07353211554410818\n",
      "train loss:0.016267004399118778\n",
      "train loss:0.07049556575063043\n",
      "train loss:0.05725543399215944\n",
      "train loss:0.012537246778640578\n",
      "train loss:0.028402680298496623\n",
      "train loss:0.023293273615914076\n",
      "train loss:0.07654520105601358\n",
      "train loss:0.019048183384455516\n",
      "train loss:0.05545607467331978\n",
      "train loss:0.033338866411651694\n",
      "train loss:0.013243561120853025\n",
      "train loss:0.0708698389614122\n",
      "train loss:0.07809720109851934\n",
      "train loss:0.07046232873293726\n",
      "train loss:0.026247049417960824\n",
      "train loss:0.075217220025935\n",
      "train loss:0.020913847528988786\n",
      "train loss:0.1087404116372077\n",
      "train loss:0.05848523473823051\n",
      "train loss:0.04535689304016904\n",
      "train loss:0.01108056791929307\n",
      "train loss:0.05128021202305681\n",
      "train loss:0.03603887438805522\n",
      "train loss:0.02867577445135806\n",
      "train loss:0.02396659225953439\n",
      "train loss:0.02399350228795395\n",
      "train loss:0.023965904365698426\n",
      "train loss:0.02157590876430918\n",
      "train loss:0.04432061569008953\n",
      "train loss:0.017918193455736933\n",
      "train loss:0.025419917984523477\n",
      "train loss:0.03193398942204407\n",
      "train loss:0.025562942422315302\n",
      "train loss:0.019115380530308312\n",
      "train loss:0.08564797673266461\n",
      "train loss:0.05053471908591566\n",
      "train loss:0.029652252032061326\n",
      "train loss:0.03822337967924081\n",
      "train loss:0.03536546752317293\n",
      "train loss:0.02646132118953309\n",
      "train loss:0.05543321111748991\n",
      "train loss:0.055802231531997176\n",
      "train loss:0.039314251326808956\n",
      "train loss:0.08901682867404\n",
      "train loss:0.026668973522289554\n",
      "train loss:0.027917335588779433\n",
      "train loss:0.07129717066564413\n",
      "train loss:0.023636016020852905\n",
      "train loss:0.013621281975105306\n",
      "train loss:0.03663752045703283\n",
      "train loss:0.02414639171945447\n",
      "train loss:0.020108631533463456\n",
      "train loss:0.029751101292683088\n",
      "train loss:0.044041154146713814\n",
      "train loss:0.03737516706295017\n",
      "train loss:0.032739962425969736\n",
      "train loss:0.06483305330700338\n",
      "train loss:0.06165796711874874\n",
      "train loss:0.05787893054586902\n",
      "train loss:0.02017335394678394\n",
      "train loss:0.10320612586872309\n",
      "train loss:0.047347044827581196\n",
      "train loss:0.04571259191152698\n",
      "train loss:0.06942114603388784\n",
      "train loss:0.06109100351494013\n",
      "train loss:0.033493760332208106\n",
      "train loss:0.08020568959649217\n",
      "train loss:0.029796961850576512\n",
      "train loss:0.05511166282430268\n",
      "train loss:0.04275731032026038\n",
      "train loss:0.03860815744828361\n",
      "train loss:0.009220656261266554\n",
      "train loss:0.05730771275645676\n",
      "train loss:0.016455897718626128\n",
      "train loss:0.01544842527943872\n",
      "train loss:0.054555978201581194\n",
      "train loss:0.052405638210934115\n",
      "train loss:0.03841942668197019\n",
      "train loss:0.07144048276704304\n",
      "train loss:0.024410911759678217\n",
      "train loss:0.07188501295381226\n",
      "train loss:0.028317688385225557\n",
      "train loss:0.06984994838237546\n",
      "train loss:0.032105733697849706\n",
      "train loss:0.07549149639355869\n",
      "train loss:0.04752908265425126\n",
      "train loss:0.015831642987555315\n",
      "train loss:0.03099993956369538\n",
      "train loss:0.01656288992562856\n",
      "train loss:0.06451209177949938\n",
      "train loss:0.06664611591606376\n",
      "train loss:0.021709305457321165\n",
      "train loss:0.050744481104125994\n",
      "train loss:0.026761542182136923\n",
      "train loss:0.04213509591485864\n",
      "train loss:0.030119998176742966\n",
      "train loss:0.025189920258328013\n",
      "train loss:0.00922514142877972\n",
      "train loss:0.057190554615904256\n",
      "train loss:0.07426931845808948\n",
      "train loss:0.03335839337047348\n",
      "train loss:0.022534301865524534\n",
      "train loss:0.07729097920253078\n",
      "train loss:0.046557060747824314\n",
      "train loss:0.006248786850043597\n",
      "train loss:0.011460168466677446\n",
      "train loss:0.0695366574006665\n",
      "train loss:0.05214184700734334\n",
      "train loss:0.04094461352504261\n",
      "train loss:0.03853240785543438\n",
      "train loss:0.09854424993902527\n",
      "train loss:0.024182935896873595\n",
      "train loss:0.038679733897488536\n",
      "train loss:0.00950427141891286\n",
      "train loss:0.04645708361544974\n",
      "train loss:0.040685264612602634\n",
      "train loss:0.03963448881603121\n",
      "train loss:0.05281939562486766\n",
      "train loss:0.052569175986220885\n",
      "train loss:0.05108694795017354\n",
      "train loss:0.02690883296105603\n",
      "train loss:0.031094353353255003\n",
      "train loss:0.04029727813482152\n",
      "train loss:0.04835171177021388\n",
      "train loss:0.03915297142843663\n",
      "train loss:0.042916112537547804\n",
      "train loss:0.044351131333573414\n",
      "train loss:0.110015467395223\n",
      "train loss:0.02980272946449595\n",
      "train loss:0.05568927343830472\n",
      "train loss:0.02284385567975754\n",
      "train loss:0.023001795468067847\n",
      "train loss:0.027359003957366523\n",
      "train loss:0.10004255656142433\n",
      "train loss:0.10737014475558723\n",
      "train loss:0.026747630980837468\n",
      "train loss:0.07128224228992358\n",
      "train loss:0.008282632398016512\n",
      "train loss:0.03363302869045744\n",
      "train loss:0.04582771395817678\n",
      "train loss:0.06223062982058365\n",
      "train loss:0.06273580127740913\n",
      "train loss:0.057674030031508894\n",
      "train loss:0.030266269581892383\n",
      "train loss:0.029980529958303095\n",
      "train loss:0.0958202198978819\n",
      "train loss:0.040492259568823935\n",
      "train loss:0.04461738769498891\n",
      "train loss:0.012550232254301347\n",
      "train loss:0.02695277644710502\n",
      "train loss:0.05185235941974861\n",
      "train loss:0.05381883175456345\n",
      "train loss:0.028045654431497598\n",
      "train loss:0.032956877711709714\n",
      "train loss:0.018075289321853132\n",
      "train loss:0.08273166951779264\n",
      "train loss:0.049551496267190354\n",
      "train loss:0.008732703735241628\n",
      "train loss:0.0789671555904411\n",
      "train loss:0.016906127067618668\n",
      "train loss:0.013692077078076468\n",
      "train loss:0.03486597902703599\n",
      "train loss:0.046651390670290914\n",
      "train loss:0.028706906014274832\n",
      "train loss:0.028874813828665746\n",
      "train loss:0.034026757485069004\n",
      "train loss:0.035769109080024904\n",
      "train loss:0.01652809787485318\n",
      "train loss:0.035274470722646015\n",
      "train loss:0.04537911516904418\n",
      "train loss:0.007584309326089469\n",
      "train loss:0.01604558616503348\n",
      "train loss:0.05633376641855469\n",
      "train loss:0.0674746117249259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04603852085337677\n",
      "train loss:0.01587507089622991\n",
      "train loss:0.038232129733959154\n",
      "train loss:0.02264718275005287\n",
      "train loss:0.03827632965207514\n",
      "train loss:0.02418887304953705\n",
      "train loss:0.059948476338157385\n",
      "train loss:0.06304658189029715\n",
      "train loss:0.027885002099104203\n",
      "train loss:0.07110389458266514\n",
      "train loss:0.054274497287033895\n",
      "train loss:0.035208551692973676\n",
      "train loss:0.022741673661541242\n",
      "train loss:0.11858665804506323\n",
      "train loss:0.018478916921517274\n",
      "train loss:0.06681918445309995\n",
      "train loss:0.03883093509129686\n",
      "train loss:0.03374677788224208\n",
      "train loss:0.03887107255317185\n",
      "train loss:0.045050161621382825\n",
      "train loss:0.04527828508046127\n",
      "train loss:0.06602677172929186\n",
      "train loss:0.026043908714551627\n",
      "train loss:0.0435575345072188\n",
      "train loss:0.01823828451534057\n",
      "train loss:0.06539550626633708\n",
      "train loss:0.0678950129913287\n",
      "train loss:0.061373967454584594\n",
      "train loss:0.01212430774485881\n",
      "train loss:0.011859493248106931\n",
      "train loss:0.013278133313537593\n",
      "train loss:0.012558262993435664\n",
      "train loss:0.027816150789893978\n",
      "train loss:0.054024717756379806\n",
      "train loss:0.052666904258840165\n",
      "train loss:0.015641243868836318\n",
      "train loss:0.06200541559938153\n",
      "train loss:0.0820258599804766\n",
      "train loss:0.037840297327465175\n",
      "train loss:0.039663516612760706\n",
      "train loss:0.05975079368338172\n",
      "train loss:0.04590426124594599\n",
      "train loss:0.06194138952323222\n",
      "train loss:0.03427272418696819\n",
      "train loss:0.11597390573327435\n",
      "train loss:0.015784630862809245\n",
      "train loss:0.06459675177491377\n",
      "train loss:0.06766689767179253\n",
      "train loss:0.050616827798468836\n",
      "train loss:0.02817872570755084\n",
      "train loss:0.018144440821285274\n",
      "train loss:0.051134399378649026\n",
      "train loss:0.052568368633573004\n",
      "train loss:0.05435077987699468\n",
      "train loss:0.039624896596252235\n",
      "train loss:0.027087424782690096\n",
      "train loss:0.05284275790570734\n",
      "train loss:0.031246463859263815\n",
      "train loss:0.01615136135053427\n",
      "train loss:0.19121158589319134\n",
      "train loss:0.017619638993819357\n",
      "train loss:0.028730295901791582\n",
      "train loss:0.027556957433465014\n",
      "train loss:0.09803401315397797\n",
      "train loss:0.024027990746221754\n",
      "train loss:0.04537432793548437\n",
      "train loss:0.014510101172227431\n",
      "train loss:0.16232337175123976\n",
      "train loss:0.03346825844977547\n",
      "train loss:0.03866724597184445\n",
      "train loss:0.023019979715245067\n",
      "train loss:0.021769403888154605\n",
      "train loss:0.06769963761637825\n",
      "train loss:0.02539364877632123\n",
      "train loss:0.04049485644640206\n",
      "train loss:0.03701579225894496\n",
      "train loss:0.049026926811754724\n",
      "train loss:0.060832706827570276\n",
      "train loss:0.00891265215257055\n",
      "train loss:0.02878222427953343\n",
      "train loss:0.021320184775223013\n",
      "train loss:0.0310136386811851\n",
      "train loss:0.021437479627788827\n",
      "train loss:0.03409765731627136\n",
      "train loss:0.01835353046017555\n",
      "train loss:0.043486525396031823\n",
      "train loss:0.04648600110352965\n",
      "train loss:0.0315060224258126\n",
      "train loss:0.03799899956602982\n",
      "train loss:0.02751105269634417\n",
      "train loss:0.06119367529165743\n",
      "train loss:0.021874915137624268\n",
      "train loss:0.026129575225748883\n",
      "train loss:0.059498132634567096\n",
      "train loss:0.017163689252065115\n",
      "train loss:0.018913469969979918\n",
      "train loss:0.04354465895200366\n",
      "train loss:0.05923089861589499\n",
      "train loss:0.07810063604324154\n",
      "train loss:0.00797156607594364\n",
      "train loss:0.0294767573521889\n",
      "train loss:0.02628953484782708\n",
      "train loss:0.03201649696780155\n",
      "train loss:0.08864769723141494\n",
      "train loss:0.018247850617572826\n",
      "train loss:0.014542475064515205\n",
      "train loss:0.006650735077116847\n",
      "train loss:0.07412633005905604\n",
      "train loss:0.03587142539259205\n",
      "train loss:0.03962315474027882\n",
      "train loss:0.024100699300425635\n",
      "train loss:0.0505617385673736\n",
      "train loss:0.02527446750374884\n",
      "train loss:0.040624442813686\n",
      "train loss:0.03246421074057021\n",
      "train loss:0.042973255376388735\n",
      "train loss:0.043656235862122805\n",
      "train loss:0.12482016326511566\n",
      "train loss:0.043175842764002034\n",
      "train loss:0.016915655920556952\n",
      "train loss:0.011783000162322184\n",
      "train loss:0.01913919567677061\n",
      "train loss:0.01740697606237642\n",
      "train loss:0.014873199882453165\n",
      "train loss:0.11287854453461846\n",
      "train loss:0.01823834428960979\n",
      "train loss:0.06695395533918866\n",
      "train loss:0.05328292140771503\n",
      "train loss:0.07288184553230131\n",
      "train loss:0.09184316038382148\n",
      "train loss:0.04683315079919995\n",
      "train loss:0.0879314321711704\n",
      "train loss:0.012569794524651751\n",
      "train loss:0.028900955720852703\n",
      "train loss:0.03199694848702034\n",
      "train loss:0.04473778748824672\n",
      "train loss:0.047986483750972635\n",
      "train loss:0.1257190418420437\n",
      "train loss:0.016189901875182072\n",
      "train loss:0.016237653022845362\n",
      "train loss:0.06607130761336759\n",
      "train loss:0.03563118175036259\n",
      "train loss:0.06862800256587963\n",
      "train loss:0.08105173634192736\n",
      "train loss:0.058036824610517665\n",
      "train loss:0.018081925491705727\n",
      "train loss:0.04182721287944056\n",
      "train loss:0.10699062611648616\n",
      "train loss:0.0349226364793153\n",
      "train loss:0.06100177921624088\n",
      "train loss:0.031917539842032196\n",
      "train loss:0.03629833499981872\n",
      "train loss:0.030146019893023582\n",
      "train loss:0.05404815231491167\n",
      "train loss:0.035336779657298284\n",
      "train loss:0.07113061185831963\n",
      "train loss:0.03984327973324826\n",
      "train loss:0.030118067524482123\n",
      "train loss:0.03318115356777321\n",
      "train loss:0.012726375011566982\n",
      "train loss:0.04551862020721495\n",
      "train loss:0.040459949918291035\n",
      "train loss:0.051146895866276326\n",
      "train loss:0.08112666322694924\n",
      "train loss:0.14165000913507822\n",
      "train loss:0.028920948271694277\n",
      "train loss:0.03696129994269842\n",
      "train loss:0.05569871713052575\n",
      "train loss:0.0597408490876298\n",
      "train loss:0.10582108053211073\n",
      "train loss:0.022613041758410404\n",
      "train loss:0.03216161781742429\n",
      "train loss:0.055117272819532125\n",
      "train loss:0.014136402915870571\n",
      "train loss:0.07508677266945885\n",
      "train loss:0.0403190059815169\n",
      "train loss:0.03461542600751998\n",
      "train loss:0.020435421939471007\n",
      "train loss:0.03527682958741102\n",
      "train loss:0.029216423700895597\n",
      "train loss:0.061412477885495316\n",
      "train loss:0.08143683444363624\n",
      "train loss:0.07427344386647143\n",
      "train loss:0.04642254633629423\n",
      "train loss:0.03512334012297563\n",
      "train loss:0.01370704986857392\n",
      "train loss:0.04504230604983526\n",
      "train loss:0.03175711660202342\n",
      "train loss:0.06681046213113913\n",
      "train loss:0.03680191721820215\n",
      "train loss:0.07478919606931632\n",
      "train loss:0.04188532185715513\n",
      "train loss:0.0661624589025798\n",
      "train loss:0.028866743566344413\n",
      "train loss:0.037348245205730816\n",
      "train loss:0.053163232583725906\n",
      "train loss:0.05973866059611332\n",
      "train loss:0.053293937578029936\n",
      "train loss:0.03862353560777393\n",
      "train loss:0.023014526100724145\n",
      "train loss:0.022219906786201036\n",
      "train loss:0.013418745484190508\n",
      "train loss:0.03316826707638867\n",
      "train loss:0.04233067190093656\n",
      "train loss:0.0674150835939605\n",
      "train loss:0.04964288186086237\n",
      "train loss:0.03149107097740823\n",
      "train loss:0.1461167929328481\n",
      "train loss:0.025990179921371617\n",
      "train loss:0.10124422455614612\n",
      "train loss:0.028829776514174385\n",
      "train loss:0.006452499524920264\n",
      "train loss:0.023261332109264878\n",
      "train loss:0.07707984165885964\n",
      "train loss:0.042209117919314795\n",
      "train loss:0.03156372185224937\n",
      "train loss:0.062288185763558886\n",
      "train loss:0.04627801556723497\n",
      "train loss:0.021688444954651564\n",
      "train loss:0.08635172262767546\n",
      "train loss:0.05585312062103816\n",
      "train loss:0.08310958292727641\n",
      "train loss:0.035456776127277996\n",
      "train loss:0.018803424913741013\n",
      "train loss:0.020457701591755174\n",
      "train loss:0.042078497172003286\n",
      "train loss:0.04753294897754925\n",
      "train loss:0.053025564911963\n",
      "train loss:0.04200128509426276\n",
      "train loss:0.035048628229072794\n",
      "train loss:0.08067385769256046\n",
      "train loss:0.03916402788020324\n",
      "train loss:0.05597731709378259\n",
      "train loss:0.07373307705438864\n",
      "train loss:0.025182227603569064\n",
      "train loss:0.04863236839556847\n",
      "train loss:0.05431440480359681\n",
      "train loss:0.023204380203543973\n",
      "train loss:0.015257379850709447\n",
      "train loss:0.016000117067847767\n",
      "train loss:0.01137622469720786\n",
      "train loss:0.02226892417184345\n",
      "train loss:0.0649620688298272\n",
      "train loss:0.017674859285493304\n",
      "=== epoch:20, train acc:0.98, test acc:0.965 ===, time:  377.83561062812805\n",
      "train loss:0.08624210892497414\n",
      "train loss:0.027526759697429647\n",
      "train loss:0.028498334744420796\n",
      "train loss:0.04305655315398187\n",
      "train loss:0.022608266573175433\n",
      "train loss:0.03312735650884965\n",
      "train loss:0.02635021171343416\n",
      "train loss:0.03388899942264464\n",
      "train loss:0.040260608286459165\n",
      "train loss:0.007950189339415046\n",
      "train loss:0.027973131022307817\n",
      "train loss:0.02532835432921844\n",
      "train loss:0.04257059640906235\n",
      "train loss:0.04174673781845255\n",
      "train loss:0.046193806104858126\n",
      "train loss:0.03953593778516649\n",
      "train loss:0.034397503231046865\n",
      "train loss:0.05183743076525362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.050481085180637104\n",
      "train loss:0.04489707599940057\n",
      "train loss:0.025797270394063793\n",
      "train loss:0.029199888923109495\n",
      "train loss:0.018831232697763208\n",
      "train loss:0.06446494013178689\n",
      "train loss:0.1660480902999975\n",
      "train loss:0.0626822661394445\n",
      "train loss:0.009961273921665603\n",
      "train loss:0.029124853927654386\n",
      "train loss:0.004127510730937259\n",
      "train loss:0.026810606572210266\n",
      "train loss:0.03224488430864156\n",
      "train loss:0.04710747296332502\n",
      "train loss:0.0184132881146246\n",
      "train loss:0.023157530595497047\n",
      "train loss:0.060144456517792516\n",
      "train loss:0.04895916902685458\n",
      "train loss:0.03186133843502842\n",
      "train loss:0.05295850303525355\n",
      "train loss:0.09912375679057062\n",
      "train loss:0.04721199617219517\n",
      "train loss:0.04817849874631672\n",
      "train loss:0.01597925543469969\n",
      "train loss:0.03378745856362706\n",
      "train loss:0.10789038037224138\n",
      "train loss:0.039625796311035105\n",
      "train loss:0.04195847675468043\n",
      "train loss:0.04216511353886398\n",
      "train loss:0.023087728612345818\n",
      "train loss:0.018574296213150307\n",
      "train loss:0.015736748320791395\n",
      "train loss:0.04541389234854584\n",
      "train loss:0.04838391486801635\n",
      "train loss:0.05342170943489109\n",
      "train loss:0.14512249422668116\n",
      "train loss:0.01805675964963397\n",
      "train loss:0.05624938393937286\n",
      "train loss:0.12299670762606095\n",
      "train loss:0.03010986460003064\n",
      "train loss:0.028658264240174897\n",
      "train loss:0.0310475135503461\n",
      "train loss:0.019045148258561965\n",
      "train loss:0.039739516613071874\n",
      "train loss:0.033606328572575575\n",
      "train loss:0.05226139980843228\n",
      "train loss:0.03825792876525847\n",
      "train loss:0.05284701701879567\n",
      "train loss:0.048356556495910266\n",
      "train loss:0.06728357769789986\n",
      "train loss:0.05002920531797279\n",
      "train loss:0.015487127533804766\n",
      "train loss:0.03157465947445069\n",
      "train loss:0.05440336440587648\n",
      "train loss:0.09295259200715725\n",
      "train loss:0.011260233057830006\n",
      "train loss:0.08862363534420814\n",
      "train loss:0.05375316734765427\n",
      "train loss:0.10990027622037946\n",
      "train loss:0.10400937776136807\n",
      "train loss:0.020769818766313147\n",
      "train loss:0.02669871048964837\n",
      "train loss:0.05712925446758723\n",
      "train loss:0.053484627835010616\n",
      "train loss:0.01856508416911477\n",
      "train loss:0.0527924973052769\n",
      "train loss:0.024311450927747766\n",
      "train loss:0.10269322751547322\n",
      "train loss:0.0480563645666732\n",
      "train loss:0.030337400494451053\n",
      "train loss:0.09813451132845057\n",
      "train loss:0.06420329676353914\n",
      "train loss:0.01831772660755299\n",
      "train loss:0.046922338083943055\n",
      "train loss:0.05407396955266761\n",
      "train loss:0.04100669540894075\n",
      "train loss:0.07043707207605167\n",
      "train loss:0.029442761107379787\n",
      "train loss:0.10103217778784744\n",
      "train loss:0.027039473787252466\n",
      "train loss:0.0675908525140743\n",
      "train loss:0.032030258160924356\n",
      "train loss:0.02005464545003777\n",
      "train loss:0.011452540285803274\n",
      "train loss:0.08032684180175399\n",
      "train loss:0.11406583475253187\n",
      "train loss:0.05307023083561003\n",
      "train loss:0.03531978073548888\n",
      "train loss:0.025738600526674045\n",
      "train loss:0.054278304723185906\n",
      "train loss:0.05494934194410894\n",
      "train loss:0.055640393103601735\n",
      "train loss:0.020176094814132385\n",
      "train loss:0.011944672726480962\n",
      "train loss:0.06277701831919391\n",
      "train loss:0.025531805916363535\n",
      "train loss:0.024550490472891023\n",
      "train loss:0.029196812413188236\n",
      "train loss:0.10234971065443409\n",
      "train loss:0.04308245936509527\n",
      "train loss:0.040293797800997726\n",
      "train loss:0.03723589925420773\n",
      "train loss:0.012975061105672994\n",
      "train loss:0.02432107200532331\n",
      "train loss:0.0955076545157401\n",
      "train loss:0.027614001661661402\n",
      "train loss:0.04395926295753279\n",
      "train loss:0.03203509532195632\n",
      "train loss:0.020965726998970844\n",
      "train loss:0.03185349501156455\n",
      "train loss:0.030419474390746336\n",
      "train loss:0.06774449006454028\n",
      "train loss:0.013462963671461674\n",
      "train loss:0.06529365974650625\n",
      "train loss:0.027435507658968086\n",
      "train loss:0.04405376569859265\n",
      "train loss:0.01909532587599443\n",
      "train loss:0.030771980391717673\n",
      "train loss:0.014476650179691268\n",
      "train loss:0.019431937454263103\n",
      "train loss:0.05332851801445995\n",
      "train loss:0.038193587050845294\n",
      "train loss:0.021879644992049335\n",
      "train loss:0.022980708786349627\n",
      "train loss:0.043048235174831646\n",
      "train loss:0.024562858239672726\n",
      "train loss:0.07476944520493886\n",
      "train loss:0.02521830339055341\n",
      "train loss:0.027905592032934554\n",
      "train loss:0.02288539966542535\n",
      "train loss:0.03482277903365406\n",
      "train loss:0.012359690121228437\n",
      "train loss:0.02082734484700093\n",
      "train loss:0.06606017726693791\n",
      "train loss:0.013324998390432314\n",
      "train loss:0.02831589908236823\n",
      "train loss:0.04278723072905307\n",
      "train loss:0.0201131482976714\n",
      "train loss:0.019365305878555738\n",
      "train loss:0.050318733579908105\n",
      "train loss:0.054510643859526045\n",
      "train loss:0.04689728921133949\n",
      "train loss:0.03971633670601368\n",
      "train loss:0.048897337956531686\n",
      "train loss:0.08080230482031547\n",
      "train loss:0.04467538102419601\n",
      "train loss:0.022945472640175487\n",
      "train loss:0.061437713360816486\n",
      "train loss:0.014062364136656715\n",
      "train loss:0.04004603870640639\n",
      "train loss:0.051699772511912184\n",
      "train loss:0.03360472586167082\n",
      "train loss:0.012604728673704917\n",
      "train loss:0.014754660588069091\n",
      "train loss:0.12143066502966773\n",
      "train loss:0.022207880058694122\n",
      "train loss:0.042669700207602836\n",
      "train loss:0.019186051581421056\n",
      "train loss:0.01887752914992847\n",
      "train loss:0.013080802467955146\n",
      "train loss:0.025192079188192586\n",
      "train loss:0.02962187907519771\n",
      "train loss:0.06116652440191367\n",
      "train loss:0.03932642330230232\n",
      "train loss:0.010627207564027812\n",
      "train loss:0.0503155316613316\n",
      "train loss:0.02073688588579111\n",
      "train loss:0.015772795095423578\n",
      "train loss:0.02074393291997637\n",
      "train loss:0.02904190855401991\n",
      "train loss:0.04255955285104841\n",
      "train loss:0.0358252512780028\n",
      "train loss:0.024156465391114715\n",
      "train loss:0.06957141054824519\n",
      "train loss:0.01247262780564056\n",
      "train loss:0.014326969807890968\n",
      "train loss:0.022146300420183885\n",
      "train loss:0.19943615714251428\n",
      "train loss:0.06712732437480312\n",
      "train loss:0.028522890144612047\n",
      "train loss:0.11278018569611672\n",
      "train loss:0.026381097243464505\n",
      "train loss:0.009313499694284279\n",
      "train loss:0.024708196900289275\n",
      "train loss:0.058978655860869866\n",
      "train loss:0.04411317805993515\n",
      "train loss:0.03894816394094884\n",
      "train loss:0.006951360469679845\n",
      "train loss:0.025101450315588858\n",
      "train loss:0.018245602129696156\n",
      "train loss:0.012144851432110354\n",
      "train loss:0.011338680537590124\n",
      "train loss:0.017239418026699913\n",
      "train loss:0.024036268091050982\n",
      "train loss:0.05385139474154672\n",
      "train loss:0.05669141214427181\n",
      "train loss:0.12272957968852614\n",
      "train loss:0.013603308437909592\n",
      "train loss:0.02211188021377586\n",
      "train loss:0.04008582129811028\n",
      "train loss:0.021947410641140346\n",
      "train loss:0.03878183714360663\n",
      "train loss:0.02736715214312476\n",
      "train loss:0.05058934383454721\n",
      "train loss:0.10368295608165848\n",
      "train loss:0.0784957919675472\n",
      "train loss:0.010675432005018881\n",
      "train loss:0.04280848123952107\n",
      "train loss:0.021355995042894586\n",
      "train loss:0.05893124469526906\n",
      "train loss:0.011211269741265508\n",
      "train loss:0.043059699272470595\n",
      "train loss:0.025373161064398703\n",
      "train loss:0.08115191935925103\n",
      "train loss:0.024020766970554573\n",
      "train loss:0.010882525941156915\n",
      "train loss:0.061449171722372714\n",
      "train loss:0.2056723949947516\n",
      "train loss:0.03497785344174202\n",
      "train loss:0.037668883639686665\n",
      "train loss:0.045397146228503\n",
      "train loss:0.10537397730012688\n",
      "train loss:0.041464454500742064\n",
      "train loss:0.06418803567700315\n",
      "train loss:0.14491627617333186\n",
      "train loss:0.11122736185706986\n",
      "train loss:0.037457592789686696\n",
      "train loss:0.04443593541115833\n",
      "train loss:0.05398169617260831\n",
      "train loss:0.04203189676506511\n",
      "train loss:0.07082298065301307\n",
      "train loss:0.02524247855653903\n",
      "train loss:0.022403079365322872\n",
      "train loss:0.0306997530308454\n",
      "train loss:0.03380409524814051\n",
      "train loss:0.012015999551989337\n",
      "train loss:0.04030537946083878\n",
      "train loss:0.055033854423107195\n",
      "train loss:0.07981641105883718\n",
      "train loss:0.03643172788782453\n",
      "train loss:0.01600973636554621\n",
      "train loss:0.05502939410755066\n",
      "train loss:0.03952615807920795\n",
      "train loss:0.08054861847804479\n",
      "train loss:0.03072339315307476\n",
      "train loss:0.07509509173112316\n",
      "train loss:0.02330314421338279\n",
      "train loss:0.09560007107732128\n",
      "train loss:0.03254343389588286\n",
      "train loss:0.022206152714528127\n",
      "train loss:0.04414905006871118\n",
      "train loss:0.08268876133806315\n",
      "train loss:0.026907169694789682\n",
      "train loss:0.018421163738970046\n",
      "train loss:0.061102163000323895\n",
      "train loss:0.03308851652611559\n",
      "train loss:0.02097596050137474\n",
      "train loss:0.04667638766911034\n",
      "train loss:0.07750277460065927\n",
      "train loss:0.04026411907472439\n",
      "train loss:0.017116761735004843\n",
      "train loss:0.04674803982976156\n",
      "train loss:0.03400044861792137\n",
      "train loss:0.05331179182333516\n",
      "train loss:0.0348556895678553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03879449320699119\n",
      "train loss:0.04709273182529072\n",
      "train loss:0.047966401670072836\n",
      "train loss:0.021424879078141196\n",
      "train loss:0.11244371923466416\n",
      "train loss:0.04568760361445187\n",
      "train loss:0.068077844884806\n",
      "train loss:0.027453462177340442\n",
      "train loss:0.06409957288898795\n",
      "train loss:0.016776474421500168\n",
      "train loss:0.03512717064763027\n",
      "train loss:0.018740299543207817\n",
      "train loss:0.028770476354797445\n",
      "train loss:0.017314935991048833\n",
      "train loss:0.018952949538793257\n",
      "train loss:0.03599547696879568\n",
      "train loss:0.011831742748460146\n",
      "train loss:0.024427973419256302\n",
      "train loss:0.03950297806511608\n",
      "train loss:0.036356884403308\n",
      "train loss:0.018703866548825568\n",
      "train loss:0.03008981649673885\n",
      "train loss:0.06788679965388486\n",
      "train loss:0.03603475069886358\n",
      "train loss:0.07327266701146545\n",
      "train loss:0.02362005986975533\n",
      "train loss:0.02214078569390157\n",
      "train loss:0.062249452396296104\n",
      "train loss:0.08454429578348562\n",
      "train loss:0.046475879060627834\n",
      "train loss:0.04407431235578402\n",
      "train loss:0.03243135573909515\n",
      "train loss:0.032819535448434106\n",
      "train loss:0.09677890920187174\n",
      "train loss:0.03026707895961324\n",
      "train loss:0.08069618751065559\n",
      "train loss:0.0350245169989987\n",
      "train loss:0.02430411928784797\n",
      "train loss:0.04730815842495855\n",
      "train loss:0.030299342818107377\n",
      "train loss:0.08214352958499899\n",
      "train loss:0.03897907797565572\n",
      "train loss:0.030743389633159493\n",
      "train loss:0.02467139044053106\n",
      "train loss:0.06202358335982149\n",
      "train loss:0.03247000306619113\n",
      "train loss:0.03270082393968731\n",
      "train loss:0.013558941008862844\n",
      "train loss:0.013396251380420858\n",
      "train loss:0.008948441465768587\n",
      "train loss:0.02532380454128432\n",
      "train loss:0.00655784780185847\n",
      "train loss:0.03850049013463561\n",
      "train loss:0.046791628325526295\n",
      "train loss:0.02507280693960878\n",
      "train loss:0.010411237258191758\n",
      "train loss:0.02177411065935207\n",
      "train loss:0.021853858964315687\n",
      "train loss:0.041508567858561614\n",
      "train loss:0.01707553448770941\n",
      "train loss:0.023832787070886704\n",
      "train loss:0.03755292634264195\n",
      "train loss:0.027874050487832355\n",
      "train loss:0.015775303924758333\n",
      "train loss:0.013655602048343518\n",
      "train loss:0.011662418138797662\n",
      "train loss:0.022984096594254436\n",
      "train loss:0.013193669872289926\n",
      "train loss:0.045977400152646446\n",
      "train loss:0.025385189578537592\n",
      "train loss:0.09679081451891283\n",
      "train loss:0.05126886268555255\n",
      "train loss:0.009997885518114882\n",
      "train loss:0.03633009324868172\n",
      "train loss:0.04479628951960104\n",
      "train loss:0.024818421672787\n",
      "train loss:0.04575848165882654\n",
      "train loss:0.11334485367318793\n",
      "train loss:0.04478142921782598\n",
      "train loss:0.030890685897980687\n",
      "train loss:0.0261195655789469\n",
      "train loss:0.03339351053603703\n",
      "train loss:0.050867676181649696\n",
      "train loss:0.015384775322176674\n",
      "train loss:0.07460812578580081\n",
      "train loss:0.021887655395826874\n",
      "train loss:0.022684646184530376\n",
      "train loss:0.03604833935549476\n",
      "train loss:0.010676124170575254\n",
      "train loss:0.021475590270999358\n",
      "train loss:0.05703890552270432\n",
      "train loss:0.02756217728597832\n",
      "train loss:0.03938647886328564\n",
      "train loss:0.03541589853295364\n",
      "train loss:0.017868316449376677\n",
      "train loss:0.046140676486500276\n",
      "train loss:0.11034738135736845\n",
      "train loss:0.014196606968114405\n",
      "train loss:0.013796340939797234\n",
      "train loss:0.015318215738928869\n",
      "train loss:0.019179951892696525\n",
      "train loss:0.012804693081436336\n",
      "train loss:0.07729171207872845\n",
      "train loss:0.011201423311584075\n",
      "train loss:0.03149943028754564\n",
      "train loss:0.025889868713203625\n",
      "train loss:0.028366045476193324\n",
      "train loss:0.005732726617948796\n",
      "train loss:0.037203801484902405\n",
      "train loss:0.023273576251997\n",
      "train loss:0.05821434237721222\n",
      "train loss:0.012008566242478085\n",
      "train loss:0.03428599841196692\n",
      "train loss:0.04377506085604432\n",
      "train loss:0.049274648411515604\n",
      "train loss:0.025466336153043997\n",
      "train loss:0.03186223682100421\n",
      "train loss:0.06856164447361145\n",
      "train loss:0.040496102530798384\n",
      "train loss:0.01730626232109405\n",
      "train loss:0.03748897478380099\n",
      "train loss:0.06506824136346016\n",
      "train loss:0.025310958908598982\n",
      "train loss:0.014682380548793226\n",
      "train loss:0.021021566157360585\n",
      "train loss:0.0460610448980528\n",
      "train loss:0.027886835065153246\n",
      "train loss:0.07715193852568576\n",
      "train loss:0.007978514315651785\n",
      "train loss:0.041807248078113854\n",
      "train loss:0.03882149329865172\n",
      "train loss:0.030496431602562813\n",
      "train loss:0.033310742532702074\n",
      "train loss:0.10226103165779465\n",
      "train loss:0.025319569425028297\n",
      "train loss:0.014412026934350189\n",
      "train loss:0.011593513664922773\n",
      "train loss:0.05721746907792841\n",
      "train loss:0.051743892900088545\n",
      "train loss:0.05201682982999628\n",
      "train loss:0.029917666667121222\n",
      "train loss:0.0501044404189664\n",
      "train loss:0.020497288958978795\n",
      "train loss:0.010581468290005462\n",
      "train loss:0.03163194843741412\n",
      "train loss:0.026375602354659407\n",
      "train loss:0.054636810553820456\n",
      "train loss:0.08900450852325464\n",
      "train loss:0.03349628145776328\n",
      "train loss:0.058852047976058114\n",
      "train loss:0.01658787119576518\n",
      "train loss:0.03524242876860419\n",
      "train loss:0.04697393087138397\n",
      "train loss:0.032545287743552136\n",
      "train loss:0.027293020682748727\n",
      "train loss:0.018008245559823822\n",
      "train loss:0.02476880466702819\n",
      "train loss:0.013681376411020804\n",
      "train loss:0.010084225273622054\n",
      "train loss:0.022642170435538223\n",
      "train loss:0.030140872145028294\n",
      "train loss:0.03806922344176779\n",
      "train loss:0.019636769054402738\n",
      "train loss:0.01785326895817464\n",
      "train loss:0.05568728844154037\n",
      "train loss:0.046236873474183406\n",
      "train loss:0.020989609232480135\n",
      "train loss:0.04997711985489264\n",
      "train loss:0.08906743884393886\n",
      "train loss:0.04344413407297729\n",
      "train loss:0.043684565608309335\n",
      "train loss:0.02217942818630825\n",
      "train loss:0.03198058690300853\n",
      "train loss:0.07402852596281177\n",
      "train loss:0.056012718111101006\n",
      "train loss:0.04543523906446577\n",
      "train loss:0.01699013268397811\n",
      "train loss:0.053332222283161486\n",
      "train loss:0.037130463076831724\n",
      "train loss:0.07005103339623889\n",
      "train loss:0.034823549994609765\n",
      "train loss:0.032311788002864834\n",
      "train loss:0.02280941208328269\n",
      "train loss:0.03001822551728767\n",
      "train loss:0.027069216074117625\n",
      "train loss:0.026067675521637957\n",
      "train loss:0.07729739793597791\n",
      "train loss:0.038505592636423065\n",
      "train loss:0.029420763079961068\n",
      "train loss:0.01756848506479724\n",
      "train loss:0.10110607292867689\n",
      "train loss:0.04271962447455449\n",
      "train loss:0.012881245027288721\n",
      "train loss:0.023970762555857675\n",
      "train loss:0.014081048821132045\n",
      "train loss:0.05100362530027791\n",
      "train loss:0.10636853143619547\n",
      "train loss:0.021718798386466762\n",
      "train loss:0.0426558199050386\n",
      "train loss:0.050797349930816596\n",
      "train loss:0.027264596370521078\n",
      "train loss:0.02110244208005455\n",
      "train loss:0.03210965998180184\n",
      "train loss:0.043163076796882055\n",
      "train loss:0.08625732835518005\n",
      "train loss:0.01928452644341979\n",
      "train loss:0.015047475965641884\n",
      "train loss:0.06651056375558985\n",
      "train loss:0.014027568548623207\n",
      "train loss:0.021464461722747245\n",
      "train loss:0.02903779338094377\n",
      "train loss:0.021296549077256435\n",
      "train loss:0.05104611675007659\n",
      "train loss:0.08172130252421914\n",
      "train loss:0.0851009298242603\n",
      "train loss:0.03110619679210383\n",
      "train loss:0.04607201092196469\n",
      "train loss:0.01615126577045137\n",
      "train loss:0.07158533588044291\n",
      "train loss:0.043033590709698054\n",
      "train loss:0.004637543696486778\n",
      "train loss:0.04184500257095756\n",
      "train loss:0.08695171243259649\n",
      "train loss:0.046594527300620886\n",
      "train loss:0.02385828783356442\n",
      "train loss:0.04546249751046196\n",
      "train loss:0.0193241050199913\n",
      "train loss:0.055901922922028405\n",
      "train loss:0.1135920020192927\n",
      "train loss:0.06200420918679786\n",
      "train loss:0.011568969775724872\n",
      "train loss:0.011808865599744917\n",
      "train loss:0.023185809945603784\n",
      "train loss:0.04528248111767324\n",
      "train loss:0.02297916271178356\n",
      "train loss:0.02172042988434971\n",
      "train loss:0.018080801684752693\n",
      "train loss:0.06297818609613627\n",
      "train loss:0.060529021392195806\n",
      "train loss:0.010420560616393924\n",
      "train loss:0.03933507930409122\n",
      "train loss:0.02665304513890692\n",
      "train loss:0.06911961285283917\n",
      "train loss:0.06018327280132954\n",
      "train loss:0.05638382616366216\n",
      "train loss:0.044322946578472744\n",
      "train loss:0.04206882241859891\n",
      "train loss:0.06083235387734234\n",
      "train loss:0.03608120897004574\n",
      "train loss:0.018052830256861704\n",
      "train loss:0.0067565945194419655\n",
      "train loss:0.01812825292052774\n",
      "train loss:0.06953771393349488\n",
      "train loss:0.015992332485357225\n",
      "train loss:0.10322745999705919\n",
      "train loss:0.07403844871926107\n",
      "train loss:0.0237035837832393\n",
      "train loss:0.022943524808875085\n",
      "train loss:0.021455353525349483\n",
      "train loss:0.034731217883986885\n",
      "train loss:0.0807055027176077\n",
      "train loss:0.09348187412849657\n",
      "train loss:0.04179768951152047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.033351306495281674\n",
      "train loss:0.01937564050785195\n",
      "train loss:0.04454385960868789\n",
      "train loss:0.10569877703026975\n",
      "train loss:0.05207562176355896\n",
      "train loss:0.032077272136551\n",
      "train loss:0.006987023012857403\n",
      "train loss:0.05955839133265054\n",
      "train loss:0.11245398125159697\n",
      "train loss:0.03635994911397369\n",
      "train loss:0.01011429497065722\n",
      "train loss:0.04640917943467517\n",
      "train loss:0.0832257649399445\n",
      "train loss:0.024965567177802437\n",
      "train loss:0.04460237420060057\n",
      "train loss:0.04012897496055456\n",
      "train loss:0.01992032160914898\n",
      "train loss:0.07487187709692349\n",
      "train loss:0.07387970563613294\n",
      "train loss:0.06414532508808671\n",
      "train loss:0.019064492060462287\n",
      "train loss:0.01581967503367309\n",
      "train loss:0.08627259788697174\n",
      "train loss:0.014235955929142407\n",
      "train loss:0.018985775864996408\n",
      "train loss:0.09389268108718542\n",
      "train loss:0.01696872549801903\n",
      "train loss:0.021033108598275927\n",
      "train loss:0.14287027586094955\n",
      "train loss:0.01807054684148772\n",
      "train loss:0.04335170110951405\n",
      "train loss:0.02428401168258674\n",
      "train loss:0.0295116470132834\n",
      "train loss:0.04018431940414116\n",
      "train loss:0.041489281744283506\n",
      "train loss:0.028532635125794018\n",
      "train loss:0.01773869043802931\n",
      "train loss:0.027414184277681834\n",
      "train loss:0.035030177039780085\n",
      "train loss:0.023520789499547553\n",
      "train loss:0.03304850632554642\n",
      "train loss:0.01361222819930423\n",
      "train loss:0.024433693205527726\n",
      "train loss:0.05948856453546303\n",
      "train loss:0.01366195044748257\n",
      "train loss:0.02628762275601851\n",
      "train loss:0.02369217517501449\n",
      "train loss:0.12231543390372643\n",
      "train loss:0.024898251153033128\n",
      "train loss:0.020903347284038466\n",
      "train loss:0.011535224631104053\n",
      "train loss:0.014022064178332289\n",
      "train loss:0.018468954819478356\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9711\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"C:\\\\Users\\\\pleiony_seo\\\\swoos91\\\\deep-learning-from-scratch\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from ch07.simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 3, 'pad': 1, 'stride': 3},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params_striding_2.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0.80, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "\n",
    "plt.savefig('striding_2_acc.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "print('============================================')\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params_striding_2.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
