{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치 미분의 경우, 단순하고 구현하기엔 쉽지만, 계산 시간이 오래 걸리는 단점이 있음.\n",
    "# 오차역전파법은 Chain Rule 을 이용하여 위의 문제를 해결함.\n",
    "# 중간까지 구한 미분 결과를 공유할 수 있어서 다수의 미분을 효율적으로 계산하는 것이 가능함.\n",
    "\n",
    "# 덧셈 노드의 역전파는 1을 곱하기만 할 뿐, 역전파 값을 그대로 하류로 보냄.\n",
    "# 곱셈 노드의 역전파는 순전파 때의 입력 신호들을 '서로 바꾼 값'을 역전파 값과 곱하여 하류로 보냄.\n",
    "\n",
    "# '차분을 이용한 수치 미분'과 '역전파'의 차이는,\n",
    "# 수치 미분의 경우에 모든 값들에 대하여 직접 미분을 계산하는 반면, 역전파는 순전파에서 이용했던 입력 신호를 가져다 계산만 한다는 점에 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단순한 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 곱셈 계층\n",
    "\n",
    "class MulLayer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # 순전파 시의 입력 값을 유지하기 위해 변수 할당\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x * y\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "        \n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n",
      "2.2 \t 110.00000000000001 \t 200\n"
     ]
    }
   ],
   "source": [
    "# 순전파\n",
    "\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward( apple_price, tax )\n",
    "\n",
    "print( int(price) )\n",
    "\n",
    "# 역전파\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(dapple, '\\t', dapple_num, '\\t', dtax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 덧셈 계층\n",
    "\n",
    "class AddLayer():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        out = x + y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        \n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "2.2 110.00000000000001 3.3000000000000003 165.0 650\n"
     ]
    }
   ],
   "source": [
    "apple_price = 100\n",
    "apple_num = 2\n",
    "\n",
    "orange_price = 150\n",
    "orange_num = 3\n",
    "\n",
    "tax = 1.1\n",
    "\n",
    "# 순전파\n",
    "\n",
    "apple = MulLayer()\n",
    "orange = MulLayer()\n",
    "\n",
    "mul_apple = apple.forward(apple_price, apple_num)\n",
    "mul_orange = orange.forward(orange_price, orange_num)\n",
    "\n",
    "shopping = AddLayer()\n",
    "total_price = shopping.forward(mul_apple, mul_orange)\n",
    "\n",
    "plus_tax = MulLayer()\n",
    "price = plus_tax.forward(total_price, tax)\n",
    "\n",
    "print(price)\n",
    "\n",
    "# 역전파\n",
    "\n",
    "dprice = 1\n",
    "\n",
    "dtotal_price, dtax = plus_tax.backward(1)\n",
    "dmul_apple, dmul_orange = shopping.backward(dtotal_price)\n",
    "dapple_price, dapple_num = apple.backward(dmul_apple)\n",
    "dorange_price, dorange_num = orange.backward(dmul_orange)\n",
    "\n",
    "print(dapple_price, dapple_num, dorange_price, dorange_num, dtax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 활성화 함수 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.mask = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    \n",
    "    def __init(self):\n",
    "        \n",
    "        self.out = None\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        dx = dout * self.out * (1.0 - self.out)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine / Softmax 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine Transformation\n",
    "# 기저벡터의 linear transformation을 통해 input 데이터의 기저벡터를 변환하여 표현\n",
    "\n",
    "class Affine:\n",
    "    \n",
    "    def __init__(self, W, b):\n",
    "        \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.x = x\n",
    "        out = np.dot(x, self. W) + self.b\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis = 0)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax_with_Loss\n",
    "# 신경망 추론과 다르게 학습에서 Softmax 층이 필요한 이유는, 손실함수를 통해 출력되는 지표값을 참고하여 backprop이 이루어지기 때문\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    \n",
    "    def __init(self):\n",
    "        \n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None    \n",
    "    \n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        \n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        \n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        \n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict\n",
    "\n",
    "    \n",
    "    \n",
    "    def loss\n",
    "    \n",
    "    \n",
    "    \n",
    "    def accuracy\n",
    "    \n",
    "    \n",
    "    \n",
    "    def gradient\n",
    "    \n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
