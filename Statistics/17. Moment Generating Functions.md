##### Statistics 110

###### Moment Generating Functions

---



### Goal of this lecture

> 무기억성이 있는 연속 확률 변수는 지수 분포를 따른다는 점을 이해하고, '적률 생성 함수'와 '라플라스의 후속 확률'을 이해한다.







#### Memoryless Property of Continuous R.V.

$$
\begin{aligned}

&\begin{aligned}
\bold{Theorem}\quad &If\ X\ is\ a\ positive\ continuous\ r.v.\ with\ memoryless\ property,\\
&then,\ X\sim Expo(\lambda)\ for\ some\ \lambda.
\end{aligned}\\
\\
&\begin{aligned}
\bold{Proof)}\qquad &Let\ F\ be\ the\ CDF\ of\ X,\ G(x)=P(X>x)=1-F(x)\\
&Memoryless\ property\ is\ G(s+t)=G(s)G(t).\\
&Solve\ for\ G.\\
\\
&If\ s=t,\ G(2t)=G(t)^2,....,G(kt)=G(t)^k\quad where\ all\ real\ k>0.\\
&Then,\ if\ t=1,\ G(x)=G(1)^x=e^{x\ln G(1)}=e^{-\lambda x}\quad(\because \ln G(1)<0\to -\lambda) 
\end{aligned}

\end{aligned}
$$

- 무기억성이 있는 연속 확률 변수는 <u>**지수 분포**</u>를 따른다.







#### Moment Generating Function(MGF; 적률 생성 함수)

> 분포를 설명하는 또 다른 방법

$$
\begin{aligned}
&\begin{aligned}
\bold{Def}\quad &A\ r.v.\ X\ has\ MGF,\\
&M(t)=E(e^{tx})\ as\ a\ function\ of\ t,\ if\ this\ is\ finite\ on\ some\ interval\ [-a,\ a], a>0
\end{aligned}\\
\end{aligned}
$$

- Why moment **<u>generating</u>**?
  $$
  \begin{aligned}
  E(e^{tX})&=E(\sum_{n=0}^{\infin}\frac{X^nt^n}{n!})=\sum_{n=0}^{\infin}\frac{E(X^n)t^n}{n!}\\
  &(\to E(X^n);\ n_{th}\ moment)
  \end{aligned}
  $$

- Why is MGF important?

  Let X has MGF M(t).

  1. The n<sub>th</sub> moment, E(X<sup>n</sup>) is coef of **t<sup>n</sup>/n!** in taylor series of M, and is **M<sup>(n)</sup>(0)=E(X<sup>n</sup>)**.

  2. MGF determines the distribution, ( i.e. if X, Y have same MGF ), then, they have same CDF.

  3. If <u>X has M<sub>x</sub></u> and <u>Y has M<sub>y</sub></u> **where X, Y are independent**, 

     MGF of X+Y is E(e<sup>t(X+Y)</sup>)=E(e<sup>tX</sup>) E(e<sup>tY</sup>) .

  $$
  \begin{aligned}
   
  &\begin{aligned}
  \bold{EX.1}\quad &X\sim Bern(p),\ M(t)=E(e^{tX})=pe^t+(1-p)\\
  &\to X\sim Bin(n,p),\ M(t)=(pe^t+(1-q))^n
  \end{aligned}\\
  
  &\begin{aligned}
  \bold{EX.2}\quad Z\sim N(0,1),\ M(t)&=\frac{1}{\sqrt{2\pi}}\int_{-\infin}^{\infin}e^{tZ-\frac{z^2}{2}}dz\\
  &=\frac{e^{\frac{t^2}{2}}}{\sqrt{2\pi}}\int_{-\infin}^{\infin}e^{-\frac{1}{2}(Z-t)^2}\\
  &=e^{\frac{t^2}{2}}\qquad (\because \frac{1}{\sqrt{2\pi}}\int_{-\infin}^{\infin}e^{-\frac{1}{2}(Z-t)^2}=1)
  \end{aligned}
  
  \end{aligned}
  $$







#### Laplace Rule of Succession

> **Given p**,
>
>  X<sub>1</sub>, X<sub>2</sub>,... are i.i.d. Bern(p) (<sub>Conditional indep.</sub>) is true, but p is unknown. So, Baysian treats **p as a r.v**.

$$
\begin{aligned}
&Let\ p\sim Unif(0,1)_{(prior)}\ and\ S_n=X_1+...+X_n.\\
&Then,\ S_n|p\sim Bin(n,p)_{(\to \ p\sim Unif(0,1)\ )}.\\
&Find\ posterior\ \bold{p|S_n},\ and\ \bold{P(X_{n+1}=1|S_n=n)}.\\
\\
\\
&\bold{(1).\ p|S_n}\\
&\begin{aligned}
&f(p|S_n=k)=\frac{P(S_n=k|p)\cdot f(p)}{P(S_n=k)}\ \propto p^k\cdot (1-p)^{n-k}\\
&\qquad(\because f(p)\to prior,\ P(S_n=k)\ does\ not\ dependent\ on\ p.)\\
&\qquad (\ *\ LOTP; P(S_n=k)=\int_0^1P(S_n=k|p)\cdot f(p)dp\ )
\\
\\
&\to f(p|S_n=n)=(n+1)p^n 
\end{aligned}\\
\\
\\
&\begin{aligned}
&\bold{(2).\ P(X_{n+1}=1|S_n=n)}\\
\\
&P(X_{n+1}=1|S_n=n)=\int_0^1(n+1)\cdot p\cdot p^ndp=\bold{\frac{n+1}{n+2}}

\end{aligned}

\end{aligned}
$$

