##### Statistics 110

###### Conditioning Continued, Law of Total Probability

---



### Goal of this lecture

> 전체 확률의 법칙을 이해하여 적용할 수 있고, 조건부 독립의 개념을 이해한다.





#### Law of total probability

> "Thinking conditionally is a condition for thinking" Then, how to solve a problem?
>
> 1. Try simple or extreme case
> 2. **breakup problem into simpler pieces**


$$
Let\ A_1,\ ...\ ,A_n\ partition(based\ on\ disjointness)\ of\ S.\\
\begin{aligned}
Then, P(B)&=P(B\cap A_1)+P(B\cap A_2)+...+P(B\cap A_n)\ (\ \because \ Axiom\ 2\ )\\
&=P(B|A_1)\cdot P(A_1)+...+P(B|A_n)\cdot P(A_n)
\end{aligned}
$$

- 의의: **Transform unconditional probability to conditional probability**

- **EX_1)** get random 2-card hand from standard deck
  $$
  \begin{aligned}
  Find\quad P(both\ aces|have\ ace)&=\frac{P(both\ aces,\ have\ ace)}{P(have\ ace)}\\
  &=\frac{P(Both\ aces)}{P(have\ ace)}\\&=\frac{\frac{\binom{4}{2}}{\binom{52}{2}}}{1-\frac{\binom{48}{2}}{\binom{52}{2}}}\approx \frac{1}{33}\\
  \end{aligned}\\
  P(both\ aces|have\ ace\ of\ spade)=\frac{3}{51}=\frac{1}{17}
  $$
  ​			=> **'최소한 하나'와 '특정된 카드'의 차이( conditional probability의 정의 참고 )**

  

  **EX_2)** Patient gets tested for disease that affects 1% of population, tests positive. 

  ​		   Then, what is P(D|T)?
  $$
  Suppose\ \begin{cases}
  D:\ Patient\ has\ disease\\
  T:\ Positive\ result\ of\ test\\
  Test\ Acc\ "95\%"\\
  P(T|D)=P(T^c|D^c)=0.95
  \end{cases}\qquad
  \begin{aligned}
  P(D|T)&=\frac{P(T|D)\cdot P(D)}{P(T)}\\
  &=\frac{P(T|D)\cdot P(D)}{P(T|D)\cdot P(D)+P(T|D^c)*P(D^c)}\approx0.16
  \end{aligned}
  $$
  ​			=> **"1% of population" 과 Test accuracy 간 Trade off 발생** 
  - **Bio hazard)** Confusing P(A|B), P(B|A)

    ex) **(Prosecutor's fallacy)** Sally Clark case, SIDS(영아 돌연사 증후군)

    ​	  error 1. It is not independent incidents. ( 1/8500 * 1/8500 )

    ​	  error 2. It is not P(innocence|evidence), but P(evidence|innocence)

    ​					=> **Prior probability "P(innocence) ≒ 1", this problem is on "Prior vs. Posterior"**

    ​						 Like confusing P(A) with P(A|B)





#### Definition of Conditional independence

> The key is, **Don't confuse unconditional independence with it**.


$$
Events\ A,B\ are\ conditional\ indep.\ given\ C\quad if\ P(A\cap B| C)=P(A|C)\cdot P(B|C)
$$

- Does conditional independence given C imply ( unconditional ) independence?

  **No**, for example, 

  >  suppose we have chosen either a fair coin or a biased coin with probability 3/4 of heads, but we do not know which one we have chosen. We ﬂip the coin a number of times. Conditional on choosing the fair coin, the coin tosses are independent, with each toss having probability 1/2 of heads. Similarly, conditional on choosing the biased coin, the tosses are independent, each with probability 3/4 of heads.
  > However, the coin tosses are not unconditionally independent, because if we don’t know which coin we’ve chosen, then observing the sequence of tosses gives us information about whether we have the fair coin or the biased coin in our hand. This in turn helps us to predict the outcomes of future tosses from the same coin.
  > To state this formally, let F be the event that we’ve chosen the fair coin, and let A1 and A2 be the events that the ﬁrst and second coin tosses land heads. Conditional on F, A1 and A2 are independent, but A1 and A2 are not unconditionally independent because A1 provides information about A2.
  >
  > ref: 'Introduction of Probability', Joseph K. Blitzstein, Jessica Hwang 

  

  Then, does ( unconditional ) independence given C imply conditional independence?

  **No**, for example, 

  > $$
  > Suppose\quad \begin{cases}
  > A:\ Fire\ alarm\ goes\ off\\
  > caused\ by\  F:\ fire,\ C:\ popcorn\\
  > F\ \&\ C\ are\ independent.
  > \end{cases}\\
  > P(F|A,C^c)=1,\ not\ cond.\ indep.\ given\ A.
  > $$
  >