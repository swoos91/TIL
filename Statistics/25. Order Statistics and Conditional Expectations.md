##### Statistics 110

###### Order Statistics and Conditional Expectations

------



### Goal of this lecture

> 베타 분포와 감마 분포의 관계를 이해할 수 있으며, 순서 통계량의 분포를 구할 수 있다.









#### Example for Normalizing Constant of Beta  Gamma dist.

> X~Gamma(5, λ) 인 경우, 5개의 i.i.d. (독립 항등 분포) λ를 지수로 하는 지수 분포를 합친 것으로 볼 수 있음
>
> (e.g.) 줄 위에 5명의 사람이 있고, 각 사람 당 eλ 시간 만큼 기다리는 상황

- Bank - Post office example

$$
\begin{aligned}

&Let\ X_{(\to\ wait\ on\ bank)}\sim Gamma(a,\lambda),\ Y_{(\to\ wait\ on\ post-office)}\sim Gamma(b,\lambda)\ indep.\\ &Then,\ find\ joint\ distribution\ of\ X+Y=T,\ \frac{X}{X+Y}=W.\ (Let\ \lambda=1\ to\ simplify\ notation)\\
\\
\\
&\begin{aligned} &\bold{Sol)}\\
&\begin{aligned}1.\ joint\ PDF\ f_{T,W}(t,w)&=f_{X,Y}(x,y)\left| \frac{d(x,y)}{d(t,w)} \right| \\&=\frac{1}{\Gamma{(a)}\Gamma{(b)}}x^ae^{-x}y^be^{-y}\frac{1}{xy}|-t|\\&=\left(\frac{\Gamma(a+b)}{\Gamma{(a)}\Gamma(b)}w^{a-1}(1-w)^{b-1}\right) \left( \frac{t^{a+b}e^{-t}\frac{1}{t}}{\Gamma(a+b)}\right)\\ &\qquad^{\to\ \bold{function\ of\ w},\ \bold{\ Gamma(a+b,1)};\ W와\ T\ indep.}\\&^{\begin{aligned}\quad ^*Jacobian\ :\ &x+y=t,\ \frac{x}{x+y}=w\ \to\ x=tw,\ y=t(1-w)\\
&\begin{vmatrix}\frac{dx}{dt} & \frac{dx}{dw} \\ \frac{dy}{dt}&\frac{dy}{dw} \end{vmatrix}=\begin{vmatrix}w&t \\ 1-w&-t \end{vmatrix}=(-tw)-t(1-w)=-t \end{aligned}} \end{aligned}\\
&\begin{aligned}2.\ &Marginal\ PDF\ f_W(w)=\int_{-\infin}^{\infin}f_{T,W}(t,w)dt=^*\frac{\Gamma(a+b)}{\Gamma{(a)}\Gamma(b)}w^{a-1}(1-w)^{b-1}\quad _{^*\frac{\Gamma(a+b)}{\Gamma{(a)}\Gamma(b)}:\ Normalizing\ constant} \\ &\qquad \to\ know\ normalizing\ const.\ of\ Beta(a,b),\ and\ T\sim \Gamma(a+b,1),\ W\sim Beta(a,b)\ are\ indep. \end{aligned}\\
\\
&*\ Find\ E(W),\ where\ W\sim Beta(a,b)\ _{(\ Two\ ways:\ \mathsf{i)}\ \cancel{by\ LOTUS\ \&\ Def )}\quad\ \mathsf{ii)}\ E(\frac{X}{X+Y})=\frac{E(X)}{E(X+Y)}=\frac{a}{a+b}\ )}\\ &\qquad :\ Why\ is\ E(\frac{X}{X+Y})E(X+Y)=E(X)\ in\ this\ special\ problem\ of\ Gamma_Beta?\\ &\qquad\qquad \to\ \frac{X}{X+Y}\ is\ indep.\ of\ X+Y\ _{(\ Uncorrelated:\ E(XY)=E(X)E(Y)\ )}

\end{aligned}



\end{aligned}
$$











#### Order Statistics

$$
\begin{aligned} &\begin{aligned}\bold{Def}\quad &Let\ X_1,...X_n\ be\ i.i.d.,\ the\ order\ statistics\ are\ X_{(1)}\le X_{(2)}\le ...\le X_{(n)},\\ &where\ X_{(1)}=min(X_1,...,X_n),\ X_{(n)}=max(X_1,...,X_n).\\ &^{(e.g.)\ if\ n\ is\ odd,\ the\ median\ is\ X_{(\frac{n+1}{2})}}\\ &^{^*\ difficult\ since\ \bold{dependent},\ and\ Tricky\ in\ discrete\ case\ because\ of\ 'ties'(=동일한\ 값의\ 경우)} \end{aligned}\\ \\ \\ &Let\ X_1,...,X_n\ be\ i.i.d.\ with\ PDF\ f,\ CDF\ f.\ Find\ the\ CDF\ \&\ PDF\ of\ X_{(j)}\\ \ &\begin{aligned}\to CDF:\ P(X_{(j)}\le x)&=P(at\ least\ j\ of\ X_j's\ are \le x)\\ &=\displaystyle\sum_{k=j}^{n}\binom{n}{k}F(x)^k(1-F(x))^{n-k} \end{aligned}\\ &\quad \begin{aligned} PDF:\ &f_{X_{(j)}}(x)dx=n\binom{n-1}{j-1}f(x)dx\cdot F(x)^{j-1}(1-F(x))^{n-j}\\ &\therefore f_{X_{(j)}}(x)=n\binom{n-1}{j-1}\cdot F(x)^{j-1}(1-F(x))^{n-j}f(x) \end{aligned}\end{aligned}
$$



+) [<img src="https://camo.githubusercontent.com/3b9a2f328ce83c513df70017129572233ce7d0eb/68747470733a2f2f637068696e662e707374617469632e6e65742f6d6f6f632f32303138303930395f3236352f313533363437353732343138317a555336555f504e472f32352d332e504e47" alt="img" style="zoom: 50%;" />](https://camo.githubusercontent.com/3b9a2f328ce83c513df70017129572233ce7d0eb/68747470733a2f2f637068696e662e707374617469632e6e65742f6d6f6f632f32303138303930395f3236352f313533363437353732343138317a555336555f504e472f32352d332e504e47)<sub>ref: https://cphinf.pstatic.net/mooc/20180909_265/1536475724181zUS6U_PNG/25-3.PNG</sub>


$$
\begin{aligned} \bold{EX}\quad &U_1,...,U_n\ i.i.d.\ Unif(0,1),\\ &f_{U_{j}}(x)=n\binom{n-1}{j-1}x^{j-1}(1-x)^{n-j}\cdot \underline1_{*{(\to Unif\ PDF)}},\ for\ 0\lt x\lt 1\\ &\to\ U_{(j)}\sim Beta(j,n-j+1)\\ \\ &^{\begin{aligned}(e.g.)\ E|U_1-U_2|&=E(max(U_1,U_2))_{_{(\to\ Beta(2,1))}}-E(min(min(U_1,U_2)))_{_{(\to\ Beta(1,2))}}\\ &=\frac{2}{3}-\frac{1}{3}=\frac{1}{3} \end{aligned}} \end{aligned}
$$
 